channel_id,video_id,published,title,source,description,transcript
newsroom_robots,20,"Wed, 16 Aug 2023 23:56:27 GMT",Jeremy Caplan: Exploring the Landscape of AI Tools to Boost Productivitiy,https://shows.acast.com/newsroomrobots/episodes/jeremy-caplan-exploring-the-landscape-of-ai-tools-to-boost-p,"Jeremy Caplan joins Nikita Roy to discuss the evolving landscape of AI tools by analyzing their use cases, addressing the challenges they present, and offering tips for enhancing productivity through strategic AI adoption
Jeremy Caplan is the Director of Teaching and Learning at the Newmark Graduate School of Journalism at the City University of New York. He also leads the school's Entrepreneurial Journalism Creators Program — a 100-day online curriculum that guides independent journalists to build new ventures.
Before transitioning to academia, Jeremy was a Time Magazine reporter writing about digital innovation. He is also the person behind Wonder Tools, a weekly newsletter that zeros in on the most useful digital tools to boost productivity.  He studied public policy at Princeton University's Woodrow Wilson School and subsequently earned an MS in Journalism as a Knight-Bagehot Fellow at Columbia University and an MBA as a Wiegers Fellow at Columbia University.He is a violinist who formerly served as the Concertmaster of the International Symphony Orchestra in Israel. 
Tools discussed in this episode: 
	•	ChatGPT
	•	Claude
	•	Bing Chatbot
	•	Bard
	•	Poe
	•	Personal.ai
	•	Woebot
	•	Character.ai
	•	RunwayML
	•	Kapwing
	•	Descript
	•	Wotchit.ai
	•	Superhuman
	•	Bloks.app
	•	4149.ai
	•	Supernormal
	•	Intros.ai","Nikita Roy  0:02  
This is newsroom robots, the Podcast where we explore the intersection of artificial intelligence and the news industry. I'm Nikita Roy, a data scientist, media entrepreneur, and one of the many founders currently building their ventures at the Harvard innovation labs. On the newsroom robots. I'm excited to bring you insightful conversations with industry experts about how AI is impacting the way we do journalism. Today, I'm joined by Jeremy Kaplan, who serves as the Director of Teaching and Learning at the Newmark Graduate School of Journalism at the City University of New York. He also leads the school's entrepreneurial journalism creators program 100 day online curriculum that guides independent journalists to build new ventures around the world. before transitioning to academia, Jeremy was a reporter at Time Magazine, where he wrote about digital innovation. Now he's the voice behind wonder tools, a weekly newsletter that zeroes in on the most useful digital tools to boost productivity. In our conversation. Today, we explore the landscape of AI tools, weighing their capabilities against their constraints. Plus, Jeremy gives us a first hand account of his experiences and use cases integrating AI into his work.

Hi, Jeremy, welcome to newsroom robots. I'm so excited to have you here today.

Jeremy Caplan  1:35  
Hi, Nikita, it's a pleasure to be with you.

Nikita Roy  1:37  
So I have been looking forward to having you on the show mainly because every time I've spoken to you, I've always come away with some important insights on AI or a fascinating new tool that you've told me about that then soon becomes part of my AI toolkit. And so I'm eager to just dive deep into a discussion on AI tools with you today and want to learn what you've come across and how you're using it and your work. We are all familiar with Chachi Beatty from open AI and we've discussed it a lot on the show. And there's now a growing list of competitors that have coming out meta at the time of recording right now is just open source. They are language model llama two, which is surprisingly done with partnership with Microsoft. But we've also got cloud from anthropic and Paul from Cora, and all of them getting a fair bit of buzz recently. So I want to start off by knowing what are your thoughts on how all of these other chat TBT competitors stack up and what experiences you've been having with like Cloud and foe, I like to think

Jeremy Caplan  2:42  
of the AI tools we have so far as the big five. And we started with open AI as Chad GPT, as you mentioned, and then we've since then, seen Bard join from Google. And then being AI, which was using open AI as technology but had a different interface, a different user experience, and most recently clawed and Poe. And those two are the newest and I think the most exciting kind of most recent entrance. And in addition to those five though, we also have a bunch of other kind of custom AI tools that are slightly different that I think are really interesting that we can talk about things like personal.ai, or py and woebot. These are individual AI tools that are for specific purposes that are a little bit different from the church CPTs of the world.

Nikita Roy  3:28  
Can you get into more into personal AI and hopeful but what's really different about them?

Jeremy Caplan  3:34  
Yeah, so this category is a brand new one that I'm writing about. And the idea here is not that they're going to answer any question you have, like check GPT or generate texts from the corpus of the entire internet, like Bing, and Bard and Intel, GPT. And Claude. Instead, they're basically conversation partners that use AI to comfort you or to counsel you, or to just be a conversational partner for you. And they're very much emerging at the moment, they're still kind of in development. personal.ai just announced their second version. And the idea is, is that you essentially have a kind of conversation partner that has an AI power to it. So you can kind of get to know it, it can get to know you a little bit and it can remember answers that you've given in the past. So that can be useful if you want to be reminded of what was that restaurant I went to when I was here last time or what did I really mean to say mentioned three points, I was gonna say to this person, or it can act as kind of like a external memory bank for you. And it can also remind you of different things you've been thinking about. And it can also just be a kind of like robotic assistant for you as you're going through your day. Here are the five things I want to get done today. Help me think through what order I should do them in. And I'm stuck. I'm not feeling motivated at the moment. What are some ways people like me can, you know motivate themselves to keep working when we're stuck so you can kind of think of it as a digital assistant or digital AI conversation partner And it's a different category from the Chachi pts.

Nikita Roy  5:03  
That sounds so cool. I feel like it's like a personalized blog post written for you that before you would have Google answer your questions, and now something like that can just be your assistant. I'm also curious to know you've been playing around with cloud and poll, what has that experience been like how you've been using it more than Chad TPT

Jeremy Caplan  5:23  
Claude is really interesting to me because of the extent of its memory. So you can upload almost 75,000 words to Claude, I'm actually finishing a post about this right now, because I've been testing long uploads of PDFs that are quite substantive and lengthy. And I can ask you to, to help me analyze this to give me a summary of the key points to help teach me something from it in a simple way, step by step to coach me on how I would implement the ideas in this document. And to give me feedback when I give an example of how I might implement it based on the insights of the documents, so I can kind of use it as a coach that draws only on that document. So unlike GPT, or something, where you're using it generally, for material from the corpus of the entire internet, you can direct Claude to just draw on this specific material. And it could be your own materials, something you created. Or it could be something from another research document or a scholarly paper, for example that you're trying to learn from. So that's really powerful. And the 75,000 word maximum means that you are just able to have much bigger documents, much bigger window of information to examine, you could upload your own journal past journal, for example, and think through what were some of the interests and the inferences that can draw about things times when you were doing well, or times when you were struggling? There are really limitless possibilities for for ways to use it that I'm just beginning to explore. And with quad, it's completely free. So for Chachi BT, you can use the plugins to have it examine attachments and other materials. But those require the $20 a month subscription, at least as of now. Whereas with Claude, it's completely free to do that kind of analysis for now, which is great. And the UI is very similar user experience. And interface is very similar to touch up tea. So it's essentially just a box. But the answers are slightly different. So it's a Coke and Pepsi kind of thing. In addition to that attachment feature, it has a slightly different response to the question, you might ask chat GPT. So I think it's fun to experiment with both. One thing that's great about Po, which is another new AI tool is that you can create these single use AI bots that do just one thing really well. So for example, I created a little one, that's a French Goro. So I'm still trying to work on my French. And it basically not just translate something, but it explains why it's using certain phrase or how it's using a certain grammatical elements of the language. And that's its only purpose is for that, right, there's another one that I created, that just gives me a six word summary. So I can give it a title of any book, or movie or film or play or anything. And you can create your own really, really easily. Or you can find hundreds of other bots that people have created, for example, one that just gives you good mid journey prompts. So you describe the kind of picture you want. And it'll give you the language to use in midjourney. So I love this idea of like really custom made AI bots that just do one thing really, really well. And they can be useful when you need to do some specific thing.

Nikita Roy  8:20  
Oh, that's fun. The French girl, especially having your own French teaching aid for yourself. One

Jeremy Caplan  8:27  
that I really liked playing with is called memory aid. And the idea here is it gives you little mnemonic devices. So I often like frameworks and tools for remembering things because I forget them so easily. So I can ask it for mnemonic device, basically, for pretty much anything I want to remember whether it's the order of the colors of the rainbow, or the planets, or the classifications of living things, you know, the kingdom and phylum and all that. And it will give me a clever little way to remember that. So that's been a useful single purpose AI tool with Poe.

Nikita Roy  8:59  
And this is something that people can just create their own poll bots with kind of just having their own prompts, that they can just have single purpose use for every single thought that they create, right? Yeah, exactly.

Jeremy Caplan  9:09  
It's really, really easy. And you're basically just customizing a flavor of Claude or ChatGPT. So you're not creating the whole language model, you're just building on top of it a little bit of a custom set of instructions that requires no coding, it's no complexity takes a few minutes, in some cases, depending on how sophisticated it is. There are some other ones that allow you to do this in a more sophisticated way, like character.ai. But this one is really just a simple one and very easy to use. And you can use anyone else's bots so you can make your own or you can just use what other people have already made.

Nikita Roy  9:39  
That's a really fun use case for and right now Chad GPT also has all of these different plugins that are adding the new layer of usability to it. What have you come across with Chad GPT over there. That's been a fun use case that you've been using in your work.

Jeremy Caplan  9:56  
So the plugins are really, really interesting and plugins store just keeps growing and growing and growing. There are hundreds and hundreds of different plugins. There are 177 screens as of now, each of which will have several different plugins to choose from. So it really depends kind of what you want to use it for, you can find something, there's some really specialized ones. For example, people who are substack newsletter writers like me, we now have a substack AI plugin that allows us to dig into our past posts or even look at other people's posts and topics covered by other newsletter writers, for example, there are travel plugins that are useful for making some preliminary travel plans and thinking about different possibilities and different cities, things like Expedia and kayak OpenTable if you're interested in booking a restaurant, so there's some of those kinds of practical ones. There are some more research oriented ones that are really useful like Wolfram Alpha. And an example of how that works is essentially enables chat GPT to do math, which surprisingly, it can't really do on its own cloud, by the way, that same handicap and can't really do math, surprisingly. So with Wolfram Alpha is plugin for GPT, you can actually have it do relatively complicated multi part, math problems, and also kind of situational math. So you can tell that a CPM for example, and how many ads you're thinking about having on a particular page and how many advertisers you potentially will be pitching and what percentage you think might convert you can sort of feed it that information in a scenario. And then it will do all the number crunching for you and spit out some some accurate analysis, which is helpful in my test.

Nikita Roy  11:31  
And you've obviously spent a lot of time with all of these variety of AI tools, is there any one tool that you found is absolutely essential for you now that's become a part of your everyday life. And what makes that stand out?

Jeremy Caplan  11:44  
Well, I do think ChatGPT remains the most versatile and at the moment because of the range of plugins. So for example, one of the other plugins I like is one called whimsical, which is a design tool that allows you to create diagrams, like organizational charts or process or flowcharts. And with whimsical is plugin, you can just type something in natural language like show me the process for having a plant grow or having hiring a ploy, and through all of the stages of that process, and it will generate a diagram for you that you can then edit in whimsical so and you can do similar things with other apps like you can use Zapier and have the research that you're doing and ChatGPT be plugged into a spreadsheet, a Google spreadsheet, or an email that you have chat GPT helping you draft you can have it put into your drafts folder in Gmail. So the fact that it plugs into all of these different kinds of tools, like Zapier, like whimsical like Wolfram Alpha, like all these travel apps that I mentioned, means that it's really versatile and you can use it for whatever you want to use it for. Or if you just want to have it compose a crazy poem in the style of Michael Jackson about grilled cheese or something, you could do silly things. But you can also do really useful practical things. So for now, ChatGPT with its plugins does remain the most versatile. But increasingly, I think that we'll have a whole AI toolkit, we won't necessarily just have one that we always use. And increasingly, all of the tools we have will have aI built in, right, so notion already has a really nice AI limitation. Coda has a new really excellent AI implementation craft, which is a toy love craft I do, which is a note taking and document what I love using, which is beautifully designed has a really nice AI implementation right inside the tool as well, even Google Docs now has an AI implementation. Canva has an AI implementation. So all of these tools we use, have aI baked in. So we don't necessarily always have to go out to dt or Claude or one of those tools to benefit from AI. And I think that's, that's gonna be really helpful. So we don't have to break our workflow to get the benefit of AI. And I'm eager to

Nikita Roy  13:49  
learn more about how you're utilizing AI. When you're running your newsletter, your newsletter is all about evaluating tools and being on top of all of the new tools that are coming. And there's a lot of them, how do you use AI to kind of write that? 

Jeremy Caplan  14:04  
Well, one of the secrets I'll share is that for Wonder tools, one of the things that has been time consuming for me, by choice is responding to email. So I encourage people to write back and many people, surprisingly, or not, surprisingly, do take me up on that. They'll write me a question or they'll say hello, which I love. I really, it's so fun getting to meet people from around the world's e meet not really meet in person, but meet them through email. It's really nice and interesting. And oftentimes, they all share something about where they're from, which is really a great opportunity for me to learn about different places and different fields of interest that people have. And yeah, that can be time consuming. Because once you get into an email dialog that can be really time consuming. So one of the new things I've been experimenting with is using AI in email as part of my workflow, and superhuman, which is the email tool I use which plugs into Gmail. and it actually has a new API implementation as well. And the nice thing about it is that it unlike sort of generic GPT, email, on chat, GPT, or caught or somewhere else, it actually starts to know your style, because it can look at your past emails, you essentially give it access to a month of your past email when you set it up. So it actually does a decent job of imitating your style, I would say, and it's not sending anything without your permission, of course, right, you're still in charge of that experience. It's just helping you draft. So you're starting from a draft. And in addition, you coach it on the draft. So you say, here are a couple things I want to mention. But you don't have to word it out exactly. or type it out exactly in your own words, which is what often takes me some time. So instead, I can just give it a few phrases or key points I want to make, and then it puts it into a nicer format that sounds like full sentences. And then I can take another look at it, and then I can send it. So it's still my words. So my thoughts, it's not doing anything for me in that sense, except stringing my thoughts together into something a little bit more coherent, and full sentences. And that's a time saver when you're doing many, many emails a day, particularly for these kinds of light exchange emails where it's someone I don't know. And the alternative is, I wouldn't be able to write to them at all. I wouldn't necessarily use this day to day with colleagues or friends, for example, because I want to be my human self and those interchanges. But when it's, you know, just dealing with a large group of people that I don't know, and just have a one off, or one or two email exchange, it can be pretty helpful in that in that context. So that's, that's one of the ways in which AI is useful for for the newsletter.

Nikita Roy  16:30  
That's actually a really fascinating use case. And and the first time I'm hearing somebody openly talk about using AI to help write emails, you have to

Jeremy Caplan  16:38  
be careful. You have to be you have to be careful with it. Yeah, yes. I've gotten a couple emails from people and I email them back, say, did you say for that, because it didn't sound like. And I do think there's a danger here. And I definitely don't encourage people like just giving the AI you know, free rein on your email. But if you do write a lot of emails, and some of them aren't, like, super important or super personal, then you know, I think it can help with that. And again, just drafting and sending. So yeah, I do think there's a place for it in the routine. There are a couple other use cases, for me AI in the newsletter. One is I had a column recently or post where people had a lot of comments suggesting different tools, alternative tools and ideas in response to a post. And I wanted to gather those in a way that people could see because sometimes when you have a threaded set of comments, it's kind of hard to make sense of if you're coming upon that as a reader. So I just copied all that and pasted it into notion and had notion AI basically put it into a neat table, and organize it and create two columns, one, which was the name of the tool, and in the second column was like a little description, based on what someone had written in the comments. So if I manually put that together, and like, made the whole table and grab a copy of each, you know, it would have just taken at least an hour or two of menial work to clean that up and put it in an organized way and set it up, et cetera. And this took like five minutes, because I just literally copied and pasted it as a notion gave it a little prompt as to you know, what I wanted the table to look like organized, you know, and it did it really well. It was surprisingly good at that. And recently, I tried something similar with Claude. And it actually added the links as well, which surprised me added accurately added the links to the words so that people could just click on the name of the tool. So that's another case where AI can be helpful with a kind of menial task of organizing information that would have otherwise just been a lump of stuff.

Nikita Roy  18:21  
And how are you dealing with like hallucination? How are you dealing with your prompt specifically to avoid hallucination with when you're using like Cloud or chat up or any of these AI tools?

Jeremy Caplan  18:32  
Well, there are a few different strategies. One is to tell it to be careful and make sure that you're not adding anything fake. So even just saying something like adding that little addendum to your prompt can be helpful. And I've heard that a couple of of kind of experts in this arena. Another thing is, you know, in many cases, I'm not actually using it to look for fact based material, if that makes sense. I'm kind of more asking it to take this set of text, and clean it up, reorganize it, put it into a table, or draft some material that I'm going to look at that's based on something I'm giving it. For example, I'm giving it a PDF of the scholarly paper of 20 page paper about pedagogy. And I'm asking you to synthesize key stuff. And I can go back and look and check if that's in the paper and make sure. So those are a couple of specific strategies. I think increasingly, we're going to be asking the AI to focus on a specific corpus so that it's not just pulling generally from the entire internet, but it's pulling specifically from this specific Google Drive folder, or this specific set of documents on Dropbox or this specific corpus of material that you've created or prepared or curated. And I think when it's doing that it's in a lot more controlled environment. And it's not just going to pull in as randomly as, as it might otherwise,

Nikita Roy  19:49  
yeah, can avoid the hallucination. True, and that and I'm really eager to know I'm wondering when you're evaluating all of these new AI tools that are coming about what are the primary factors that you're considering to kind of discern what's a potentially great tool from the pack that you then go and include in your newsletter.

Jeremy Caplan  20:08  
I have a little four F's checklists, this is I like alliteration, and I like checklists. So first is friction. So if there's something that's super complicated, like it's going to be really expensive, are really time consuming, or I'm gonna have to fill out like a three page set of documentation and wait three weeks, that might be a reason for pause right on the tool, if I'm just kind of wanting a quick experiment. So friction is a big first thing. Second, is it fast? Like can I actually get something done quickly, either a lot of things I'm excited about doing an eager to do and want to do. And if I have to suffer slow performance, or something isn't really working rapidly enough? For me, that's also a question mark, or danger mark, some things you do have to wait for. And some things are worth doing slowly, for sure. But when it comes to AI and productivity, I want it to work quickly. Third, is fun. Like, is this actually fun to use? Like, is it lively? Is it well designed? Is it feel good and useful? And then fourth, is it fruitful? Like, does it actually generate something that I can use and build on work with? So that's simple kind of checklist for me when I'm thinking about something new. And after testing a bunch of these things, I start to get a feel for whether there's something actually new here and different, because we don't just need 10 of the same things. We only want to add something to a toolkit if it's really going to be better, and or cheaper and or faster than something else we've already been using, or if it's really adding something new and different, right. So if it's going to be doing something that no other tool has really been able to do, that can be a really helpful thing. So for example, one of the new areas I'm looking into is taking long videos and creating short little usable, shareable clips out of them. Right. So that's a useful function that takes a long time to do manually by hand. But AI tools can can start to do that now. Well, so if I find a tool, and I'm exploring tools, if I find one that I really like in that arena, that would be a good one to add to my toolkit. Whereas if I find a simply another tool that will generate plain text like chat, GBT does, or like any of the other tools we've we've discussed do, that's less of a priority, because we already have some really great tools to do that.

Nikita Roy  22:23  
And I'm quite interested in that use case of getting shorter videos from long form videos, what tools have you come across right now, in your research?

Jeremy Caplan  22:31  
Well, it's still early to say so I'm not in a position yet to recommend one of those keep an eye on one or two holes for later this summer or fall for recommendations at that arena. But there are some interesting tools that are using AI for video creatively. So runway, ML is one that's really interesting cap wings, another one that's using AI really in an interesting way, and D script. So those are three that use AI already for a variety of purposes, and each have aI incorporated in a slightly different way. There's also one called watch it w o c h i t.ai allows you to create a 32nd sort of magic AI video, it'll just kind of like make the video for you with a little prompt, which is kind of cool. The other ones that I mentioned, the script and cap wing and runway are a little bit more sophisticated in terms of using AI to empower you as a video editor to do a little bit more quickly some of the menial things you would otherwise have to do. So they're not exactly handling all of the clipping kind of scenario that I was speaking about. But they're doing some of the video editing help in terms of generating transcripts in terms of letting you edit with the transcript in terms of letting you automatically clean up filler words and other material automatically kind of improve the let's say lighting or contrast, and some other kind of technical things that you might do with video editing. So it's an exciting arena. But it's still an arena that's developing. And I think we'll see more and more tools later this summer and this fall into the winter that are helping with the video editing process, which can be so labor intensive. And where there's really like a lot of benefit to having more AI I think we'll see Adobe and Apple starting to include more AI features in their professional tools Final Cut and Premiere. And we'll also see more creativity around smaller startups taking longer form video interviews, for example, and giving you cool ways to chop those up into small pieces that you can then share without having to spend hours doing the manual video editing, you can just do a quick check or a quick adjustment and share.

Nikita Roy  24:31  
Yeah, I'm excited for that future, hopefully, where we can convert all these podcast interviews into more shorter form bite sized content without having another person doing all of that. But I'm kind of interested to know also, from your experience, what are the recurring limitations that you've been facing? When you've been dealing with all of these AI tools? Has there been a constant gap that you've been seeing in the current landscape?

Jeremy Caplan  24:54  
Some of the tools don't do a great job explaining what you can do with them and how to use them effect Probably, I think that's the problem with a lot of tools in general is they give you a blank box. And they said go to it. And they might say, you know, watch out, it might confabulate, or it might hallucinate. Or they might say, you know, you can't trust this information or what have you. But they don't necessarily do a great job of guiding you to some creative use cases or uses of it. And I went through the Cloud documentation, for example, and they have some good tips on how it works. And they tried to be as concise as possible, I think, because there is their focus, it seems. But actually, I think what would be more useful would be to say, here are five different fields that people might be in in 10, different use cases, and each of those fields where we've found that certain prompts work really well to get you in this direction, right. So I think people need more hand holding and more help and more scaffolding to use the tools effectively. And I think a lot of the tools, and I'm generalizing here, but I found it to be generally true. A lot of the tools just kind of want to let you figure it out for yourself, that's there is kind of like, well, you can do anything with it. So go to it. And I think what ends up happening is that 90% of the uses tend to fall around a certain small area that people have seen other people or heard other people talking about. But there's actually this like huge 90 other percent, that we just haven't really thought through yet. Because there's a disconnect between what you could do or possible uses possible use cases, possible ways of using them creatively that we just haven't been introduced to. So that's, that's one of the limitations. I've seen. I think another limitation is the windows of what something will remember are limited. So for example, if you start a if you started particular chat with cloth or with chat, GBT, or some of the other tools on a particular topic, and then you come back to it later, if you're within the same chat window, it'll remember that context. But if you want it to know several different things about different kinds of preferences you have, and those are situated in different chat conversations that you've had, it won't remember across those conversations, right. So it essentially treats you as a separate person each time. And there's some security reasons for that are some some kind of guardrails that are set up. And that's part of why but I think that creates an artificial limitation, which is to say, it can't really get to know your preferences. And therefore you have to repeatedly include those constraints or those details or those reminders, which limits what you can do in each chakra, you have to reiterate all the stuff that you needed to know every single time basically. And so that's a limitation, I think. And I think that's a little bit where these other tools like personal.ai come into play, or pie where the idea is that they are going to get to know you over time. And they're going to serve as kind of an agent for you. And they knowing your preferences, knowing your style, knowing your key considerations. You don't have to keep telling those tools, the same things every day. And I think that can be kind of helpful that can be useful. There's obviously considerations people have about people being too dependent on an AI tool or falling in love with an AI tool and that sort of stuff. But for productivity purposes, it's really helpful to have it get to know some of your your preferences, some of the key considerations what sit you know, if you're using it for travel, you want it to know what city you're going to what your airline preferences are that sort of thing, your budget, those kinds of things. You don't want to have to start from scratch every single time.

Nikita Roy  28:20  
Yeah, I see that as that's currently a roadblock for me as well, every time you go to chat GPT as well, putting in the same problems again, and again, for different use cases, it doesn't remember what I like or what I want. And that's the biggest limitation.

Jeremy Caplan  28:34  
Yeah, and if you think about across all domains, various domains of our lives, right, like if you have certain dietary preferences, or dietary needs, right, you have certain travel preferences, you have certain preferences in terms of what time of day you're doing certain things, or you are traveling with particular family members or alone or you have other like, there's all these different characteristics that we have in a persistent way that if the tool remembers those, that's really helpful. And if it doesn't, it really slows us down every time and prevents it from being like a really quick, helpful aid to speed our productivity.

Nikita Roy  29:06  
Shifting gears a bit, I want to talk more about using AI in the space of education because I did an AI workshop for your entrepreneurial journalism Creators Program. And when I came into the Zoom Room, I remember being with a couple of bots and new AI tools being experimented over there. And I got a bunch of transcripts and emails at the end. And I was introduced to a lot of tools just by being in your classroom, which was a fun use of seeing how AI is being used in teaching. And so I'm curious to know more about how are you integrating AI into your teaching as a professor and how do you use all of those tools in different aspects to just engage students? Well, the

Jeremy Caplan  29:46  
first and most significant or substantial way we've used AI so far is through the creation of summaries and transcripts and materials that we can refer back to for the classes. So with live classes, we Eat? Well, let me back up and say that the program that I lead is the entrepreneurial journalism creators program, which is a 100 day online program for independent journalists around the world who are creating new newsletters, podcasts, niche ventures of various kinds news sites, and we meet a couple times a week for live sessions. And after a session, there might be a lot of different ideas that have floated through that session and a lot of different tools and resources and quotes and comments and frameworks, and slides. And there's a lot that people may want to come back to and return to. So we do have a manual human process, which is really important. And that is that we have a shared notes document. So everyone takes a turn, leading notes for one particular day during the term. And we share that document and everyone has access to it. So we have a collective record an artifact of our learning and our term and our journey. And that can include images and screenshots and various kinds of resources. But it doesn't have necessarily summary of everything in the way that the AI can provide that. So we use several different AI tools, we've been experimenting with several different AI tools to create a full transcript and a summary. And what's exciting about a couple of them, that I'll mention is that you can actually query them. So the one that I'm thinking of in particular is called 4140 nine.ai. And it's a new tool that is really useful in that it records the session mainly for the transcript. So we're not using it for the video itself, or the even the audio itself necessarily just for the transcript. And then it takes the transcript generates a really intelligent summary that's broken down by section with helpful headings. And then it has this function where it gives you a Google Doc, and you can actually query the Google Doc. So you can say, what were some interesting quotes from the session? Or what did this person say about burnout, or the subject of revenue streams came up, which were the ones that people mentioned, because I can't remember all of them. And you can ask those questions. And it has the answers, right? And it can answer them in natural language. So in essence, it's like having an assistant who was at the session and memorized every single word that was said, and have that assistant available to you, 24/7, to answer any questions you have about any of the sessions. So to me, that's really, really powerful. And increasingly, you can imagine being able to query across the sessions, right? So like, the subject of growth came up several times, like, what were the some of the key strategies that came up over several terms, and who mentioned each of them. So you can ask it really interesting and subtle questions about what we've been learning and engage with a dialogue with the actual material. And then we'll give you the quotes, right, it'll say, Oh, that was in session, whatever. And it happened at this time, and this person said this, and then you can go back to the other notes when you go back to the actual recording. So that I think is really helpful. And our experiments are really promising with with that. And I think people found participants that I spoke with about this found that that was useful to have, and again, anyone can put in any query they want. So it's flexible and open ended, that at the moment has been free as well, which is really, really great. And you can even tune it now. So you can say you want its summary to be a little bit more creative or a little bit like more exacting, you can sort of give it a little bit of flexibility. In its next phase, one of the things that tool creator is doing is actually giving it license to be even more proactive. So it could follow up a session by saying in this live session, these five topics came up here are three related pieces that have been published recently on this topic and two other frameworks that might be useful, and sort of like allowing the AI to do some research, following up on the live sessions to give you supplemental information that you could then either use or not use. So that's that's one thing. There's several other tools like that, that have been helpful for summaries. supranormal.com is one we've used for summaries, which has really been great. I like the quality of the summaries. And you can customize the format and the headings that it uses. We've used one called blocks, dot app, B L, okay, s dot app, which is one I recommend, because you don't have to invite it to the meeting. So it just operates on your desktop. And you can use it to record any session on any topic. And just as a side note, I actually was at a couple of conferences recently and use that app to summarize the sessions I was in so that I could just kind of be focused on listening. And thinking about what people were saying and knowing that I would have the full transcript and the summary via the AI app. That was quite handy. So all of these are AI tools we've been using, as part of the program, we haven't gotten into having AI generating lots of material or content for us, because we still obviously are human lead and the humanity of our connections with one another is is really important and valuable. We are thinking about using tools for connecting people, for example, based on their interests. So there's a tool called intros.ai that we're experimenting with that will help introduce people in our network and our alumni network to one another based on their interests and their preferences and their objectives. So AI can be helpful in matching people in that way. So that's one example that we're experimenting with. But I'm excited about this next phase because Now we have a lot of potential new ways to apply AI for teaching.

Nikita Roy  35:05  
That's really exciting and amazing to see how AI can be transforming that entire learning experience. I started trying blocks dot app after your recommendation, and every single meeting, getting all the transcript and all the key takeaways that you were sending me in emails. And so that prompted me to download blocks that up and that soon become my favorite app right now, as well. Thanks to that 4149 Ai, it's still on a waitlist. So I'm still stuck on the waitlist. And hopefully soon, I get to try out all of those features that we've been talking about. So I'm excited about that. And kind of switching into journalism education, but also in light of all of the changes that we've been seeing. How are you envisioning journalism education, evolving to better prepare students, and people who are trying to build their ventures, right now in this increasingly AI driven era? Like, what are they supposed to be keeping in mind?

Jeremy Caplan  36:01  
Well, I think one thing that the AI allows us to do, which can be helpful is to customize and personalize more efficiently some of the materials we're creating or could create. So for example, we've had people from 37 different countries and last couple of years, and they all have been terrific about speaking English and understanding English to be in the program, but many of them have another native language. And they might prefer having some materials available in that native language. And they might, for example, benefit from having examples of certain ideas that we talked about, and certain frameworks presented either in their own language or in relevant cultural contexts. And so I can envision AI being used in some cases to create adaptive materials that are really customized for a particular scenario, or use case or cultural context or language context, so that people have, you know, the shared set of materials, but then they also might have some supplemental materials that might be more relatable in certain cases, or might include examples that are closer to their particular context, like the kind of project they're working on the language they're working in the cultural and geographic location they're in. So that's one thing I'm looking ahead to, I think in terms of productivity, you know, as independent creators and journalists, there's so many different kinds of things that we have to do on a daily basis, right from gathering information, synthesizing information, organizing information, sharing information with other people putting information onto social platforms to distribute the information, I'm drawing connections between different things that we're working on in our notes, or in different interviews that we've conducted, or different research papers that we're reading and gathering, looking for new material that we don't even haven't even started reading yet, we're just identifying new potential sources, either people or papers or other information out there. And AI can be helpful with a lot of those tasks, because it can do that kind of menial manual work really quickly. And then we always can act as the final arbiter, right? It's not that, again, AI is doing and thing for us, it's kind of helping us along with the menial components of the task. So we use a lot of labor saving devices, you know, all the time with washing machines, and microwaves and dishwashers, and so on. And I think the AI can be helpful with the kinds of manual tasks that just would take longer by hand. So, for example, as a reporter, we're looking at spreadsheets and looking at 1000s of rows and columns and looking for outliers in the data, right. And pretty soon, we'll be able to just normally just query for those and have a identify those outlying cells or columns or rows, that we can quickly take a look at. Right? It's not that it's going to make a final decision for us, it's just going to direct our eye to something we might want to have a look at. Similarly, we can direct AI to look at our notes and the hundreds of people that we've spoken with recently and identify, you know, which of them we're talking about, I don't know geothermal energy, when we had conversations with them, because now we're collecting some string on a new potential story, right? Today, I can do that really quickly. Whereas if we went back through our notes, I don't know about you. But if I went back through my notes manually, that would take me hours, to go through all of that and find those specific mentions. Because we're not just looking for keywords. That's the thing, like people may word things differently or talk about them in different ways. So it's not just like running a search for a keyword, it's actually kind of using the intelligence to understand the context of the sentences and the conversations that we've had. So I consider AI as a kind of an assistant, a digital assistant that will help us speed up the menial parts of our work throughout the journalism workflow.

Nikita Roy  39:34  
That's exciting. And I think we've been talking a lot about the future in terms of what AI can be doing for us throughout this entire episode. And with everything, all of the different tools to just wrap up this entire conversation. I really want to know more about your perspective on what do you think as an industry at large, what advice do you have to join us and what steps do you think we should be taking right now to kind of stay competitive and be Be a part of this AI revolution,

Jeremy Caplan  40:02  
I think we should all have a core part of what we do be time devoted to learning and experimentation. So if you are working in a newsroom, and you are tasked with, you know, writing three stories a day, as I know, from some of my former students have had to do, and you are chasing deadlines, you know, day after day, it's hard to have time to sit down and say, Okay, how could I actually reorganize my workflow so that I'm not just a little more efficient once but consistently, more efficient on a particular task or type of work regularly every day, because those are games that are going to open up a 10x improvement in your workflow in terms of how enjoyable it is to work on something and how efficient it is to work on something. But in order to open up that 10x improvement and benefit, there has to be that little investment upfront, in terms of understanding how this thing works, why it's useful, when to use it, what some of the red flags are, or when it might not be the appropriate thing to use. And I think we need to carve out space for that within newsrooms, and within whatever kind of work we're doing. And it's hard to do, right? Because it's one of those things that's important, but not necessarily urgent or doesn't feel urgent, feels like it might be useful, but it doesn't feel as urgent as the deadline that's confronting us today. Right. And so that's what I think we need to open up space for. And I think part of that is creating a culture where that's just part of what we do, right. So we have a sandbox launch every week, where we talk about things, right, and we experiment with things, or we have a monthly training session where we get together and see how someone is doing something really cool and useful. And these can be spark shops, right? Spark workshops, where there's 15 minutes, right, it doesn't have to be that we devote many hours to this, but I think we have to prioritize it. And the experimentation does require a little bit of an open mind and openness to trying things that we're not necessarily good at right away, or we don't understand right away, we have to be comfortable with that discomfort a little bit. And trying out something like AI tools that take care of some of the meaningful work may not always yield instant perfection, right? So people love to share online examples of AI kind of miss misfiring, or you know, what, whatever doing a bad summary or something like that will happen, just like it happens with any any tool. But we have to push past that and identify, Okay, well, this is where it's really useful. This is a use case where I could actually make use of it regularly. And this is a way that I'm going to incorporate it into my workflow. So I think that's something that we can do and the industry is to carve some more space for that. It's essentially, again, focusing on the important and not just the urgent,

Nikita Roy  42:33  
those are some ways where it's there focus on the important and not the urgent and have a space for us to navigate this world of AI that might seem daunting, but kind of at the right mindset and tools, we could be able to embrace it to be more productive. And I have learned so much just from talking with you today. And once again, I felt like it was a life wonder tool session that I got. And thank you so much for your time and insights. And joining me on newsroom robots.

Jeremy Caplan  43:00  
It's a pleasure. And I learned from you all the time as well. And I'm learning from so many people who are doing this experimentation. One of the exciting things is there's so much happening in public people are sharing their prompts. They're sharing their ideas, they're sharing their examples, and we can all learn from each other and keep experimenting and the tools keep changing so quickly, that we can avoid having to relearn over and over.

Nikita Roy  43:21  
Yes, it's going to be a time of learning and experimenting throughout this entire time. So thank you so much, Jeremy.

Jeremy Caplan  43:26  
You're welcome. Thank you.

Nikita Roy  43:29  
That was Jeremy Caplan, the Director of Teaching and Learning at the Newmark Graduate School of Journalism at the City University of New York. This podcast is made possible thanks to the Harvard Innovation Lab spa grant. I'm Nikita Roy, and this is newsroom robots.

"
newsroom_robots,19,"Wed, 09 Aug 2023 23:56:27 GMT",Scott Brodbeck: Early Experiments with Generative AI in Local News & Lessons Learned,https://shows.acast.com/newsroomrobots/episodes/scott-brodbeck-experiments-lessons-generative-ai-local-news,"<p>Scott Brodbeck joins Nikita Roy to discuss his experiments using generative AI in his local newsroom, from creating completely AI-generated newsletters and AI-generated videos to ad copy and back-office support. He also shares his views for other small newsrooms looking to experiment with AI.&nbsp;</p><br /><p><br /></p><p>Scott is the founder and CEO of Local News Now, which owns and operates three hyperlocal news websites in the United States, covering the Northern Virginia region. A former TV news writer and producer, Scott was also a founding board member of the Local Independent Online News Publishers (LION).</p><br /><p><br /></p><p>Tune in to hear about Scott’s early experiments with generative AI in his newsroom.&nbsp;</p><br /><p><br /></p><p>Thoughts or questions? You can reach us <a href=""https://forms.gle/egyJZDsGjogiyNTH8"" rel=""noopener noreferrer"" target=""_blank""><strong>here</strong></a>.</p><br /><p><br /></p><br /><hr /><p style=""color: grey; font-size: 0.75em;""> Hosted on Acast. See <a href=""https://acast.com/privacy"" rel=""noopener noreferrer"" style=""color: grey;"" target=""_blank"">acast.com/privacy</a> for more information.</p>","Nikita Roy  0:00  
Hi, Scott, welcome to newsroom robots. I'm really excited to talk all about local news and AI and what you've been up to today.

Scott Brodbeck  0:08  
Looking forward to talking about it. Thanks for having me on.

Nikita Roy  0:12  
So, Scott, before we delve deeper into our discussion and talk all about your Hyperloop hyperlocal newsroom in Virginia, I want to kick things off by getting started about your background and about your company, local news now and where you are in your AI journey right now.

Scott Brodbeck  0:32  
Sure, so the background on the company is I worked in television news for a few years out of college, and the great recession hit, I lost my job. And I kind of saw the volatility of the news business and had a desire to to get more involved in the on the business side and kind of create my own luck, as this, you know, long term shift from traditional media to digital media was taking place. And so Wow, out of out of work I studied for the GMAT, I ended up getting an MBA at Georgetown, part time rejoin the workforce, for NBC for what one of our local stations here in DC. And at some point, I realized that I was never seen the sun because I was going to class at night, working overnights at NBC four and then go to sleep. And I said, you know, the future needs to come sooner for me, so I left that job. And I was going to go work for I was hoping to go work for Jim Brady, who was launching tbd.com At that point, which was this local news venture he did with Allbritton. One of the local TV stations here and one of the other local TV stations. But he was taking a little while to launch it. And I decided kind of on a whim that I was just going to launch a website for Arlington worth living. Because there wasn't a time there was like a weekly paper, but it only reached certain households and some of the more affluent areas. And I launched the site, January 2010 On a whim, fast forward like a year later. And it's going pretty well. And people are approaching me about advertising, which is good because I launched it without kind of much of a business plan other than just gonna go out and do this. But people were reading, then people wanted to advertise and eventually, an actual business formed. And now we 13 years later, we're a 10 person company, we're actually bringing a 10th on board in the next few weeks. We have three sites that we owned and operated in a row now, which is the original that serves Arlington, Virginia, and then sites covering Alexandria, Virginia, and Fairfax County. And we also partner with some other publishers. So pop Phil is one of our partners at the site that covers neighborhood happenings in DC, and then Potomac local, which covers local news, a little further south in Northern Virginia, Prince William and Stafford counties.

Nikita Roy  3:18  
Yeah, and you made headlines with the Nieman lab with your experiments that you've been doing with generative AI. So I kind of want to delve into how you've been seeing and experimenting with generative AI in your newsroom now a decade later of starting it.

Scott Brodbeck  3:35  
Yeah, so, you know, it's funny, I'm usually a very slow follower on trends. I remember, when Groupon was really big, and every news company was trying to go after daily deals, our friends can net over and Tyson's had something called deal check. And it was a weird time. And I was you know, I've always been one to not follow some hot trend just because everyone else is doing it. But generative AI in the advent of chat GPT was different. And, you know, I immediately saw this, this was something that was gonna have a ton of utility for publishers and that we would have to be on top of so you know, I immediately got on chat GPT started experimenting with stuff posted some some novelty articles, you know, had had had it write some, some weird poems about Arlington and whatnot, you know, rhymes. Those are, though were novelties. You know, it's not something that that we're going to be able to do day in and day out. And it was pretty clear early on that it was also not a reliable platform at this point for original work. So I had to generate, you know, give me a list of the top 10 Best ranked restaurants in Arlington and some of them were real, and some of them were totally made up. And none of them were based on actual ranking. As far as I could tell, you know, likewise, you know, other lists and things I had to generate, there was just some stuff that just wasn't true. And so that when when you're a local news business, you have a brand and that brand, you know, the brand values based on trust with readers and being authentically local. And thus, posting stuff, just straight from Chachi PT that's made up, not going to cut it on, but what I kind of figured out was that and others have figured this out too, is that it's actually pretty good at summarizing stuff, if you feed your original articles into it that you know, that people paid reporters have written, you feed that into it, it could generate some pretty pretty good summaries and and with the right prompts, it could be do different types of summaries. So everything from bullet points to you know, in this style of morning brew or Axios. And, and that, I saw that that could could solve some problems for us. You know, we have a afternoon newsletter, that that's basically just links to articles, we don't have a morning newsletter, and we don't have anything that's more voice, it's just, you know, when you when you're our size, you have to prioritize what you're spending your time on. And we want to spend most of our time on the editorial side on doing original recording, you know, uncovering local stories that other people are not reporting on or haven't reported on in as great of a depth as we've been doing. That's where we add value. That's where we bring value to our readers. So spending a few hours not reporting news, and instead writing a morning newsletter just based on summaries of our own work, probably not the best use of time. But if we could have a I do that, and do so in a way that's, you know, somewhat engaging and not a bad read. That was attractive. And so the Nieman lab article was about our efforts there, they they've advanced a bit further since then, we've figured out the one of the trickiest things wasn't the AI, it was actually just the email formatting of how to get to work, the formatting that appear consistent across desktop and mobile. So I think we've pretty much got that one fixed and the product, the email product is pretty close to being ready to release without the experimental label that we currently put on it.

Nikita Roy  7:33  
So how does it work currently, because like when we talk about local news, as you were saying, Is that close knit community where the newsroom really understands that reader, and now when you're bringing generative AI adds a whole new dimension to how local news can really be delivered? And can you talk more about how the tools that you're using to kind of generate this AI newsletter and what's really driving it behind?

Scott Brodbeck  7:58  
Sure. So the another initiative that I've been doing kind of concurrent with our AI work is no code automations. So I'm not, I'm not a coder. I couldn't, you know, write JavaScript code or C++ code. But I do kind of generally know how technology works and how to how to link tools together. So we use something called Zapier, which is a note code platform to link together RSS feeds and to to airtable, which is a database solution, and then link that then to chat GPT to generate summaries from the articles that come out of our RSS feed. And then that in turn, can go to MailChimp our email platform and go out it's the newsletter. That's kind of the simple, simplified way to put it. In this, this kind of work with the no code automations has also brought some other AI use cases to light for us. So in our newsletter, we put links to events, and we have the AI right now choosing an emoji that's appropriate for each event. To make it a little easier to browse for readers. We also have the the the AI helping to reformat some material outside material we get this is mostly on the advertising side of things. But rather than manually having someone go in and have to reformat a post submission that kind of had some weird HTML stuff going on with it, the AI can be asked to do that and does it pretty well. So we've we've found some use cases they're not. One thing you'll note here is that these use cases or not go out and report a story. For me. That is not a capability that the AI currently has. I think, you know from what I've seen, I think it's going to take a little while to get there. You know, we'll probably get to a point soon where we can feel a little more comfortable feeding in a press release and having it write off a press release with a little bit of context based on things we've previously published. That that context layer is something that's hard for me to do myself in, in the no code automation here. But I do think that tools that can do that are coming down the pike. And that could give us another AI use case. But it's again, something that it's a nice to have, it's not like a must have it's it's not going to replace the reporters who are going out in reporting stories and know deeply a community and what we published before in the context of it, and why it's interesting to people. You know, that is something that I don't see going away in the next 10 years. And well, I will say there's a lot of advancement in AI happening, but so that last call it 9% of the way there is, is really tough, I think for the folks who are developing this.

Nikita Roy  11:10  
Yeah. And talking about the AI right now you're using GPT. quite interested in knowing how you went about dealing with the prompt engineering of creating an entire newsletter. Does it sound repetitive? cringy? What's been the experience? What's the experiment been like?

Scott Brodbeck  11:28  
Yeah, so we had an issue early on, where I asked it to write an introduction to the email newsletter, and just base it on the weather forecast for the next day, to make it kind of fresh and original. And also to, I asked it to take a look at whether the day the date corresponds with the holiday. So if we're approaching Christmas, or something like that Fourth of July, maybe it'll make a reference to that. And the, the early iterations of that were incredibly repetitive with just like, continuously referenced Christmas. And it wrote, like it was, you know, just got done reading all of Gary V's books, and it was just very effusive and kind of cringy. I like it, by the way, but it, you know, people out there will probably, some people know what I'm talking about here. Yeah, it was just very, like, not not a tone that I really wanted to go to. I wanted it to be voiced, but not over the top. And like it was. So it's required some of what people have been generously calling prompt engineering, I call just like writing for the prompt of tweaking it to the point where it's now toned down. It's still a little bit on the on the cream side, and sometimes with its choice of emoji and whatever, but maybe that's just my own taste for dryness, you know, it would fit right in on on an Instagram feed, probably.

Nikita Roy  13:05  
Okay, and currently, it's what I understand is it's completely AI generated, and it's not really having an editor that reviewing it before publication. So like, how concerned are you about, like, the accuracy and reliability issues when using generative AI?

Scott Brodbeck  13:23  
Yeah, so, you know, again, the state of the art here is a little early, and we're utilizing the API's through a no code. tool. So it's a bit of a it's a bit rickety. It's a bit of a, you know, machine. I'm sorry, if you can give me an edit point here. I'm trying to remember that the name of what's it called? A what's the name of the machine? That's just like overly complex?

Rule Rube Goldberg? Okay. Yeah. I probably can't even you know what? Yeah, sorry, if you could give me that. That question. Again. I might not even reference the machine because I'm gonna screw up the pronunciation. But yeah, if you don't mind.

Nikita Roy  14:30  
Yeah, sure. Give me the question. It was about accuracy and reliability. Right. So. So as I understand it, currently, the newsletter is completely AI generated, and there is no human editorial input that goes into it before publication. So how concerned are you and how are you addressing all of the issues of accuracy and reliability of all this content that's being produced with TBT?

Scott Brodbeck  14:57  
Yeah, so right now is It's pretty clearly labeled as an experimental newsletter, which gives us a little more leeway to make mistakes. I think we haven't fully released it to the, to our readers, you know, we've advertised it. But we have not said like, you know, this is our morning newsletter, we've said, This is a weird AI experiment, and you can get it if you want. And so we have some, some hardcore early adopters getting it and hopefully, they're tolerant of the occasional mistake. So yeah, the state of the art here is a little early on AI. And we're using the API's through a no code automation tool, which makes it even more rickety. And, you know, on top of that, we're doing a bunch of different calls to the API to generate parts of this newsletter separately. So every time we publish an article, it creates three different types of summaries, one of which will later be used for the newsletter. On top of that, we then ask it to create summaries of the summaries. for use as the subject line and the introduction to the email, we want it to list like three bullet points of okay, here are the stories you're going to get to see, you know, read when we get through this email. It's quite similar to some of the major newsletters out there in the way it's formatted. And that was somewhat deliberate. You know, if it's working for them, it could very well work for us. I'm not trying to reinvent the wheel too much here. But yeah, there's a lot of complexity. And we've found errors in you know, whether those errors are sometimes they're the result of just chat GPT weirdness in consider inconsistency. Other times, it might be something on our end. For instance, we, for a while the summaries we generated were what we we had it commit to memory, the discussion that we were calling through the API. And so we had to summarize the gave it the article, so summarize it this way. And then, you know, we made the next call, just a addition to that conversation, you know, summarize it this other way? Well, what we found was that sometimes the chat GPP would take a little longer to generate one than the other. And as a result, it was we were essentially asking it to generate based on a the article that had not fully processed in the previous step. And so it would just totally hallucinate, just like whatever it thought was an prototypical Arlington story with with no other other input. And so you got these, like, made up stories that seemed feasible. But they they were not, they were just totally made up whole cloth. And so it made it that was not ideal, to say the least. So we had to call it a different way, feed it the the article, same with each step. It's those kind of learnings, that kind of debugging that that's taking place. And there's no playbook for this, you know, no one else is my knowledge writing about their their efforts to do what we're trying to do here. And so that, you know, it's even still, like, we had an issue today, where we fed it, the summaries of the summary. Or we've bedded the summaries of the articles in the, in the newsletter and said, Okay, come up with the bullet points in the subject line, and it just ignored it and came up with its own made up thing again, and I have no, I couldn't tell you why I really couldn't. So where's this all leading, this is all leading up to saying that there will need to be some human intervention here. Once we launch it more widely, there will have to be an editing step right now, I do have a built in where an initial newsletter will go out, that can be reviewed. And then we can go out and edit the email that's generated. But it's not like a process we've worked in with our staff. And if we're going to really make this work, we're going to have to have to do that. Unfortunately, it would be really nice if we could just totally automate the whole thing that anytime you build in a step where someone has to do something at a certain time, every day, you know that you get enough things like that, and it becomes hard, you start feeling a little overloaded. And I the ideal for me here was if the AI could just operate autonomously, but based on what I'm seeing right now, I don't think that's quite the case. I think that Elise needs to be a review step but we have had some newsletters that I would say are pretty well done. And when we've surveyed the early adopters who are getting it, they've been positive about the writing and the accuracy. So there are encouraging signs, but they're also the frustrations that we're gonna have to address going forward.

Nikita Roy  20:18  
And how does your audience feel about getting a completely AI generated content?

Scott Brodbeck  20:24  
You know, the people who have signed up for it have signed up like very eyes wide open. So we haven't gotten feedback from a wider audience on this. I think what we saw in the comments, and we have a very active comment section on arrow now was some trepidation. People asking, why don't if this is so important, why don't you just do it yourselves. And, you know, I jumped in there and explained that the situation we're in where we have a limited staff, and we need to prioritize our time. And I didn't Don't think that summarizing our own work is necessarily the best use of that time. And I think people were understanding, you know, there's a lot of hand wringing around AI and its role in journalism. And my thought on this is that readers are probably going to, by and large, be accepting of it, you know, as long as the output is something that is reliable and accurate, and written in a way that's engaging enough to be a decent read. I don't think readers ultimately are going to care that much they they have a goal that is independent of you know, how something gets written.

Nikita Roy  21:44  
Yeah. And with the current format that it's been generated in, and how so how are your editors? If the question would be if you were to, if you were to release this as, as if you release this and launched this newsletter, with the current format, and the generation that GPT is doing, how much time do you think your reporters would require to make this publish, publishable and accurate enough? Do you think it helps you generate, like a good first draft and reduces your time there? Or it still requires a lot of reworking?

Scott Brodbeck  22:25  
Yeah, so the email is it, there's not a ton of rewriting that needs to be done for the email, from what I've seen. If if we're talking about, you know, trying to get chat GPT, to write articles for publication on the site, then there's a lot of work that needs to be done to get those up to what we would consider publication quality for us. Sometimes it's not too bad. If if the subject is simple enough, and the input is pretty solid, in terms of like a press release, or whatever. But but most of the times that I kind of feel, it's not worth the effort. Because our reporters can, if it's simple enough for the AI to handle it, it's simple enough for a reporter to, to just crank out in like 1015 minutes and do so in a way that's going to be more engaging and informative for our readers. Generally, I don't think that's always going to be the case. And I don't think that, that people in this industry should have that as a takeaway, that that AI is going to always kind of remain in their current state or something near it, I do think it'll, it'll get better. And once you have an ability to pull in material from your own archives, to use as reference material, both in terms of writing style, and, you know, linking back to previous stories, then I think, I think it starts getting, you know, a lot more interesting, it's still not going to be able to tackle a complex, you know, city council or county board type story that requires going to a meeting talking to people, it's not going to do that. But if for stories that are a little more straightforward in terms of source material, I do think it'll have a get to the point where you'll get mostly publication where the stories that only need to be lightly edited, and, you know, actually do connect with readers. But there's gonna be a right way to go about it and a wrong way, you know, there's going to be, I'm sure that some people are going to try to go down the easy path. Let's just have this do everything for us, or, you know, crank out a whole bunch of low value content. And the fact of the matter is, on the internet, yeah, you know, there are the SEO, Content farms and whatnot where you can get away with low value content, but I think in local News, there's a higher bar, because you have a, you have a smaller target audience, right, you have a geographically constrained target audience. And local news is going to work as a as a business online, only if you engage a very substantial portion of that audience. And the way you do that is by really producing good work and covering stories that are important to the lives of readers in a way that's engaging and gives them the information that they need to form opinions and discuss it with their friends. That the AI, I just don't think it's going to reliably do that for the kind of range of stories you do, and local news, I think it'll fill some gaps. And there will be an advancement, and it'll exceed where a lot of people think it could go. But I also think that just in general, humans, like hearing from other humans, and you know, the robot, that it's going to be obvious, I think that AI is going to put higher value on human produced work and creativity. And, you know, if you want to get that critical mass of an audience, in local, you're going to have to do human things. The robots are not going to, you know, solve the local news crisis alone.

Nikita Roy  26:25  
Yeah. And what I'm really hearing is kind of diversification of content seems to be where AI could really help in terms of just being able to repurpose your news and your content for other platforms. And that's how you've been exploring AI and thinking about AI in your newsroom. So can you talk about more in terms of like, what your newsroom is specifically doing other than the newsletters with AI and helping produce content that way?

Scott Brodbeck  26:52  
Yeah. So So again, you know, our, our newsroom, our staff, very focused on finding stories, and reporting original stories. Serving our readers and being a comprehensive local news source. But we're less focused on right now is how can we take this raw material of, you know, newsletter, news articles, rather, written by humans, edited by humans, and put, put it into different forms that connect to readers in different ways. So the morning newsletter that we talked about, that's, that's one additional channel by which we were hoping to reach even more readers with the same, you know, reporting output. But I think that there are going to be additional opportunities, especially as it relates to multimedia. So now I've, excuse me, I've looked into whether we could have aI generated content, work together with automations, to put together videos for us, and for uploads to YouTube. So this these these news summaries were doing in the email newsletter, you know, could they be remixed further, so as to be narrated by an AI generated voice, and made into a video that utilizes photos that are articles used? I think that'd be pretty cool. I bet some people would like to consume news in that way, not enough people to get us to do that ourselves by hand and use utilize that extra time. But you know, with a AI output with a very low Variable Cost of few pennies that could be worthwhile and again, reach readers in a different way. Give us another channel by which we can be can engage readers and be discovered by by people out there. Unfortunately, the no code automations right now, we kind of hit some dead ends in terms of making this work in a way that doesn't totally suck. But I think that it that these possibilities, you know, some people at some point, the vendor ecosystem out there, the tech tech companies out there, I think are going to probably figure out stuff like this, and would not surprise me if in a few years, something like that off the shelf gets made and becomes another way we we take advantage of this this news content we're already generating.

Nikita Roy  29:33  
Yeah, and I'm just curious what, why saturation tools and video generation tools were you looking at?

Scott Brodbeck  29:41  
So there was something called shot stack, which is a works with Zapier to kind of put together videos. Amazon Pali is a through AWS is a text to speech Engine, there are other text to speech engines, but they don't work with Zapier. At least not yet not that I saw. So, you know, once some of these tools mature and maybe you know, have more extensibility into Zapier and other platforms like that, I can see us homebrewing some more cool stuff for which we can use the AI. But right now, I think we're in a place where we've kind of, I've kind of reached the endpoint of the use cases, at least with the current level of brainstorming. You know, there might be more ways we can use it and other channels by which we can put it to work. For instance, we have a Facebook group that's kind of not in use right now. Of like, 20,000 people interested in Northern Virginia news, and I never know what to do with it. So do we use the AI to help generate content for that, you know, news summaries or something? Maybe? I don't know. It could be I don't know the exact approach we would take. But in terms of like the low hanging fruit? I think we I think we've kind of what we've discussed here is, is it for now.

Nikita Roy  31:23  
Yeah. And as you've been saying, small newsrooms, you're facing resource constraints offering on like a shoestring budget, really, an AI seems to be opening up some new, hopefully doors for reaching audience. So what's your take for other small newsrooms? who are looking to use AI? What should they be keeping in mind while entering into the space?

Scott Brodbeck  31:49  
I think one thing to keep in mind here is that building it yourself is totally possible. And, you know, if you have strong data, that could definitely be worth it. For others, you know, maybe the slow follow route here is the best one, where let's, let's kind of wait and see what's built around AI, the specific applicability to newsrooms, because if you, if you go out and invest too much in creating AI tools that are custom to your newsroom, I think you might find down the road that actually those were already being built, and probably built better than how you were able to do it yourself. So it's, it's definitely worthy of experimentation. It's definitely worthy of building out some custom stuff when it's of high value and not a high value in terms of the output and not a ton of cost to do so. But just know that that every, it seems like every VC in the valley is just throwing tons of money at every AI use case, and company that you can find. So a whole bunch of stuff is on the way. And I think assuming that the way things are is it's going to remain generally the same is would be a mistake and and be prepared for more stuff to come down that very well could be disruptive, or could make stuff you've built totally outdated.

Nikita Roy  33:25  
Yeah, and talking about disruption. And you've been innovating with AI in this space and an early experimenter and adopters. So I want to hear more about to wrap up really looking ahead, kind of the possibilities seem endless. And so what do you see the future of AI playing in local journalism, especially in content creation, and distribution?

Scott Brodbeck  33:50  
Yeah, so I do think that we will get more and better tools for utilizing your content archives to tune the AI output, that's gonna, that's going to come in and that's going to really up the level of what the generative AI can can can create for, for publication. So I'm just kind of like waiting on that to happen before. Excuse me doing more of that. I think on the visual side, it's going to be very interesting to see how AI might take some visuals for a story and turn it into something even better. So let's say we have a gallery of five photos, could AI take those and make an even more compelling animation or video or something out of that? That kind of upped the game in terms of I know, maybe there's a there's a time in the not too distant future where just throwing a photo or a small gallery on a page is not going to be enough for you Isn't what AI can do. So you know, that's another thing to be prepared for. I've been doing a lot of thinking about, you know, this social social media right now. And, you know, multimedia, because I think that texts on page is going to be something that is to some degree devalued by AI, right? You're gonna get a lot more text based content that's AI driven on the internet. And while that might not be specifically, disruptive to local news, I think it's harder to do. So for local where there are fewer sources of data from what you can pull easily for AI applications. I do think that overall the internet is going to grow with with all this AI content, and there's a good chance that the ad rates you get keep going down and, and the ability to pull people out from search engines will will be become harder, as there's more content. And as Google tries to give people more answers right on the search engine, rather than directing them to pages. So the hedge to that is, how can we do more on multimedia? How can we connect with people in a more engaging way? Through our reporters and editors having conversations? How can we do more conversational stuff, engaging stuff on social media that that maybe doesn't rely on people to click a link to go to your site, but you still get some sort of a brand and audience and business advantage from it. I do think AI could could play a role here. It's might it maybe it's a kind of a bank shot where it's indirect, for instance, you know, I want to launch a podcast, a new podcast, where it's me and my reporters talking about some of the local news stories of the week. Well, there's a lot of prep work that goes into that, right. But what if we can have the AI, kind of pick the stories that he thinks are going to be the most engaging, and then create some questions, create a little script, and save that, that 15 to 30 minutes that I would have otherwise have spent. That that could be a very valid valid use case where, you know, it's not ultimately showing up directly on the page or on the screen. But it's saving enough time that it makes things like that more possible. And when you're in a short staffed situation, like local news, where you have one, two or three people per site, we have about two people per site with a little little extra freelance help on the side. That saving those 30 minutes, it's actually quite valuable. So yeah, I think AI applications will be what, there will be the stuff you see, and there will be the stuff you don't see. And maybe it's a little harder to think about now, but will become obvious as we get further down the road of like, okay, well, you know, here, here's something where it is saving time, and allowing this to do stuff that we otherwise would be time constrained or otherwise resource constrained from doing.

Nikita Roy  38:12  
Yeah. And it's the sentiment I agree with you. I mean, textual based content is going to be everywhere. And what's really going to set local news apart is that connection that we have to readers and getting into the community there. So I really like the way you've brought up some use cases and help brainstorm in terms of like what we could be doing with AI throughout this entire conversation. And thank you so much for joining us, Scott. It's really exciting to see how you've been experimenting with AI. And I'm really excited to see how the local news landscape and how you'll be kind of pioneering with the experiments you're doing there.

Scott Brodbeck  38:50  
Thank you for having me. This was a fun discussion. It would be really fun to see how this whole space evolves over the next few years. I think there's gonna be a lot coming down the pike that we're not expecting.

Nikita Roy  39:01  
Yeah. Okay. Thanks, Scott. Okay. And can you just say your name for me just before I hit stop record?

Scott Brodbeck  39:12  
Sure. It's Scott Brodbeck.

Nikita Roy  39:15  
Scott brought back Okay. Scott brought back. I said that correctly, right. Yeah. And so can you tell me more about how you've been experimenting with different ways and like chatbots and sort of back office items?

Scott Brodbeck  39:30  
Yeah. So we are doing some some things on the business side. I will preface this by saying that they're there. It's pretty nascent, and people aren't necessarily using it that much at this point, but I created an AI chatbot through Zapier, Zapier has a chat bot functionality that's in beta right now. Where are our sponsor content clients so the advertisers who booked sponsor content with us can use the chat bot to query A sponsored article and the Chatbot is tuned to create it in such a way where it it's kind of a the length and format that we think is going to be effective for the clients. In many cases, I would say that the Chatbot would create a sponsored article for the client that's more effective than what they would otherwise send us. Keep in mind that a lot of our clients are smaller businesses that are small to medium sized businesses that maybe don't have a time to invest in iterating around their sponsor content on our site. But that's one example. It's, again, it hasn't been really been used. I think that whole AI thing is still scaring some people away. But it exists. And it works. And it's something that I could see gaining more use down the line. And we've we've looked into other other AI use cases, help our business team on the advertising side, it brainstorms social posts for sponsor content, it'll slack it out, put it in Slack. And we can just copy and paste one of the three potential social posts it generates. Sometimes we use it sometimes we don't. Some of them are good, some of them not too good. But that's another one where it's just helping us with our creativity, or finding ways to save time. But yeah, you know, it's not just the editorial side, it's the business side as well. They're going to be definite applications. And I'm hoping to do a little more to to help us streamline processes or maybe connect with clients. A little a little better, you know, for instance, helping compose emails to clients that aren't as formulaic. You know, maybe giving us a little little intro that talks about the weather or something. I don't know. We haven't done that yet. For the record. But bunch of possibilities out there.

Nikita Roy  41:55  
Yeah. Okay.

"
newsroom_robots,18,"Thu, 03 Aug 2023 18:12:05 GMT","Elite Truong: From The Washington Post to American Press Institute, Leading AI Innovation in Newsrooms (Part Two)",https://shows.acast.com/newsroomrobots/episodes/elite-truong-from-the-washington-post-to-american-press-inst,"<p>In the second part of this episode with Elite Truong, she shares her work leading AI products like <a href=""https://metricsfornews.com/"" rel=""noopener noreferrer"" target=""_blank"">Metrics for News</a> and <a href=""https://sourcematters.com/"" rel=""noopener noreferrer"" target=""_blank"">Source Matters</a> at the American Press Institute for local newsrooms.&nbsp;</p><br /><p><br /></p><p>She shares how AI can help local news and her advice for product managers looking to incorporate emerging tech, like generative AI.</p><br /><p><br /></p><p>Elite is the Vice President of Product Strategy at the American Press Institute. Formerly, she was the Director of Strategic Initiatives at The Washington Post. In the first part of the episode, she discussed her experience working on emerging technologies.&nbsp;</p><br /><p><br /></p><p>Before joining The Post, Elite spent four years at Vox Media, three as the product manager for off-platform storytelling, primarily negotiating with tech platforms to create user experiences that benefited news consumers. She serves as the Board Secretary for the News Product Alliance and is on the advisory board for Democracy Day.</p><br /><p><br /></p><p>Tune in for the second part of this episode with Elite and hear about her current work at The American Press Institute.&nbsp;</p><br /><p><br /></p><p>Thoughts or questions? You can reach us <a href=""https://forms.gle/egyJZDsGjogiyNTH8"" rel=""noopener noreferrer"" target=""_blank""><strong>here</strong></a>.</p><p><br /></p><br /><hr /><p style=""color: grey; font-size: 0.75em;""> Hosted on Acast. See <a href=""https://acast.com/privacy"" rel=""noopener noreferrer"" style=""color: grey;"" target=""_blank"">acast.com/privacy</a> for more information.</p>","Nikita Roy  0:02  
This is newsroom robots, the Podcast where we explore the intersection of artificial intelligence and the news industry. I'm Nikita Roy, a data scientist, media entrepreneur, and one of the many founders currently building their ventures at the Harvard innovation labs. On the newsroom robots. I'm excited to bring you insightful conversations with industry experts about how AI is impacting the way we do journalism. This is part two of my conversation with Elijah trunk, the Vice President of Product Strategy at the American Press Institute. In the first part, we discuss elides experience working on AI products at the Washington Post, where she was the Director of Strategic Initiatives. He led spoke about working on heliograph, the robot reporter at The Washington Post, we heard about how she and her team developed Claire, an AI voice assistant. That was the third iteration of heliograph, Claire was given the persona of a woman in her 30s and was designed with a voice using Microsoft's AI technology. This AI bot generated flexible audio snippets with election updates based on the status of local election results and tailored it to the listeners location. These snippets all read by Claire will automatically inserted into the posts political podcast, Elon shared how this approach provided a more engaging and personalized way to present election data to audience. She also shared an interesting product use case she had the computer vision in journalism, computer vision, a field within Artificial Intelligence enables computers to interpret and analyze visual data in a manner similar to human eyes. Eli believes this technology could assist journalists to review and report on traumatic events. Today, we pick up from there Turning our focus on the AI products Eli is currently working on at the American Press Institute. We discuss the untapped potential of AI in newsrooms, and hear her insights for product managers looking to incorporate cutting edge technologies like generative AI.

So Elite, you're now working at the American Press Institute building tools and resources to help local news. And so I want to learn more about that. Could you tell me more about how are you incorporating AI into the tools that you're working on right now to help newsrooms?

Elite Truong  2:29  
So at API, there's two lanes that the product team that I oversee are interested in exploring. So the first is actually as practitioners. So working alongside our local newsrooms who we serve, you serve over 100 Local newsrooms store to products, source matters and metrics for news. And we're really trying to understand what AI technologies have to offer us the industry at large and how we can utilize those technologies to serve our clients that are local newsrooms. So we can have a really robust industry, not just national newsrooms leveraging AI, but a really strong local newsroom component of our democracy and Dino information needs in the US. So we're interested in particularly, we've done some experiments in the past on exploring how natural language processing helps identify and automatically categorize sources and source tracking in the article context a little bit more quickly in source matters, versus reporters having to go through and attach all this, like identifying information manually to sources that these are all like self volunteered information, and things like that. But it's also quite laborious to have to do that manually, right? I'm just like, Okay, we want top level metrics on how we've covered the past couple of months on election races in our area, for instance, and how many community members versus public officials did we talk to, if you want top level data like that, you do need to aggregate some no data about your sources along the way, this makes it a little bit easier to do. And also through our contextual metrics, tool metrics for news, we've been interested in tapping NLP, for those kinds of things to automatically tag things and add more context. So it gives more data on how local news leaders and their staffs are reaching their editorial goals without having to put a ton of manual work in so a really, really good use case for using automation and other parts of AI to be able to help do those jobs for those reporters and editors. Were interested in potentially open sourcing data on specific beats, or workflow tools behind the scenes or content discovery, which I think we've had about earlier is really, really interesting, and I think a huge potential area for us to look into. And we're happy to support any vendors who are doing that in a really smart way or potentially look into seeing is that something that we could potentially help out with, if all their content is in the same place and there's, there's a potentially really big opportunity there. So that's the first lane which is, as in practice using AI and understanding what it has to offer us. The second lane here is as conveners and facilitators so we're in a real A unique position as a journalism support organization to be able to zoom out and see a lot of the issues and see how can we help? Like, how can we find a place to help that is actually useful to local news leaders. There's so many different resources. We have amazing folks in the journalism support space, who are really trying to figure out also the same thing, like how can we help at this time, but not overlap and do a lot of the same AI support kind of stuff. So one of the things I'm thinking through right now, and depending on when this episode is out in August, this is likely something that we'll be able to happen pretty soon is gathering local news leaders to better understand and identify issues and opportunities to use AI to expand their work capacities and serve their audiences a bit more. This is why I think local news is one of the biggest industries to be able to the biggest audience opportunity to be able to serve as many people as we possibly can. Versus just national newsrooms, because there's so many communities who are no longer being served effectively by local newsrooms, because of the pandemic's effect on shutting so many local newsrooms across America in the past couple of years. And there's just a huge opportunity to reach a lot of people on the business operation side and the content discovery side to be able to scale their work effectively, or help them with some parts that could be automated a little bit. So potentially, that could open up new avenues of opportunities to serve audiences a bit more. So maybe in a couple years, there could be opportunities to see more and more local news outlets who may be able to be leveraging some of that help. The other part of this lane of convening and facilitating is, we're pretty lucky in American Press Institute to be able to develop research best practices for local newsrooms to use being out ahead and sort of identifying the pitfalls of using AI irresponsibly, and encouraging transparent news for technology. So we've seen this a lot in the past couple of months alone, which is, you know, like something that could be very useful for I think any organization who's committing to using a risky technology that has a real, a real effect on trust, either way, like you could maintain your trust, or you could easily erode it by using this technology, depending on how you communicate your your intention, right. So I think that's just a simple business strategy tactic is for local news leaders to to explain their mission and why they're using AI to both their staff and their audiences. So they can avoid any, you know, they can answer the questions like why are we using AI? What for? If there's any content that's being presented to audiences? Like, where can I expect to see like this was written by a bot or this was compiled by automation or something like that, that should be on there to help clarify, like, their reporting is really left up to these reporters. And this is how we use automation behind the scenes to sort of to make this workflow a little bit more effective. So we're working on some of those best practices. And I'm really looking forward to hearing more from these local news leaders about where they see opportunities are and in driving some research from there.

Nikita Roy  8:00  
Yeah. And so now all of the products right now at api focus on using natural language processing, which is also a subset of AI. And so with generative AI coming into the mix right now, how are you approaching that with the products and and experiments that you've been doing?

Elite Truong  8:17  
So right now, I'm really interested in paying attention to see what the different use cases are, I still see a lot of sort of back of house business operations opportunities, where I'm not totally sure, again, who is the right producer? Like who is the right person or organization to start a product like this? Is it us? Is it someone else, I'm trying to identify how we can differentiate ourselves just like newsrooms should and how they use AI or any emerging tech to be able to add to their product portfolio. So instead of pursuing immediately a product experiment for that, what I'm trying to do is research on who else has been doing this for a while, and maybe hasn't marketed themselves as using natural language processing, or AI or anything kind of like that, evaluating the landscape of those products and seeing, okay, now that we understand the local news space really well, we understand the problems that the people that we work with every day, we start from there, and then try to see like, okay, something that might be a solution to that is this product that has that's built on top of AI, we would recommend this. So that's where I think the biggest potential for us at API is as a journalism support organization. Others are already building tools and which is fantastic. It's a whole new lane, though, I think to do product marketing and build a solution that's looking for a problem that may not solve the most important problem for local news organizations. So I'm still in the Listening still in the research phase of understanding. Okay, let me understand the evolving problems and the upcoming opportunities for instance, next year with elections. I want to anticipate some of the problems that will build and potential solutions that we could enlist either by recommending vendors and working out like potential deals for local newsrooms. or building some sort of solutions ourselves. So our local news leaders can understand how can we get closer to our editorial goals? Maybe using AI or maybe something else?

Nikita Roy  10:09  
And for the newsrooms that you're partnered with right now and talking about regarding the use of generative AI, how are you kind of guiding them towards adopting it within their newsrooms? We're not

Elite Truong  10:19  
we're not necessarily recommending anything without understanding their problems. There are some really interesting vendors out there. LEED AI is one that I think has been interesting for years, Jay already is the CEO of that, which is associated with Richland source in Ohio. And what they do is help like they gather a lot of data about high school games and sports scores in general, they help scale by publishing a lot of those things in automated article templates, and a fix the right images to those kinds of things. And it helps really boost traffic, it boosts revenue and local communities. And also other opportunities come from that because communities love to see like, Hey, that's my kid, he was in a soccer game, look at this, like write up on it. Whereas if you have two reporters, there's no way those reporters should spend time in all those different games. So trying to identify and understand the market for what solutions are coming up that may match with problems in general. That's not necessarily generative AI, I think in that same sense, I haven't found anything yet that I would trust enough to proactively recommend to local newsrooms. I think there are a lot of interesting solutions out there. But I would, I want to better understand the biggest problems, a lot of the solutions I'm seeing are nice to haves, or have some other interest in mind of like, Hey, I got a lot of funding for this, because a lot of venture capitalists like really liked that this was an agenda of AI solution. I'm going to try to get journalists to do this. And I think that's really disingenuous. And sure you could do it, but I really hate to try to push a local news leader in their staffs, who already are so understaffed have so little capacity to try to adopt yet another tool. And that's what makes technology and new advances that help local newsrooms evolve? Tired of this new stuff, right. It's hard to keep up with. Yeah,

Nikita Roy  12:11  
absolutely. I'd really love to hear more about how you see newsrooms working with this technology. And now with your work at the American Press Institute, where you're working a lot in local news and the tech products that you're working on, what opportunities are you seeing for generative AI.

Elite Truong  12:28  
So I think there's a couple of different things retarget, so many different, we've had amazing guests on who have gone into all the different use cases that are or categories of use cases that people should be thinking about. So I won't repeat to electric that I'll just highlight a couple of things that I'm really interested in. One is I don't agree with this, however. So Google Docs is rolling out like a sort of Clippy like assistant from old Microsoft Word that helps you start out with writing your document. This is potentially disastrous for students who use Google Docs, who could have Google Docs, like fill in the entire thing. But we're already starting to see an email, for instance, what I would like to be able to follow in that spirit is starting outlines for service journalism, and how to guides so we can better jump on timely events that could really help with SEO, for instance, for any news organization, when you're trying to develop news you can use for your audience. So all that stuff is like it's not something that you have to report to deeply. If the news comes out of like, hey, TSA, or like the Department of Homeland Security, it's really backed up on approving passports right now. And that's the news story. The service journalism that to follow is, here's how to get a passport right now. And adding specific lines of context for that time of like how you can apply for a passport now what to expect those things like that, you can have something like that started really quickly with like with generative AI and be able to publish that thing incredibly quickly with like a piece of stock imagery, and be able to scale your operations to be to have useful news alongside the actual news story, right? And how to guides like how do you do these things like and being able to, you know, link your your other coverage in that way, it can be a big traffic boost. Besides that, I think a really interesting way to incorporate AI in the newsroom is to be open to automation assistance in some way. At media party, I reconnected with my beloved former colleague, Matt Keefer. He's now the data editor over at WBEZ in Chicago, and he had this great idea that I really love, which is when data reporters are working on and trying to file a million FOIA requests. For instance, how do you keep track of that over time? It's mostly an email. When you submit those FOIA requests, you might get a submission confirmation, but you might have a lot of those requests out, for instance, how do you track them over time? And how do you connect them to actual change in the stories that you publish when you might get some information back from that player request? I find a lot of interest in trying to track things over time that automation can help you do it a particular place that's removes it from just that email back and forth, maybe like that helps us to show accountability to our audiences. As we see, we've filed this request over and over again, maybe it's been like, X amount of times. And this is they refuse to give this information to us, even though it should be divulged in a FOIA request. Or eventually, here's the law that got changed because of all of our work. And that AI assistant might have been able to keep track of all the foyers, ins and outs, I think, as an operation system, it does very well, if you give it that kind of job, or like some other kind of impact tracking, which could really help nonprofit newsrooms sort of automate, hey, here's like the number of stories that we did on this particular subject. And you can give it that sort of job to keep track of how things are, are driving towards impact goals that you and your newsroom might have on the audience side. content discovery is I mentioned before, the biggest opportunity that really isn't a human job, I really think that the machines job to be able to surface really, you know, there is this this concept of an audience at one at scale. So Nikita is like what you read, and like what your friend reads, And like what your parent reads are all different, but we're trying to reach all those people. So how do we do that with first party data and connecting that to what in our, like, entire treasure trove of decades of content is most interesting to you? Like, what do we know about you that you might want to read more streaming services do this incredibly well, especially for the inherit archives of like older shows that we really like. And they can connect that and they can serve that up to you, when you're in the mood for watching something, there's a lot of lessons that we can learn from that. So I think that's really, we should get that job to a machine and make a person in charge of the strategy of how that might surface things. And it's hard because many companies didn't prioritize infrastructure, I can say that writ large, they focused on today's content production. So it's really hard to find and serve older content looks as a strategy. So I'm really encouraged to see taxonomy projects, and like the boring non shiny work that it takes for AI to be able to surface things later on. Because everyone thinks in the same place,

Nikita Roy  17:11  
I totally agree with you about content discovery, it's been that one size fits all model for quite a while. And I think that's probably where social media companies and everybody else is kind of beat than a lot of the news industry, because they're able to serve as content that people just want to keep scrolling on, whereas we're not doing that yet to the capacity that we could. So kind of wrapping things up. I'm also just interested to know more about the relationship between newsrooms and audience. You worked a lot on these tools between the two, how do you see the future of that interaction, evolving with the influence of AI? How newsrooms are going to be using generative AI, building more tools to interact with audience? Where do you see us heading.

Elite Truong  17:57  
So I think there's a dual effect that we can we see now of newsrooms using ai ai, like any other technology used by imperfect humans who use it for both corporate interests and community engagement. At the same time, you get issues like misinformation, and news literacy is even more needed. It's really complicated. All the issues that generative AI introduces in that space where there's already perhaps low news literacy or something like that, or it's just not being taught in schools. But also you could use it to scale up operations and really save time, I am interested most I think, in the tools that help audiences like reach audiences, and audiences have one and scaling that up, I think that's the biggest potential for AI. That is for good. I think big tech, as I said, at media party, big technology doesn't need to like adhere to an ethics code like we do as journalists. So it's our responsibility, I think, to evolve with the times as technologies come and go, but to also use it to improve our work and our trust with their communities and not replace or destroy it, we see this in a couple of different use cases going on now. I think it is always a hard road to go down and books will go down this road of trying to introduce more and more AI enabled tools for journalists to use in their work. I think anytime there is and this is because I work on products that are outside the CMS and I asked journalists to use this, I think anytime there's an opportunity to integrate this into your CMS or integrate this into your workflows. So it's just something working alongside many other functions that you're working on in the background automatically doing this thing for you automatically looking for SEO keywords that you can like either accept or like just exit out of anything that is sort of seamless, and then can help you in that way in the background is going to be way more successful than introducing more and more tools that they have to actively use. However, I really this is something that I think is a challenge for anyone working with technology in Gerlitzen but anywhere else that isn't just technology itself is really is the expectation that any Single technology solution is a silver bullet that it'll solve the problem for you, even otter or even whatever that you might use that is so helpful, still needs an editor. And we can really understand that as journalists that everyone can use an editor, and everyone should have an editor before that work comes out to check for quality control, because our our communities, our readers, they really deserve it. And we, we don't want to questionnaire and have our integrity questioned at all when we're producing any kind of content. So I think if there are folks who are willing to understand the technology as it goes on, and really know their newsrooms well enough to find problems that need that kind of solution that I'm really excited to see more and more folks use it and embrace this stage and be ready for the next one that comes up.

Nikita Roy  20:48  
Yeah, exactly. It's pointing to integrate with these tools, while also just critically understanding and exploring this space while we get to know more about how we can develop with it. But one final question that I want to know just as somebody working on products for such a long time, you've seen the transition to different different, I think eras of the media, as with social media coming in now with AI, what advice you'd give to product manager working on trying to step into AI, especially standard of AI, what would you like them to keep in mind,

Elite Truong  21:23  
any of these technologies is just solution looking for a problem. So the only goal for any product that you oversee, in my opinion is to be is to be useful enough to be used. So really, where I think you should develop your expertise is not as much as this technology as it is with social relationships that you develop with your stakeholders and people you serve. Who are you making products for being well connected with them, whether you work in a newsroom with them, or you're a startup trying to serve newsrooms in general, I really urge folks to not create a solution just because it's easily funded. And it doesn't solve a problem that's worth solving for the people you're trying to serve. And you're trying to it becomes even more confusing for small newsrooms who don't know as much about the technology, they depend on others to sort of like explain what's going on sometimes, because they have to run the whole operation as just a founder or a smaller newsroom, but I'm seeing but really trying not to, you know, they don't know exactly always like is a solution, like helpful to me, right. So trying to be as clear as you can. And understanding here's the opportunity, here are the problems we're working with. I think this is a good way to connect the dots, I see an opportunity here. I think that's that's the mark of a really strategic product manager. I think if you can identify something in the space of AI, or automation, and an opportunity in your newsroom, that is a problem worth solving that enough people care about that slows down enough work, start there. I'm super happy to talk with anyone feel free to email me, I can share my email address as well. I want to hear how those experiments are going. And I especially folks in local newsrooms, I would love to support you in some way. And, and yeah, I'm excited for the practitioners on the ground to keep pushing forward and to keep defining the future of what journalism looks like.

Nikita Roy  23:10  
Thank you. Thank you, Eli. Those are some wise words. They're remembering who you're making the products for. And I'm excited to see how you work on local news and building those products and copying it at your work at the American Press Institute. And thank you so much for joining us on newsroom robots.

Elite Truong  23:27  
Thank you so much for having me. I love the show. So I'm so excited to be here. Thank you so much. Thanks.

Nikita Roy  23:36  
That was Eli Trung, the Vice President of Product Strategy at the American Press Institute. This podcast is produced thanks to the Harvard Innovation Lab spa grant. I'm Nikita Roy and this is newsroom robots.

"
newsroom_robots,17,"Wed, 02 Aug 2023 16:55:13 GMT","Elite Truong: From The Washington Post to American Press Institute, Leading AI Innovation in Newsrooms (Part One)",https://shows.acast.com/newsroomrobots/episodes/elite-truong-washington-post-american-press-institute-ai,"<p>Elite Truong joins Nikita Roy to delve into her journey of leading AI products, first at The Washington Post and now at the American Press Institute, in a special two-part episode.&nbsp;</p><br /><p><br /></p><p>In part one, Elite shares insights from her work on Heliograf, The Washington Post's robot reporter that debuted in 2016. She discusses the evolution of the product under her leadership and explores the potential of computer vision in assisting journalists, particularly when covering traumatic events. Join us for part two of this episode, where we discuss her current role at the American Press Institute and her perspective on the potential applications of generative AI in newsrooms.</p><br /><p><br /></p><p>Elite is the Vice President of Product Strategy at the American Press Institute, where she manages data products like Metrics for News and Source Matters that empower local newsrooms to make strategic decisions. Formerly, she was the Director of Strategic Initiatives at The Washington Post, where she led the newsroom R &amp; D team to capture younger and more diverse audiences by creating projects driven by emerging technologies, including machine learning, artificial intelligence, 3D, and augmented reality. Before joining The Post, Elite spent four years at Vox Media, three as the product manager for off-platform storytelling, primarily negotiating with tech platforms to create user experiences that benefited news consumers.</p><br /><p><br /></p><p>She serves as the Board Secretary for the News Product Alliance and is on the advisory board for Democracy Day.</p><br /><p><br /></p><br /><p>Don't miss out, as Elite recounts her initial experiences with AI product development at The Washington Post in this episode.</p><br /><p><br /></p><p>Thoughts or questions? You can reach us <a href=""https://forms.gle/egyJZDsGjogiyNTH8"" rel=""noopener noreferrer"" target=""_blank""><strong>here</strong></a>.</p><br /><hr /><p style=""color: grey; font-size: 0.75em;""> Hosted on Acast. See <a href=""https://acast.com/privacy"" rel=""noopener noreferrer"" style=""color: grey;"" target=""_blank"">acast.com/privacy</a> for more information.</p>","Nikita Roy  0:02  
This is newsroom robots, the Podcast where we explore the intersection of artificial intelligence and the news industry. I'm Nikita Roy, a data scientist, media entrepreneur, and one of the many founders currently building their ventures at the Harvard innovation labs. On the newsroom robots. I'm excited to bring you insightful conversations with industry experts about how AI is impacting the way we do journalism. Today, I'm excited to kick off a two part interview with Elijah trunk. She's the Vice President of Product Strategy at the American Press Institute. elide was previously the Director of Strategic Initiatives at the Washington Post, where she led the newsrooms r&d team to capture younger and more diverse audiences by trading projects driven by emerging technologies, including machine learning, artificial intelligence, 3d and augmented reality. She's also worked at Vox media as the product manager for off platform storytelling. elide currently serves as the board secretary for the news product Alliance, and is on the advisory board for democracy day. In today's episode, we hear about Elijah experience working on heliograph, the robot reporter from the Washington Post that came into existence in 2016. We talk about how she evolved the product during her time at the posts, and also discuss how AI could potentially be used to help journalist when reporting on traumatic events.

Elite, welcome to newsroom robots. I'm so excited to learn from your experience about building AI products for media houses.

Elite Truong  1:43  
Thank you so much for having me. I'm so excited to be here with you today.

Nikita Roy  1:47  
So you like you've had this exciting journey on the product side of the newsroom for quite a while immersing yourself in the intersection of tech and journalism, an AI way before it was cool. And now with generative AI come into the mix and everything you've built AI products over at The Washington Post. And now you're working at the American prescient Institute. And so there's a lot to unpack today for our conversation, in terms of what it's like building products with emerging tech, especially for big media houses. And before we get deeper into anything, I always like to hear about people's first experience doing something new. And so I'd like to start off right there by knowing what was your first AI product that you built? And what was that the whole experience? Like?

Elite Truong  2:36  
Absolutely, you're right, I was working on it before it was cool. And it was much more difficult to think of use cases. So I do have a lot of old time or knowledge in that way. When I started at the Washington Post, it was 2018. And I was taking over a product called heliograph. It was well known in the I guess that the 2010s at that time, where we've experimented with it or our sort of flagship election coverage. So he like grep was basically a system that's built on top of all of our elections data coverage. And so we had data from DAP, we had it from a couple of different places that were really just live election data from all the different races going on across the United States. And the problem there was how do we reach folks with that data in use cases that it would be relevant, right? So you would think, okay, here are all of our Lexton news pages, our search pages like Arizona researcher thority, strong enough to be able to reach them in those areas. So heliograph was a way to generate articles, and then also social media posts of hey, here's all the live election data going on. And that's what it was in 2016. It really helped us scale our operations and what we were able to publish on election days when I came in, in 2018. But we want to use that data for was a little bit more focused than publishing all those different articles and social media posts. We found that sort of broadcasting all those things helped us learn the technology, but wasn't as effective. Because it wasn't written in a way that was incredibly engaging, it's really hard to do, especially in social media as, as anyone using like TweetDeck back in the day or managing social when you publish things at the same time. Well, no. So what heliograph did and what we built in 2018 was to take that infrastructure on top of our elections, engineering data sort of pipelines, and everything like that, to be able to share national election updates as they were happening in our YouTube live in our YouTube Live Chat in general. So the moderator who would be working in our live show in general, which was on the entire election day in general would be able to pipe in and be able to contextualize the automatic updates of what was happening in the election that was much more tailored and much more focused. It was much more engaging because it was not here's every possible way we could use this lake of data to like blast at folks who really like you get fatigue on And big event days like that you're really just looking for one piece of information. And we decided to narrow it down there and just like automate that one line of data in a very specific place. And it helped drive engagement quite a lot, and YouTube. So lots of lessons from that, too, because I had to fight against folks who are just like, why can't we just try to publish hundreds of articles again, because that seems successful in that way. But really success metrics have to be very thoughtful in spaces like these when we're exploring emerging technologies.

Nikita Roy  5:30  
Yeah, you've touched upon that product lifecycle journey, kind of that you were undertaking and developing this. And I want to learn more about like, how did that process work? The challenges that came about when you were doing something AI related for the first time, were there any additional considerations that you had to take into?

Elite Truong  5:47  
Yeah, I mean, when you're working with any emerging technologies, there's going to be some skepticism, depending from maybe your stakeholders who are the folks who are in charge of approving your projects, or your colleagues who are going to be working with you on those kinds of projects, there might have objections to it in general, with AI at the time, it wasn't as well understood. But the main face of AI was like replacing journalism, right. So that was still the the reputation that I was working with. And really stressing this is how we are using AI in this newsroom. We are using it to elevate and make a more discoverable, the content that we're all working on. We want to automate some of the things that you find really onerous as a journalist and try to do that for you. So you can work on more insightful work, things like that, especially beats like crime or sports that have, you couldn't cover all those different things. But maybe automation could help do that. And that was something that was really well understood the post when Jeremy and I were there, it's not everywhere. Unfortunately, we keep seeing folks at different media houses and media organizations, experiment with it with less transparency. And I really urge them to think about how to set a mission statement that explains to their audience explains to the staff in keeps that trust and maintains that trust of here's how we're going to use this and not replace your jobs or necessarily anything like that. Because used wrongly AI can be a shorthand for destroying that audience trust in your staff trust. But at that time, I think some of the challenges were really around trying to explain what we were trying to do, especially when we didn't know if it was going to work at first. So you know, we're also learning about in an r&d lab like ours, the lead lab at the Washington Post, we had a hypothesis, and we were going to create a prototype as quickly as we could. But we didn't know if it was completely possible all the time. So we had to ask for trust and faith in doing that. And luckily, we had built up a portfolio over years where we had enough quick wings, we publicized our experiments, enough, and there was more incentive to work with us than not, and that you would learn something more about your audience by working with us across any of the desks that most folks were interested in working with us and wanted to find out something weird or crazy about the next emerging technology, whether that was 3d modeling, or AI, or ml in some way, or what, basically just have some faith in us and give us some time to figure it out.

Nikita Roy  8:07  
So heliograph was your version one prototype that you had created and built? How did you then go about with like, developing and iterating upon the product to refine it? And when you left the Washington Post, what state was it at?

Elite Truong  8:21  
Yes, so heliograph was 1.0 was the one that had broadcasted all the hundreds of articles and social media posts. heliograph 2.0, was the YouTube version that I worked on. The third version of heliograph was called Claire. So that was really me being obsessed with House ads and podcasts in pushing our own sort of advertising and not necessarily giving the prime spots always to advertisers who might not have the best quality of podcast ads or something like that. And also just using geolocation that already exists for advertisers. But we don't think to do that, as you know, audio journalists or journalists in general. So Claire was really a couple pieces and different parts of AI. So one was pretty straightforward. It was not AI at all, it was more using geolocating. And so when you hear like a podcast, and you might get a local ad, that's like, get a Jimmy John's Subway sandwich or whatever like that, at this location near you. And you're like, Okay, that's weird. They know where I am, whatever. But it's pretty basic, like just general IP address tracking, and it is sort of helpful. What I wanted to do is to hook up the same, you know, data pipelines that we use for heliograph that powered everything on the Washington Post site, and the things that we had done for for YouTube, to our political podcasts as well. So the top add of the entire podcast before you even heard the host would be as flexible audio script that we created for different scenarios in the 2020 election. If I asked you to think back on that lasted about 13 days to get results from election day, because until afterwards into November because of all the special like the use cases in which we had to hand count ballots and things like that, we would never be in that position really again, or, you know, we had hoped at that time. And so we wanted to have something that continued to update you on your local election results as that went on. And as your local election might have been wrapped up, it would push you to the national election, which we we knew would take much longer than any local election result. So we work with the audio team to create a flexible sort of audio script that was less than 45 seconds long when read at a normal pace, and would be able to pronounce everyone's all the constituents names correctly. That was very, very important to me, as someone who has a name that is often butchered, it was very, very important to me to especially as the most diverse cast of folks who are running for the first time I wanted to make sure everything was prance correctly, we did several edits on that. And then we the second part of it was building this AI voice. So this was the persona of a young woman in her 30s, who was part of the audience that we want to attract, right. And so we gave her a voice, we built a voice with Microsoft to be able to voice all of these different, geo located election results at the top of the podcast every day that it was still going on for you. So her name was Claire, I wanted to name her Graham after Katherine Graham, but that was, that was a line too far for Marty. He was like, can you just call her something else, I don't want to have to call up Catherine's family and explain. But I thought it would have been incredibly cool. We made her her voice a little bit more pitch deeper, she could have been non binary, she could have been a young woman. And it really that was the audience that we were trying to reach. So there's a lot of strategic moves behind that one project where we took advantage of a system that's already set up for advertisers. But we used to ask journalists, and it was it turned into a piece of branded content that was offered to folks who are very excited, for instance, beer companies who want to do the same thing, like, Hey, it's 70 degrees near you, it's you know, like, it's a great time for this particular drink or something like that. It was just, it's just using the technology that was already there in a way that it wasn't meant to be. And that can be a really good place for innovation, I think.

Nikita Roy  12:12  
So just to kind of put this into context and make it more familiar for our listeners, I'm guessing this is how like, the most famous examples of like AP, automating their, like financial stories and like those generated templates is the same thing in text. But you put that into voice to have these auto generated podcast scripts that could just come about how is was that how it was working? Yes, that's exactly how it worked. Yeah. And I'm really interested in hearing more about that whole ideation phase, you've spoken a lot about how you took in all those considerations about making sure that you had the names correctly, though, how the voice would sound and attract your listeners? How did you go about, first of all, actually ideating, to what problem you would want to solve? And then all of the different steps in terms of the small, small details while working with a large team of technologists?

Elite Truong  13:09  
That's a good question. Let's see, the best ideas, I think, are often ones that have already been out there, but they didn't go anywhere in the past. So it never has to be a new idea. I often think of myself as I'm not the ideas person. But I have a special like skill somehow in making sure that this can be executed and brought to reality in some way. I think that's kind of all you need. Because you can have a million fantastic ideas, and they just kind of sit in the backlog. This was an idea that Alison Michaels had several years ago. So she is now I believe that Deputy audio director at the Washington Post, she used to oversee all the politics, programming probably still does. And she really wanted to as soon as she saw heliograph, she's like, we should do that in audio, you know, years before when I joined. And she was just like, that's, that's such a huge project. I don't know how we would do that. But I liked that I would work with whoever wants to actually make that a reality. And I was sort of thinking about different ideas. Like what this is not really a problem that we had, it was more opportunity, trying to find a useful opportunity for us to learn something about how to scale audio journalism, the post had just invested in a gigantic daily podcast team and podcasting department that was very new at the time that I joined. So what was an opportunity to showcase our audio journalism and emerging technology at the same time. And that's how I learned to work with advertising quite a bit too. So it was really trying to connect it to you know, Allison, I think there is a system that can automate a lot of this stuff for us. It's hacking like the ad tech platform that we use for podcast ads, which you normally don't. The only time you hear from them is when you have a complaint about like, this ad sounds terrible. But you don't know on the other side, there's geolocation built into all that stuff. If the advertisers decide to use it or not. We could tap into that as an advertiser slash person using that platform. Right, except it's editorial. So it really is just brainstorming with smart people, people who have more subject matter expertise than you. I'm a generalist by nature. And I think that helps me see and ask questions that might seem very basic, but helps people think about things that they've, you know, can help people connect the dots and new ways and subject matter like that they're really entrenched in and may not be able to see in new ways, for instance. So I think that's where really good projects start.

Nikita Roy  15:27  
And I mean, it's one thing to kind of develop that whole product. But then the other challenge altogether, is really getting them adopted into the newsroom. And you've touched it a bit slightly. But I want to hear more about when you were when you're building all of these different products, how were newsrooms engaging with it and your different teams? And how did you get your team to adopt this product. So AI is

Elite Truong  15:52  
interesting in that, it doesn't always have to be a tool that you have to convince someone to use, that becomes very difficult with other technologies and other tools that you're building. Because you have to convince like a number of folks to adopt, who are time strapped already, who don't have time to produce the things that they need to on a daily basis to use this new tool, because you need to learn about it to eventually help them with a workflow tasks that. So that's like you're finding a solution, but for the wrong problems to solve, right. And that's, I think that comes from my product background, which is like, let me find something that is either adjacent to that, like I can show like a quick win would be using AI in a way that either helps someone with a workflow that they are so bogged down in that they feel like they cannot do good work, or step away from their computer and fear of missing some piece of data or something like that. And they could use an editorial assistant, perhaps powered by AI or set up with different data pipelines to be able to understand things but not constantly be on or be able to be on the audience side of it and be able to, for instance, use AI or machine learning to work out a paywall or registration wallet strategy, which is something that I think the time says really well and ft did really well. And take that out of folks hands of trying to like do every single little scenario there and learn as it goes along, or content discovery. I think that's something we should talk more about in you know, later in the podcast, which is a huge, that's something that no single person should be in charge of. And it's something that has so many implications of we're sitting on years and years and perhaps decades of content, and how can we surface that a lot of that is still usable, and still relevant history repeats itself? How can we connect those things? How can we use older images and photos and videos that we've taken that we don't even know where any of that stuff is, and and take lessons from under other industries that are doing that quite well. With staffers, it's easier to solve the problems that are when you understand it. I talked about this at media party, when you understand the the hardest problems to solve or like the biggest annoyances. And the biggest obstacles for folks in like high priority beats are areas like can I free up my crime reporter from in to have a couple more breaks a day instead of staring intently at their email, hoping to not miss something and break the news right away from the different police precincts. Maybe not now, because none of that data is structured. It's like it comes from a lot of unofficial sources. But some day can like we might be able to do something like that and an open source project. Can we do that? For sports? Yes, all that data is completely the same sort of format. And that's really, really easy to do. Can we find an optical character recognition based tool or our investigative reporters to dump a bunch of legal documents in and then be able to search especially if there's handwritten notes and things like that, that are purposely like obfuscated by the folks who are like I will technically legally I'm bound to like the Muller report, for instance, which we did to be able to publish this but I don't have to make it easy for you to glean insights. Yes, we can we can find in we did, we worked with Google's pinpoint tool to be able to search those documents and break news really quickly. Because we were able to scan through all those documents. All of that is AI, you know, Otter otter is something that's also when one of the things they champion because most reporters understand that the efficiency of having someone something just take notes, a transcript of your conversation, that's easy to understand. And that's all in the same category of AI.

Nikita Roy  19:21  
And you know, we were just talking before we hit record about how AI is becoming this big marketing buzzword more like but we have all these different subsets of like machine learning, computer vision, generative AI, and you were just briefly telling me about this computer vision product idea that you'd begun working on. I'd love to delve deeper into that. What got you into thinking about like more from the automation side, then looking into computer vision, AI and keeping up with this emerging tech?

Elite Truong  19:49  
I think even general AI is very simple like aI cannot really any of these emerging technologies, as it has to do with like content industries like journalism and news is not small. aren't enough to be able to produce sophisticated content, like any average reporter could anywhere, right? But the real trick of it is like if there's like simple tasks that you can automate or be able to look out for, and you could tell it specifically enough without it generating a ton of errors, then it does that task very, very well. Even asking generative AI or Chachi Beatty to take the bar exam, all that structured data, it's pulling on guides from the internet and all that studies, why wouldn't it do? Well, you know, and that's not something that we work that way. So computer vision at the time, it was, I think, 2019, when I started to look at this, and then 2020, when we really started computer vision is really just chat GPT for visuals. In this way. It's like you're supposed to look for maybe that's you know, that's just a simple analogy. But really, what the algorithm is, is like, can I, I'm looking for something in particular. So for instance, traffic cameras are really good at this. They're there, they operate, sometimes on computer vision of like, I'm looking for cars that run the red light when the red light is on. And so I will issue like a ticket to this person or whatever. And here's a data that I'm looking for. It's a license plate, it's this model of car or something like that. We were trying to find use cases for this, and I stumbled upon a really good one. And we started to formulate the idea for this product that was never launched. But I would still love to work on this at some point, or would love to hear from folks who would like to work on this, where we had a project. Of course, in the summer of 2020, when George Floyd was murdered in Minneapolis, the week following we reconstructed a time of visual timeline of social media videos that really portrayed, hey, here's what's happening on the ground in the Twin Cities. Here's what the protests look like. And even the coverage of that from the post even and but everywhere else was really suggesting that riots were happening at that time. And all this violence is happening. And our our visual investigation really showed that violence was way more instigated when police arrived in instigated that themselves. So it wasn't citizens themselves or people in Minneapolis. It was really around that. So it helped clarify, you know, our reporter who helped us on that project and reconstructed 250 Social media videos from the ground in Minneapolis following George Floyd's murder for that week following she was even herself like, this clarifies a lot of stuff to seeing this laid out like this, right. So just like, here's what happened, a reconstruction of like what happened across these neighborhoods in Minneapolis. And with computer vision, what I really wanted to do after that project was build a tool that where we told an algorithm to help us verify locations a little bit better, that was really difficult to be able to map to these, for instance, like four locations, or six locations, or whatever it might have been across the city by viewing landmarks and the backgrounds of those videos and being able to geo locate that in that way, and be able to verify that that happened, and there was no synthetic material being put in. And so we had to view those videos over and over again and manually, sort of add them in this visual timeline. It caused a lot of harm and trauma. And for me, the visual the journalists I've worked with who had to verify those hundreds of videos, it was to the benefit of our audience to help understand that. But you know, in the future, if I could have used a tool that maybe we built, or someone else built that helped us verify the locations of those places, and helped us, you know, and just flagged some certain ones for edit for us, for us to verify, it would have reduced harm for my staff. And for me to be able to see such violent videos over and over again, for many other visual journalists. For instance, we had, unfortunately, the insurrection right after that the January 6 insurrection, where we had to do similar things with the visual forensics team reconstruct what happened. And that's incredibly traumatic. So if we could have had a tool like that, if we could have had the jump on that we didn't have the technological resources that we'd needed at that time, because it's so different than what we had been building. But I would love to still pursue something like that. I think there's a lot of potential now as that kind of AI technology is also maturing.

Nikita Roy  24:04  
Yeah, I think that's a really good use case of using AI to do the work that can actually be more harmful for journalists as humans just having to see something so traumatizing and constructing it. And that's one way we can use AI to really help us. How do you see our situation right now in the current technological landscape to help support you in building such a product right now?

Elite Truong  24:29  
Well, at the time, I think there that could have been incredibly helpful for something like an AWS partner, for instance, because you're trying to put in like, hundreds of documents or hundreds of videos or something like that. I would love to hear from listeners. Also, if you've heard of anything like that it possibly could exist it I'm not aware of it. I think newsrooms really could use something like this, anyone who has to verify what happened or work with traumatic videos or reconstruct anything in that way which is becoming more popular at some of the larger now. Shaun newsrooms, because it's such an immersive way to show what happened. It's like undeniable, you can write about something and some people won't trust it. If you show what actually happened when you went in that hallway in the intersection, then folks, it's hits you in a much deeper level of like, wow, this, I can see how all this stuff played out. Now, this helps me have a fundamental understanding of every piece of coverage that follows right. So that's why that kind of journalism is so important. And I would love to hear from folks who would love to either sponsor or like a project like this or know folks working on something like this, I think it should really exist.

Nikita Roy  25:37  
That was Elijah trunk, the Vice President of Product Strategy at the American Press Institute. Join us tomorrow to learn more about what Elijah is currently working on, and your views on where she sees generative AI having the biggest potential for newsrooms. This podcast is made possible. Thanks for The Hobbit innovation labs spark grant. I'm Nikita Roy, and this is newsroom robots.

"
newsroom_robots,16,"Thu, 27 Jul 2023 02:08:24 GMT",Aimee Rinehart: How AI is Transforming News Production at The Associated Press and Beyond,https://www.newsroomrobots.com/episodes/aimee-rinehart-how-ai-is-transforming-news-production-at-the-associated-press-and-beyond-3YjOLfI3,"<p>Aimee Rinehart, the Senior Product Manager of AI Strategy for The Associated Press  joins Nikita Roy to discuss how AP is using AI and the tools being built as part of AP’s Local News AI Initiative. Aimee shares AP's current approach of learning and experimentation with generative AI through projects around translation, image identification and search. </p><p>Before joining AP, Aimee served as the Deputy Director of First Draft's New York Bureau, where she helped journalists and newsrooms navigate the mis- and disinformation during the 2018 and 2020 U.S. election cycles. In 2018, she managed Comprova, a project to monitor and analyze misinformation and disinformation around the 2018 Brazilian elections. Aimee started working online in 1996 and was a digital originator at The New York Times, and returned to print briefly as an editor at the Wall Street Journal Europe in Brussels.</p><p>Tune in to hear how one of the largest news organizations is navigating the adoption of AI and automation technologies while also assisting local newsrooms. </p><p>Thoughts or questions? You can reach us <a href=""https://forms.gle/egyJZDsGjogiyNTH8"">here</a>.</p><br /><hr /><p style=""color: grey; font-size: 0.75em;""> Hosted on Acast. See <a href=""https://acast.com/privacy"" rel=""noopener noreferrer"" style=""color: grey;"" target=""_blank"">acast.com/privacy</a> for more information.</p>","Nikita Roy  0:01  
Hi, Aimee, welcome to News from robots. Thank you so much for joining us.

Aimee Rinehart  0:05  
Thanks for having me.

Nikita Roy  0:06  
So, Aimee, you know, when I think about AI is early integration into journalism, it's always about APS, automation of the corporate earnings reports in 2014, that always comes to mind. And that's been mentioned quite a few times on the podcast already, that was really a significant step in demonstrating the potential of AI and automation in the newsroom. And it's nearly a decade now, since that automation was brought in. And I'm interested in knowing how is the AP expanded the use of AI and automation since then, and where is it on its current AI journey right now?

Aimee Rinehart  0:46  
Yeah, so I think, you know, we look back it was nine years ago is in 2014, where AP started using earnings reports, the data get given from the or distributed from the, from the stock exchange to make earnings reports automated, and, you know, editor set those templates. And so there were there were humans in the loop, and at the very end to to check. But, you know, we went from doing 300 earnings reports, written by humans to 3000. And there's there is research that shows that that by doing that, we moved to the market like that, that companies that had never been written about before, suddenly, were able to be searched by Google and and, and so people would find these companies and then start thinking about investing. So that was not the intention of it. But that is some of the consequences. And, and also, as a consequence, you know, people, journalists at AP, were able to do more interesting work, you know, like to do analysis pieces around a sector, rather than just the earnings report. So just to say that there was a lot of good results from that. And we continue to do that work. We've also experimented with doing minor league baseball sports in the same way. And again, using that templated, very steady, very safe version of AI. And it's called natural language generation. So just generating something built with with very reliable content. So Column A in the spreadsheet is always what column A is expected to be column B, Column C, and so on. So, again, a very steady version of artificial intelligence. And you know, there are people in the industry who quibble around, is it artificial intelligence? And I would say, Yeah, I would call it sometimes I call it baby AI. Because we were just learning. We were really in our infancy, and it's grown so much. And so yeah, that was that's really sort of the genesis of where he started. I mean, we've done a lot of with AI work through similar segments of AP as well, whether it's, whether it's through our elections work, in our let me let's cut there, sorry. Okay. Yeah, sure. The I don't think I answered your question fully. This was the the other part of it was,

Nikita Roy  3:13  
where is it right now? And it's kind of journey. Okay.

Aimee Rinehart  3:17  
So, you know, AP, like a lot of large news operations is really grappling with what generative AI might mean, and I don't think anyone has an answer for that, for that. We are looking for those answers. And in many ways, one thing I think that's been great about technology throughout its history is it brings departments together that don't ordinarily talk. So when what I mean by that is that AP when I go to a meeting about AI strategy, if someone from every department, you know, and it's people who have a different take on this and we need to be informed, whether it's the legal department or the marketing department or the news department or product, all of us are coming together to think how is this going to disrupt my part of the news value chain? And and what what are our limits? What are our experiments, what are we learning? So we are definitely in a learning growth curiosity phase. And and for that reason, I you know, we are looking currently at working on shoring up our translation work. Image identification within a video, and, you know, for key keyframes for video, and, and we'll see where we get with with those projects. But those are already stuff that we've already tried to try to put forward and we're going to move those projects forward. We just instituted Merlin in our search. So search is also now generated by artificial intelligence. So where we think it makes sense for AP and our customers because remember AP is not for Profit co-operative, we answer to our shareholders who are 3500 newsrooms. So the newsrooms that we are, you know, who we listen to are the our members who are concerned about generative AI being put into the wire. And so we're hearing that and we're learning with them. And and haven't really deployed anything with generative AI yet, because we're very much experimenting.

Nikita Roy  5:26  
So currently, a lot of experiments are focusing on generative AI search within the APS archives is that was?

Aimee Rinehart  5:34  
Yeah, so So that's the Merlin's search. And, and, yeah, and it's our customers spoke loudly. And clearly, we can't find content on ap.ap news.com. Well, now they can. And so it's, it's being able to index things, much better than what we've had in the past. But that's, you know, again, anything that we implement has to make sense for AP. And it has to, and by that, I mean, it has to fit within AP standards, and also APS mission. And our mission is really to be that center, center hub for other other newsrooms that maybe don't have resources, for tools for technology to be on the ground in Ukraine to be, you know, across, you know, the tech sector in San Francisco, but they want that information. So that's, that's been our mission since the foundation and we'll continue to do that.

Nikita Roy  6:31  
Yeah, and it's interesting how you've been looking at automation. And that really helped free up during this time to go more in depth reporting. And so now with generative AI talking about writing stories, and all of that, how has the approach and strategy been within the newsroom towards the potential of generative AI to help with like summarizing information writing? How has the newsroom been looking at

Aimee Rinehart  6:55  
it? Well, I mean, again, we're all experimenting right now. We're just seeing what's what's available. I think summarization help holds a lot of promise. I think generative AI, as you know, as many of the headlines read is largely unreliable, and it's confidently wrong. And those things are true, if you're using it for its knowledge base, but if you're using it for its language capacity, it's much stronger. So what I mean by that is, if I'm, if I'm a reporter, at a very small newsroom, we're under resourced. I just, I just wrote my story. And now I have to summarize it, I think I would put that story into something like chat GBT and ask it, to summarize it, and then send that, you know, send that over to the editor to see, but it's, I would review it myself to make sure that it got it. But I think it operates much better in a in a receivership mode, rather than like, then getting it from Chuck GPT. Like write me a story, I think, I hope we're never in that space. I think the News, the news outlets that have tried to use generative aI have fallen on their face pretty hard already. And, and so I don't think I don't think we're there yet. You know, I, and I think, you know, maybe the job categories that that grow because of generative AI or editor roles, because we're going to need people to really go through each line each word to make sure it's what you really intended to say.

Nikita Roy  8:30  
Yeah, the technology will be really to be complemented and kind of augmented with that human editor. And that work that comes about. And all of this is really making me think more about the risk model that you're thinking about when applying any kind of AI into a piece products. How do you analyze the different aspects of risks that could be brought in and especially with Sen. Vi? How do you move forward and building products there?

Aimee Rinehart  8:59  
Yeah, I mean, we're gonna have to test right we, my colleague, Ernest Kang, and I were working on a local news AI project, we have five projects in development. And we were going we were testing out generative AI. For some of these projects. One of the projects, we are going to use generative AI in for the transcription because whisper, which is an API from open AI, I don't know if there's enough AIS in there. But we've just got better results than other transcription services. And we tested that against human transcription. And so we felt really competent that not only is the price right, because open AI has shrunk the prices for its GPT three and 3.5. API's that that it just was better than the other the other ones that we had tested. Now we were also looking at could we use generative AI for our Puerto Rico project or a project in Puerto Rico around noon? summaries, in particular for hurricanes. And we experimented with it, it was like, we're not sure what we're going to get every time and with hurricane information, because it is life and death, we have to be sure. So we're going to rely rely on our foundational model with with using natural language generation. So we will use that tried and true method of spreadsheet, you know, column A is the wind speed, Column B is the, you know, the the water rising, that kind of stuff, because we need it to be exact same to with the police blotter project that we're working on that where it will take it will take blotter items and put them into a format that is a story a small, small news nugget, I'll call it. And again, we tested that, could we use generative AI? And the answer was, well, we could, but the results are mixed. And for for newsrooms, we don't need, we can't have results that are mixed, we have to have it reliable every time. So again, we will rely on natural language generation. And so we were testing those out. And, you know, we were given a Knight Foundation grant to do this work. And it gave us a two year runway to do exactly this tested out what works better. Is it too dangerous? Is it too? You know, is it too risky? And and what are the results? You know, like I said for the transcription, the results were better. So we're going to use it and where situations where the technology is better, we'll use the better technology.

Nikita Roy  11:39  
Okay, yeah, you've touched upon the AP local use initiative. There's been a lot of work that you've been doing over this two years that it's now I believe, expiring in August. Yes. Your Can you talk more about the initiative and how it's been helping local newsrooms?

Aimee Rinehart  11:54  
Yeah. So it was a two year Knight Foundation grant fund. And it was meant to assess where local newsrooms were in terms of AI readiness. And what does that mean, you know, do they have they already adopted tools with artificial intelligence in it? Are they aware of those tools? And are they skeptical of those tools? Where are they and so we did a survey, and it was 32 questions. And it went to local news leaders. And we got almost 200 local news leaders to take this. It was across all formats. We got somebody from every state to take this. And so we felt like we had really good representation. And a lot of the newsrooms came back, you know, saying that we think, yeah, this could help remove really tedious tasks from the staff, who remains in the newsroom. So you know, all newsroom staffs had been cut. And they were, they were excited to the prospect that maybe they could get one more tedious task off the desk of the people who are there.

Nikita Roy  12:57  
And sorry, go ahead. No, no, no, I think you were continuing.

Aimee Rinehart  13:05  
I was just gonna say so the so with that project, we, you know, we we had all this rich information. And so we, we decided to write a report. And we felt like the report would be helpful for us to for us, but like, what do these numbers mean, we also had with the help of students at Medill, and the night lab and at Northwestern, we did 25 interviews with these local news leaders. And that's where like, that's where some of the, the stories came out, where it's like I, you know, our content management system is patched together. We've had three content management systems in the past year, you know, all of these things, all of these aches and pains where it because, you know, journalists have been forced into the position of being technologists and guess what, they're only good at journalism. So a lot of mistakes have been made. And that's just not entirely their fault. I think that we've been put in such an awkward spot. So my hope is that tools like these can get newsrooms out of the business of figuring out tools and tech that they need, and putting a P back into the center of being able to deliver those tools that we think that would be helpful for them. Okay, and so,

Nikita Roy  14:20  
right now, a lot of the work that you're doing currently, part of the initiative is focusing on helping these five newsrooms develop their AI projects. Can you talk to me more about that? How, what's the main goal that each newsroom is really focusing on? And how did they go about incorporating AI into it? Yeah.

Aimee Rinehart  14:39  
So we, we did a training course, about a year ago, and after the training was done, it was speaking to the knowledge and interest, knowledge deficits and the interest that people had from the survey. And so we built this online course. And after that, we opened up a pitch process So we said, Send us send us what you got. And we got 43 submissions, which was great. I will say none of them were like, Oh my gosh, I've never heard of something like that. Before. They were all pretty common. In fact, we got five police blotter item submissions, you know, five newsrooms want that and it's like, that is clearly a need, clearly a need and that we can certainly attempt to address that. And this was before, you know, GPT had already been released. But I think people were made more aware of it, obviously through chat GBT. So this was like, eight months before all of that hit the cultural awareness of generative AI. So just to say, we weren't sure if we could deliver on that promise for the for the, for the police blotter item, because one of the reasons why the way a tool doesn't exist is because there's been such a variance of data, data points like people get people get the police bladder items through a wire basket on the shelf in the office of the police department still, you know, people also have it called in. There's also CSV files and PDFs, and word documents, and all of these different ways that this information is delivered. And because of that variance, we haven't been able to create a tool, generative AI can resolve some of that variance and make sense of the disparate data. And so so for for that, like I mentioned earlier for the Brainerd dispatch in Minnesota, we will develop automated police blotter items through natural language generation. So very tried and true and tested. We will also do something similar for el cerro and Puerto Rico around it doesn't sound similar, but it's it's for weather related reports. You know, I would say that the weather related reports, the police blotter items, the the APS earnings reports, all of those things are natural language generation. And once you have a template, you can use it for lots of other things, you can use it for recipes, if you wanted, for example. So there's lots of different ways to make that happen. And so for Elva, Sarah, and Puerto Rico, we are going to be using natural language generation. And, you know, we're working with student development teams on these universities. So in Missouri, the University of Missouri, we're working with the comp site department at for Puerto Rico, we're working with Northwestern development team. And this has been a great way to, for a lot of things. It's it's kept the cost low on these projects, but also it's given students, you know, a real project, a project that is going to be used. And for students, they love that they hate building a bridge to nowhere, and not getting any feedback. And so for a lot of these, for a lot of the students, they're getting, you know, a towel or a foot in the door into a newsroom and some insights on what is what's needed and how and how newsrooms work and contend with the amount of information that they're dealing with. So we also are working with Michigan Radio and northwest of the another Northwestern team on a project called Search minutes. And that takes, it already takes links from YouTube and Vimeo and transcribes those. And the component that will add on to it is we are shifting the transcription tool to open a eyes whisper. And we will do keyword identifications, and then pings and alerts to journalists, if they're looking for something specific. Like for instance, if they're looking for if a stop sign was mentioned at a particular intersection, you know, they can look for that, and get alerted to that so that they can report report on those. So that I think holds a lot of promise, we think that could scale to like school board meetings and other places. So I think like, that holds a lot of promise, I know that there was an AI tool that is doing it from start to finish completely. And I I'm glad that for our project, there is a real human in the loop, who is discerning between what is putting things in context and discerning what is what is useful information for the public to know and, and maybe, and how that fits into the larger society for that coverage area.

Nikita Roy  19:29  
And this could be something that can be used for anything with like YouTube videos when your video isn't expanded throughout.

Aimee Rinehart  19:35  
Absolutely, absolutely. Yep. Yeah. So anywhere and, you know, because of COVID. You know, these, these meetings that used to be in person, were taking place online, and it's a requirements, the law in most states to have open meetings. And so this is this fits that requirement. And so if a state doesn't have something like this, especially after COVID It's, it would be Surprisingly, because it's supposed to allow the public to access so. So I guess that's one good thing that came from COVID. Possibly men are one of the other two projects. One is with WFM, z and Pennsylvania, and involves creating a sorting mechanism for the hundreds of emails that they receive on the assignment desk, AI will determine if there's credible news event and add it to the coverage planner. So again, we're working with the comp site department at Missouri on this. We're excited about that development. Our last project is with case at TV and San Antonio, will work on composing basic digital stories, from video interviews and, and the features selected by editors. So the AI will summarize the videos. And a content item is automatically added to their CMS and we're working with Stanford on developing that project.

Nikita Roy  20:52  
Wow, that's quite a lot of innovative AI products that you're working on. And so the way I'm seeing it is like two projects are focusing more on like the natural language generation, the baby AI that you were referring to, and then two or more of like, looking at videos, transcribing them, summarizing them and helping, like drone lesson use drones to be able to query that data.

Aimee Rinehart  21:17  
Yeah, yeah. And Ernest Khan has been my counterpart on the local news, AI, he has been the driving force behind getting these products ready for market like he, he will have Mbps for these by the end of August, we will also have case studies so that we can tell you all the aches and pains that happen and all the good stuff too. So that people know what they're getting into when they're trying to build something. And we will also open source the code on this so that newsrooms can use it as is, or can build on top of it to make it even better. But you know, that was part of the night requirement that more people can use it. And I I know that for some newsrooms, the second somebody mentions GitHub, they're already out of the game. But we're, we're hoping that maybe they can, you know, tap a local university for that brainpower to make to make it customized for their newsroom.

Nikita Roy  22:12  
Yeah, absolutely. And the fifth project that you had mentioned with WFM, Zee TV, I found that really interesting to kind of reduce the workload for assignment editors being able to just extract what is in classify what new story might be something that could be worked on? How I'd be interested in more in learning about how is that data model kind of being trained? And how are you looking at sometimes bias that might creep up on deciding whether a new story should be covered or not?

Aimee Rinehart  22:42  
Yeah, I mean, you know, the the people at WFM, ZR training this, so every model has to be trained. So if somebody wants to use the code base, for this project for their newsroom, they need to know that they'll be starting from scratch in terms of identifying a whitelist of emails, so WF MC, they have somebody going through and saying, oh, yeah, we know Sally, who runs the community events, and we, we trust her and we trust her information. So she will be whitelisted. And her information will be created into the into the planner. But for instance, if there's something that is particularly spammy, maybe it's a PR agency that just, you know, just send stuff to them randomly. They can identify it, as you know, no. So there's three buckets. There's yes, no, and maybe, and I think for a lot of newsrooms, sometimes there's only one big bucket, which is the email address. And you know, people look into that email into that email when they can. So that builds in a lot of redundancies, people aren't sure who's looked at what has anybody gotten back to them. And after a while, it just becomes this really tedious task, which was what we are hoping to eliminate with this project. So you know, in terms of bias, that's a very good question. You know, it's how things are trained. And that's how you see bias creep up in AI all the time, is that people, you know, who or programming it only see a certain slice of the world or slice of life and, and a lot of data and information online is really focused on a white western experience. So that that's frustrating, and it's and bias in AI is true, and it's something that again, if we have more diverse newsrooms, people in that newsroom can hopefully identify something as biased and speak up, though I hate always putting that burden on people of color to do but if or what we're even gender if it's if it's a male, female genderized problem. So it's just something we all have to be vigilant about and know that we all have blind spots. And unfortunately that will be represented in whatever product we use.

Nikita Roy  25:06  
I think initial role will have to be playing as well as we develop AI and being aware of all of this biases. The switching gears a bit little bit I kind of I'm really very interested, you've been working with a lot of local newsrooms hearing a lot about how they've been using AI. Where have you been seeing some key areas in which local newsrooms have been experimenting with AI and St. genitive AI more specifically?

Aimee Rinehart  25:32  
Yeah, you know, I do think this is a small newsrooms moment, if there ever was one for technology. And what I mean by that is, they don't have to ask corporate for approval, they don't have to go through 10 different departments to get something pushed through, they have every reason and advantage to experiment with something. And generative AI is very user friendly, like people can program it without being a programmer. So like this, this is the moment for local news. And I think what we're seeing now is inspiring and the real innovation I think, is going to come at the local level and work its way up to larger newsrooms. So one of my favorite people in this space, his name is Hank Sims. He's the Editor and Chief Technologist at the last Coast outpost, which is in Northern California. And he does simple automations with something like Quake bot, which explains or identifies when there has been an earthquake in the area. And it was sort of scary when we were looking at it just today, that there's has been a small tremors all week, in his area. And, and so it's he said that he can tell that, that there has been a large, large ish earthquake, by the amount of people who go to that page, because people in that community really rely on that information, and they've come to rely on it. Because last Coast outposts is so good at delivering it. Then he also does things all the way through GPT. Three, like summarizing meeting agendas, and then he also gives the option of reading that meeting agenda summary as like a pirate, or as a poem. And that, to me, is a really great use of technology. Because it's, it's fun, you know what I mean? It's not also serious. And I really appreciate the joy that comes when you see something like, Hey, I want to read the meeting minutes as a pirate. So I think that's, it may not be the most useful of things, but it certainly is a delightful example. Nieman lab featured about a month ago, a guy from Virginia, Scott Broderick, he's the founder of Virginia based media company, local news now, and he wanted to launch a newsletter. And and but he didn't have people to stop it. So he thought, Well, can I use a series of chat GPT protocols to make a newsletter every morning. And he did. And he was very careful to say in the article, I am not a programmer. I just strung this stuff together and wanted to see if I could do it. And now he has a newsletter. And he said, you know, there, there were at the time, 100 subscribers, he said, once I hit 1000, I may think about resourcing this with a human. You know, the interesting thing about that is just a year ago in our free online course, we've featured automated newsletters, and you know, some of those systems are like $800 a month. And so for local newsrooms, that is just a non starter, anything over like 50 is too much sometimes. And so what Scott has done is real bringing real innovation to his newsroom and bringing something that's really cost effective. So I think, you know, again, as I mentioned, I think this is the moment for small local newsrooms, and they are leading the way on what is possible with this technology.

Nikita Roy  29:05  
Yeah, it's interesting at Bob's class to Scott's example, as well, he's joining us on the podcast to talk a lot more about some other innovations to that he has been working on. And so that's coming up. And with all these local newsrooms that are trying to experiment with GPT technology and not having the technologists in their newsrooms, right now. What would you say is really that low hanging fruit that that's possible for them to just kick start the AI adoption journey? Yeah,

Aimee Rinehart  29:36  
I think thinking of through the news value chain, the news gathering production, distribution and business operations, like where are the pain points? Or where are the complaints? You know, people when you ask somebody, how can I fix something like I'll I don't know. But if you're like what annoys you every day, it's like, Oh, I've got a I got a list. I can't tell you, you know where to start. With this list, but I've got a long list of annoyances. So I think that is a really good place to start is to try and tackle One annoyance through one of the news, one piece of the news value chain to see what is possible and what what might be needed for your newsroom, I think if you're talking specific tools, if this then that is a great process automation tool that people can test out. Transcription is really low hanging fruit. And for anybody who remembers the cassette days with the foot pedal, trying to go back and forth to see what exactly what was the exact word. You'll be so amazed and relieved. Now transcription doesn't get it right all the time. But I do think it's, it gets you about 80% of the way there. And if you're a journalist who relies on audio recordings for your notes, this, you know this, this is for you. So I think transcription also came up as the number one tool that most newsrooms wanted to use.

Nikita Roy  31:09  
Interesting. In terms of like, you talking about the distribution of news, I'm quite interested in knowing how do you see really generative AI changing the way we distribute news in the future? Are you seeing with like, the Chatbot area and like so generative search coming about quite a bit? Where are the opportunities and maybe challenges will be facing in the distribution of

Aimee Rinehart  31:31  
years? Yeah, I mean, I think in the next six to 12 months search is going to fundamentally change because of generative AI. And how it will change is what we're already kind of seeing is that you ask a search engine a question, and it comes back with a paragraph and some links below it. And we all know that once links are further down the page, fewer people click on it. And you know, when we surveyed local newsrooms a year and a half ago, you know, it was clear that they, you know, half of their referrals came from Facebook, and half of their referrals came from search. And Facebook has stopped, you know, prioritizing news in its speed. So that has plummeted for newsrooms, search is about to do the same thing. And so it, you know, instead of building other platforms up, newsrooms need to build their own platforms. And so I really think having an app is more important than ever, having a podcast, maybe you know, to generate your own content, newsletters, I think are going to be essential, um, newsletters that are specific to your audience interests. And just making sure that you are driving people to your website, and that you are the driver, it is clear that social platforms are unreliable, it is clear that search, and its results will be unreliable. So we need to have a better plan for moving forward. And I think one of those plans is to build your own network, and make sure that people are finding your information.

Nikita Roy  33:15  
So taking back control of how people are finding that information directly from us, rather than getting through like, another source or intermediary service, like Facebook, or social media pop things.

Aimee Rinehart  33:27  
Exactly. It's like why build these platforms up for free on our backs without, you know, and then not even getting referred to it. It's like, it's it's those days are done, you know, like, we need to come up with our own plan, and our own trajectory trajectory. So that so that, you know, we have, we can kind of take back control. And I feel like maybe this is the moment, you know, newsrooms have are still spinning out over the web. And, and that has been a reality since the late 90s. So let's move forward with this and start to see that none of these things are going away, they're only going to become more important, and how are we going to stay important into the lives of audiences who have a million other things to look at and read and consume? We have to make a better case for ourselves.

Nikita Roy  34:15  
Yeah, exactly. And like talking about what audiences I can make a lot of more of like content mills coming up to just create content very easily, which is capable right now. The copyright issue is something that I wanted to talk to you about with AP being able to produce so much of having archives of images, videos, and text, the capability of generative AI to mimic something that's written an AP style, and all of those different copyright issues. How is the AP how concerned is the AP about all of these issues? And what is your approach towards that?

Aimee Rinehart  34:55  
Yeah, I mean, you know, AP produces 2000 articles a day three 1000 photos a day, you know, in comparison, the New York Times, which is a member of APA, and in a wonderful organization, they produce 200 articles a day. So we are we are operating at a at a much larger scale. And we're global. And so we are deeply concerned about the use of APA information to inform, you know, large language models, I think, you know, in our, in our what we do now, if somebody uses a photo and doesn't license it is, you know, we, I think we go to the door four times, the first time is, hey, we see you're using our content, would you like to license that content? You know, the second time is, you need to stop using this content. And the third time is like, we're going to, you know, there will be action taken, you know, like this third warning. And then fourth is, is, is that you need to pay up, and we're going to take you to court. So I think like, there's those are four lengthy steps that we intentionally take, we can't sue everyone, lawsuits are expensive. They take a long time, the outcomes are uncertain. And so I just know that, you know, AP is very invested in protecting its intellectual property, and being able to put journalists in spaces in places that others won't go, we were the only two, we were the only news operation that had two journalists on the ground and Mario pool, for example, the photographers, you know, that is not free to do it costs money, and anybody who uses our content needs to license it. So I think, you know, our encouragement would always be the licensing model, and the Formax, before anything would happen, because it just it's a it's a lengthy process with uncertain outcomes.

Nikita Roy  36:45  
Yeah, I think reimagining the way, maybe content as being licensed with generative AI coming into the mix now, because they've already been created these models, and we have no way to handle it right

Aimee Rinehart  36:58  
now. Well, and there's interesting research that came out in the last two weeks called model collapse, where if AI is trained on other AI written materials, then it somehow becomes less of itself and kind of falls apart. And so I think, if that research bears out, and it's true, you know, human written content will be more valuable than ever, because they need to feed on that content in order to in order to develop and grow and learn and to produce results that are close to human sounding, rather than this stilted robotic language. So that to me is interesting. And I think a space to watch.

Nikita Roy  37:41  
Yeah, absolutely. And one thing that I was quite interested in your background before you worked on AI, you were working with first draft in the misinformation space. So from combining that experience, and now with tentative AI coming to the mix, we've seen all of these examples. Where do you see that misinformation landscape heading towards? And how are we going to be able to cope with that?

Aimee Rinehart  38:05  
Yeah, you know, I think what generative AI will do, I think, for misinformation is it will enable things to be created cheaply. But the DIS distribution mechanism is still a cog. So they still have to figure out ways to distribute it, and a mechanism to make that distribution happen quickly. So I'm not saying we're out of the woods, or that everything was good on this topic, I think we are going to see a lot more slush, and a lot more problematic content, I'm worried about generative AI videos and photos around the election for candidates to use it in a way that is really disturbing. So, you know, in terms of like, building even more hyperbole into their into their attack ads and things like that, because it will be free mostly to use. And they're going to have to deploy real experts in that. That said, for a lot of people running campaigns, maybe their campaigns will be less costly because of it. I don't know.

Nikita Roy  39:14  
Yeah, well, that's actually a good way to see about the opportunity, we can stop it at the distribution. So there's still hope of like misinformation not just flooding everywhere, if we can stop it right that the distribution points. This is just been fascinating with all of your experience so far, delving into it. Oh, one of the final questions I have to kind of wrap up our conversation is looking into the future. How excited are you for AI? What's the most promising aspect that you're seeing in how generative AI could possibly change the way we're consuming news and what are you excited for?

Aimee Rinehart  39:49  
Well, I'm excited for the next year, because I think we're gonna see enormous creativity and innovation, especially at the local level, for how we reimagine News. We see news maybe it's an 800 word article and a headline and, and all of that, but it's like, but is that what is needed in the market? Now? How are people? How are people wanting information? And can we deliver it in a way in which people want? And I think like the search engines have asked themselves that very same question, can we do better than blue links? And the answer is, yeah, we can. And so now we're going to change how people's how people have searched for the past 25 years. So I think news ought to take a look at that, as well. And, and to, and to maybe see, are we delivering information and how people want it? And I think, yeah, I think the next year will be enormously creative, not without its trouble spots. And we'll see in the election in terms of the quantity of myths and disinformation and see if there's, if there are coordinated networks to help with that distribution cog we'll see. But, you know, I'm, I'm a curious student, always, I really like innovation. That's what led me to the work at first draft I had never, I didn't know that you could figure out how a piece of content arrived on the internet. And learning all of those magical tools was a lot of fun. And being able to teach that then to other journalists was fun. And then when AI came around, I was very eager to learn more in and I learned something new every day on the topic.

Nikita Roy  41:26  
Yeah, there's a lot of learning, I feel like we'll be doing over the next few years with AI. So it's kind of exciting and exciting ideas that you brought forward over here. So thank you so much for sharing all of these insights and the amazing work that AP is doing with especially helping local newsrooms bolster their AI efforts. It's been really great to know and thank you for just joining me on newsroom robots podcast and talking about all of this. Great, thank

Aimee Rinehart  41:53  
you for having me.

Nikita Roy  41:56  
Okay, well, that's it. Before I hit and record, could you just say your name, so I pronounced it correctly.

Aimee Rinehart  42:03  
It's plain old. It's Amy Reinhart

Nikita Roy  42:06  
Amy Reinhart. Okay.

"
newsroom_robots,15,"Thu, 20 Jul 2023 01:00:03 GMT",Mark Briggs: Creating an AI-Ready Newsroom Culture,https://www.newsroomrobots.com/episodes/mark-briggs-how-to-create-an-ai-ready-company-culture-W2NMBcOy,"<p>Mark Briggs joins Nikita Roy to discuss the core components necessary for building an AI-ready newsroom culture. Mark also shares the findings of a recent survey on audience perceptions of using AI in news.</p><p>Mark is the author of the widely-used book 'Journalism Next,' now in its fourth edition and used in colleges across the United States. He was a leadership and change management professor at the University of North Carolina, Chapel Hill, for six years. He will now teach a course on entrepreneurial journalism at the University of Washington in the fall. Mark has spent the past two decades championing digital transformation and innovation in the world of news.</p><p>Tune in to hear Mark’s insights on how to prepare your newsroom for the AI revolution.</p><p>Referenced in the episode: </p><ol><li><a href=""https://www.poised.com/"">Poised</a></li><li><a href=""https://feeds.acast.com/public/shows/64c86a5585617f0011a4a263"">Oasis AI</a></li></ol><p>Thoughts or questions? You can reach us <a href=""https://forms.gle/egyJZDsGjogiyNTH8"">here</a>.</p><br /><hr /><p style=""color: grey; font-size: 0.75em;""> Hosted on Acast. See <a href=""https://acast.com/privacy"" rel=""noopener noreferrer"" style=""color: grey;"" target=""_blank"">acast.com/privacy</a> for more information.</p>","Nikita Roy  0:00  
Oh, this is newsroom robots, the Podcast where we explore the intersection of artificial intelligence and the news industry. I'm Nikita Roy, a data scientist, media entrepreneur, and one of the many founders currently building their ventures at the Harvard innovation labs on the newsroom robots. I'm excited to bring you insightful conversations with industry experts about how AI is impacting the way we do journalism.

Joining me on the show today is Mark Briggs, the author of the widely used book journalism next now in its fourth edition, and used in colleges across the United States. Mark served as a professor of leadership and Change Management at the University of North Carolina Chapel Hill for six years, and will be teaching a course on entrepreneurial journalism at the University of Washington in the fall. In today's episode, we discuss the findings of a recent survey on audience perceptions of the use of AI in newsrooms, and also delve into how leadership can build an AI ready, newsroom.

Hi, Mark, welcome to newsroom robots. I'm so excited to have you on the show today.

Mark Briggs  1:20  
Hi, Nikita, thank you for having me. I love your podcast. So it's an honor to be here.

Nikita Roy  1:25  
Thank you. I'm really excited to have you today. Because your firm, the Smith Geiger group has recently released a Soviet report that provides valuable insights into how audiences are thinking about artificial intelligence. And I think we've had a lot of conversations on the podcast so far talking about how newsrooms are using AI. But at the end of it, it's all about what audiences are thinking about. They are the center of our work. And so I'm really interested in hearing, what were some of the main findings in the report that you came away with?

Mark Briggs  1:57  
Well, the survey was across the nation, a sample size of 2000. So is a really nice big sample. And what it told us on the top line is that AI is still a nascent technology in the minds of most people in the audience that a quarter of people honestly have said they had never really heard of this technology that can create this generative version of AI that, of course, in news and journalism we've been fascinated with for months now. So I thought that was a little bit of a surprise, we did learn that about 20% of people had already tried some form of generative AI. And that seemed to be about what I thought would be what we would get, you know, sort of those early adopters is really what you would expect to see in this kind of new technology that is transforming so many aspects of our lives. The other piece of it that we had a good time talking about on the webinar this week was, you know, just that fear around AI, it really has this technophobia aspect to it. And that came through in the research as well, that 60% of attendees, you know, of the webinars, so they're even proceeding with caution. And these were leaders and executives from a vast array of media companies. And so even the people who are running the companies who should be moving faster, potentially, on all of these technologies are taking a slow approach. So there's still a lot of caution right now. And the other piece of the research, you know, from the doom and gloom side of things, people said that, you know, 60% of the people said that AI will eventually do more harm than good. 80% Want some limitations to it, you know, some restrictions, maybe, you know, some guidelines, or maybe even, you know, some government intervention here, which I think is really interesting, and probably would score higher than almost any other facet of our culture.

Nikita Roy  3:49  
Yeah, I see that doomsday Buzz is really kind of hit gotten into the perception of AI and people are really bringing forward that technophobia. I'm wondering how that's really going to be affecting the adoption of AI specifically in journalism, as audiences are more concerned about AI and the use of AI and the news that they trust. How are they envisioning AI being used in newsrooms?

Mark Briggs  4:15  
Well, to me, I think it's important to look at this in separate buckets. And so I put the synthetic media and the generative AI of functions and possibilities and risks into one separate bucket. And for a lot of organizations right now, I would even advice just put that to the side and think about the other two buckets. One of those buckets is simply processes and workflows, streamlining tasks, automating or assisting with a lot of the you know, paperwork, busy work admin work that we have to do just as information workers. So that's, there's an entire bucket of opportunity there. And then the third one, which is the one that I think gets the least amount of attention, especially in the news and journalism world is me management, leadership, coaching, training. These are all incredibly important aspects to any organization. And AI is going to actually impact in a positive way, I think, each one of those elements, but we're not even talking about that. So you had Dahlia on your last podcast talking about, you know, this wonderful tools, database and all of the things that the partnerships for AI all those resources that they're building, how does that get into an organization? That's called management and leadership? So focusing on that aspect of this puzzle, I think, is really important. Ethan Malek, the Wharton professor, who is, you know, at the forefront of most of the conversations right now on this topic recently said that he considers management, that technology. And so if you think about management, as a technology, and good management will actually increase performance, increased productivity, and really, obviously, build better cultures, you have to think about how does AI enter an organization? And how does an organization utilize it and leverage it to its best abilities in a safe and responsible way? All of that is management and leadership.

Nikita Roy  6:09  
I want to get into that, because that's your expertise and helping management adapt to all of these transformation. We are at the cusp of I think one of the biggest changes in the way work is being done with AI coming into the mix, and especially synthetic AI. What's the biggest advice? Are you giving management and leadership folks in terms of incorporating the culture of AI into their newsrooms and their companies getting buy in from various different stakeholders?

Mark Briggs  6:39  
One of the topics that we've been talking about in our firm and I touched on in the webinar this week is how do you become an AI ready organization. And as someone who has spent the last decade going deep on organizational effectiveness and working with media companies, I see AI and all of the opportunities as really the ultimate organizational challenge. If you look at the research behind what creates the most successful companies, it really comes down to two things, if you only could pick two, you would pick clarity, and you'd pick adaptability. Because if an organization at all levels among all teams is clear on the focus, the direction and the mission, they are going to succeed at a much higher level than organizations who aren't sure what the mission is, aren't sure what our goal is, and what our priorities are, what's our North Star, all of these elements to an organization come back to leadership. And then adaptability. Obviously, when you're turning around, and trying to adopt all these different technologies, that will touch every team in your organization, and every person in your organization, you're gonna have to be adaptable. And so I really feel like building that culture already. You know, if you don't already have that, wow, that's you got a long way to go to get going. If you do have a culture, that really prioritizes clarity and adaptability, you're going to be much quicker at being able to adopt these new technologies and leverage them in effective ways. I think the first thing you need to do as an organization right now is organize a team or even a person who's going to be the point for all of this, because there has to be somewhere to go with the ideas with the questions with the experimentation that it takes to really sort through all of the tools that are out there, and try to figure out what works best for which team, your Human Resources team is going to use this differently than your sales team, than your recording team than your photography team. It just isn't like, okay, magic button AI, everything gets better. It's gonna take so much experimentation, adaptability. And that collaboration is a big part of your organizational effectiveness and a big part of your culture. So this is really going to be a test for organizations on those friends. And those are things that hopefully people have been working on for years, if not decades. And if not, it's really going to be hard for them to get up to speed and utilize these new technologies in the best way possible.

Nikita Roy  9:10  
Yeah, and exploring that idea of becoming an AI ready organization more. For many traditional outlets, it's taken a long time to even just move to becoming a digital newsroom and becoming a digital publication. Now with AI coming. It's daunting. And there's also a lot of skepticism around that in the industry. A lot of hesitancy to use it to be openly using AI in workflows, concerns about data privacy. How should newsroom leaders be thinking about all of those concerns, but also trying to stay on top of being innovative and using AI?

Mark Briggs  9:46  
I think it comes back to something I mentioned recently is which is called the lighthouse approach. And it's a wonderful framework that has been around business schools and management consulting for a very long time. And as I said on the webinar this week, If you don't know how to implement the lighthouse approach, you can just ask Chad GPT. And it will give you a process to learn how to implement the lighthouse approach in your organization. Now, as a management consultant, Does that scare me and make me feel like my job is going to be eliminated? Actually, no, it just gives me a sense that oh, now I can actually help people understand quicker, why you might need a management consultant, or why you might need this really thought out process for implementing something new like AI. So the reason the lighthouse approach is effective, especially with regard to AI is what it means is you build your lighthouse, right? You define what that is. And you are able to communicate that to your entire organization and say, This is how we're going to implement AI in our organization. These are the guardrails, these are the guidelines. And this is where you can come with questions. This is where you can come with ideas, we're gonna really foster and facilitate this collaboration around sorting through all of the noise that's out there, and figuring out what makes the most sense for our organization. Because it all comes back to what problem are you trying to solve? What process? Are you trying to streamline? You know, what news process are you trying to make better. And so looking at it from the problem or the challenge first, and then trying to figure out where AI assisted tools can help you makes more sense to me than saying, let's go look at all of the AI out there and see where we can fit it into our organization, because there's just too much and it's moving too fast, that you're not going to be able to really figure out what the landscape looks like and know exactly what would be most useful for your organization. So you have to go from the inside out, I would say. And that's where coming back to that, you know, workgroup or task force or whatever you want to call it is really essential, because then your investigative reporting team can come back and say, Hey, we really need a tool that will help us scan 1000s of documents. Have you guys seen anything, you know, and then now it's an assignment and people spend their time trying to find out what the best tool that would be? And then you have to apply? Of course, the framework of what kinds of tools are we going to allow? Did we check the risk on this? Did we check, you know, what our protections are on this where the privacy arguments are? So again, it's going to come back to being a lot of little things. Unfortunately, it's not really this sort of one size fits all, or even this situation that we all had a news in journalism, you know, 20 years ago, and 10 years ago, when the internet first impacted and disrupted our industry. Think about mobile, and when impacted and disrupted our industry, a lot of news organizations, were able to form a product to build a mobile app, start publishing to smartphones. And that was, you know, fairly siloed. This is not that this isn't going to be a let's the AI team is handling it and they're over there in the corner, there just isn't going to work. This has to be touching everybody in the organization. But to get started with that, you have to give everybody a sense of where they can go with their questions and their ideas. And that's why I think the lighthouse approach is really important. And that's why I think forming a working group and getting started is really important.

Nikita Roy  13:16  
I really like that approach, because it's not siloed anymore. And AI is not just this one big giant term that people are all just working on alone. And it's really cross disciplinary and people across different newsrooms and teams are able to kind of bring together their knowledge and share that. And that's where I think the real power is. So how with all of these, like, lots of AI tools, keep on coming into the market and promising good and with this huge landscape that's coming about I'm overwhelmed. I remember signing up for like a lot of AI tool newsletters in the beginning. And every day. Now, it seems like there's this new AI tools that keep coming up. And you dive into some really interesting tools as well. How are you keeping up with all of that noise and finding out what's good? And how should newsrooms be looking at that landscape of AI tools at the same time?

Mark Briggs  14:09  
It's a great question and a great challenge, because I don't believe there is any way you can keep up. There's a website called there's an AI for that.com, which, every day I see that it goes up another few 100 tools. It's over 6000 tools for like 1800 different tasks. There's no way to know everything in there. There's only knowing what you personally or you as a team or you as an organization feel like you could solve with a tool in AI. And then there's the communication and the sharing aspect of it. So I feel like that is just starting to form where people are starting to tell one another how they're using AI. They're starting to ask one another how are you using it? Have you found a useful tool, and I believe that that is going to help organizations more and more with that kind of sharing. I feel like Oregon negotiations leadership, probably don't even know who's using what in their organization. And that's a big first step, you need to have an AI asset registry or an AI tool repository or some sort of an air table database or whatever you want to do. But allow people and ask them to obviously communicate and sort of raise their hand and say, I'm using this tool for this process, and it is working really well or I tried it and it didn't work at all, so that everyone else knows, don't waste your time with it, or definitely start using it. Or maybe it's somewhere in between. But that sharing in that communication around what is working, is the only way that people are going to figure out how to sort the, the signal from the noise, because no one's going to ever catch up with everything that's coming out, it just is happening too fast.

Nikita Roy  15:53  
I like that idea of the AI tool repository, I think that really brings about that sharing and collaboration, that culture that could be established within companies to understand AI and help everybody get on track and on the same board as everyone else and see what people are actually doing. And what I'm really interested in is when you're talking about, you touched upon it a bit in your Silvia report I'd seen about synthetic AI and generative AI. That's the big thing that people I think are really excited about right now. Automation has been around, people have been using it but probably didn't realize that that's what they were doing. So with auto, synthetic AI coming about, how do you see newsrooms using that, first of all, and what was your outtake from the report in terms of how public are looking at synthetic AI and being used in newsrooms?

Mark Briggs  16:46  
I think it's important to look at that question from two different angles. And the first angle, let's talk about the journalism part of it the public perception, the audience expectation on this, I think people don't understand how much AI they're experiencing everyday already. For example, if you have a local news app on your smartphone, there's a good chance you're getting an AI triggered, severe weather alert from the National Weather Service. So that's AI content. But consumers in the audience are ok with it. Why? Because it's trusted information. And it's useful to them. So that doesn't change. So as you think about generative AI, and you think about the opportunities, and you start experimenting with the systems that produce this content, it'll be the same journalistic test we've always applied. Can you trust it? And there's a new term floating around with AI, which is called explainability? Can you explain where this current came from? So that's new, but the rest of it isn't new. The rest of it remains? Can you trust this information? Is it useful? When the Wall Street Journal and The Associated Press starting using a AI for sports and business news years ago? No, that was the test they applied? Could you trust it? Was it, you know, verifiable, vetted information? And was it useful to the audience? Then it works? Right? So if you are going to use AI, and this is sort of my I guess, pipe dream is that someday, all of the hyperlocal news that we have been trying to solve for, for 1015 years now, right? The the idea that the internet was going to create this ability to cover news, specific to a geography in a very small way. So instead of writing one news story, you're going to write 20 different news stories for 20 different neighborhoods or areas in your market. So AI is going to help us do that. So what's going to be the test on whether we should or not the test will be can you verify and trust the information that's contained in those reports? And is it useful to the audience? So it really comes back to the touchstones of journalism, and the values and the ethics that we've always had. We don't leave them behind, we just move forward with them and start using new technology as we do that. The other angle on this that I think is really important, again, that I haven't really heard too many people talking about yet. And largely because people are still a little bit afraid of getting too far into this with the legal the copyright and all the other risks that are inherent. But it's related to the burnout issue that is crippling the news industry right now. So rtdna and Syracuse did their report a couple weeks ago found that nine in 10 news directors are struggling with and actively trying to solve for burnout in their newsroom. And I have this wild bullish opinion that AI is going to help mitigate some of this and actually potentially, partially, quote unquote, save the news industry because these jobs have become so demanding. There's so many platforms to publish to. There's so much short staffing because of layoffs. There's the hours are terrible. The pay isn't Ever been great. So these are, you know, these are challenging issues to solve as an industry. So what if AI does what we always hope automation will do, and free us from the most annoying and repetitive parts of the job so that people can focus on being more creative, more collaborative, more thoughtful, and less burned out. So, to me, there is an urgency around trying to analyze and evaluate and experiment with these generative forms of AI. Because the burnout crisis is acute, and it's happening, and it's like a wildfire across a lot of organizations right now, that needs to get solved. And it needs to get solved sooner rather than later. So that the industry can remain at least somewhat viable, and maybe even have a more promising future. What if we're able to do more news, more effectively more targeted, that resonates more with audiences because of AI, all of a sudden, that affects our overall business equation, we now have more consumers, we have more subscribers, we have more audience. And it's a targeted, loyal audience that's coming to us because we're a trusted brand, instead of all of the AI generated trash that's going to be flooding the internet and already is. So I think there's a real opportunity, if you put on some rose colored glasses, which I wear all the time, you can say that AI is probably going to help the news industry more than it's going to hurt it. And that certainly is my hope. But we can I think as an industry helps shape that path. By getting going with a lighthouse that's on the promising side of the ocean, and not the lighthouse that's on the negative side. So it really is about trying to, to have everything break towards the positive side of things, instead of just standing on the sidelines and being afraid of what could go wrong.

Nikita Roy  21:56  
I like seeing AI through the rose colored glasses that you have on and seeing especially how it might help mitigate the burnout issue. I remember talking to someone recently who was worked in broadcast news for over 10 years and then night shift. And that really led him to burn out and just imagine for people working on night shift if there is something that could help them automate and make work easier. And that could just alleviate his burnout and not have to leave his role in his news industry that he really enjoyed. But the flip side of that is really talking about job displacement. And the threat that that brings about with jobs. There's a lot of survey results coming about about how AI can impact the job industry. And there's a lot of concern right now, especially for you've been a journalism professor, I teach students journalism for your students that are coming into an industry which has been experiencing a lot of layoffs, the state of for profit outlets, and are worried about their future right now. Is AI going to be creating new jobs in the newsroom for them. How is that job displacement and shift looking like,

Mark Briggs  23:05  
to me AI is not going to be a category of jobs that people are going to target and go into. So there was certainly digital product development became new jobs in the news industry, when the internet and then smartphone technology came along. There will be some of those jobs very, very small amount of product jobs, but I feel like those already exists. And people in product jobs will just start using AI. But what AI stands to serve the news industry with is better experiences as news professionals. And as journalists, which is only going to make the businesses and the companies and organizations that are doing the news stronger, which then creates more opportunity for more jobs. I feel like it's always going to come back to what we're trying to solve for in the first place with news and journalism, which is the critical information, being the watchdogs of a community, celebrating a community with news and information. And these are just new approaches and potentially new tools to do what we've always tried to do. But I do feel like the way that AI can change the work, we will get better at that. Do it with less and burnout, and potentially then create a more promising future for all those journalism students, even if the jobs don't feel incredibly different. So if you're a video editor, and you're using AI to go through decades of video archives, and you're able to find video faster because of an AI tool, you're still a video editor. If you're an investigative reporter who's using an AI tool to scan 1000s of documents for critical information. You're still an investigative reporter. So it's not like the AI team over there in the corner is going to do the AI parts of the job and then give it back to the nominee. AI people, everybody's going to be an AI worker. Marc Andreessen recently said that every person, this is not new specific this is every person someday will have an AI assistant, slash coach slash mentor slash trainer slash advisor slash therapist. That is, and I love this part, infinitely patient, infinitely compassionate, infinitely knowledgeable and infinitely helpful. Very talk about well colored glasses, right, that's as promising as it can get. But in that world, of just thinking about the news industry, those people in the trenches who don't have someone to support them, someone to turn to, with a question someone to turn to, with a challenge, someone who can guide them, train them on something new, hey, I have an idea, I wish I knew how to do this part to put into my newscast are put into my news story. And now AI is there to help you figure it out much faster, so that you can do it within the confines of your shift and not have to go to some training pointer for three days. These are nothing is pointer, I love pointer. But the point is, there are going to be different ways that jobs will improve. As long as going back to the organizational piece, leadership understands, we've got to work hard and understand and embrace this and find the good and really double down on developing people with the use of this technology to be the best people they can be. That's the future I see with AI. It's not replacing, it's assisting. And I think that as a news organization, if you take that approach, you're going to find the ways that it will help you and assist you right now, as you go forward and try to get through this uncertain period of time. But I think all comes back to starting with a positive approach, saying, let's find a way to use this today. And if legal and copyright concerns, keep us from even thinking about using generative AI in consumer audience facing forms. That's fine. There's a whole other two buckets that I mentioned, of work that you can be doing right now as an organization on automating processes and tasks. And on leadership management, coaching and training. How can you use AI for these different tactics, these different demands? Those are the questions that I think organizations should be trying to answer first. I like

Nikita Roy  27:30  
that idea of having a patient coach for people entering the industry. Do you see institutions kind of having this like knowledge repo that's now helped by AI to get their information out to support their organization, but then also to get more news out to people? Is that the kind of a future that you've been seeing?

Mark Briggs  27:51  
Possibly, I think about a pointer workshop I went to in the mid 2000s. That was for training the trainers. And so back in the heydays of news organizations, they were you know, people who had newsroom training jobs, and they would all come together a pointer and we would all, you know, talk about how are we training our newsrooms on how to do better reporting how to, you know, create more beat development, how to cover government, how to, you know, any one of the many different disciplines and challenges that come with journalism and news, you know, and a lot of those jobs have gone away, most probably. So there's this training element that has disappeared from news and any of the organizational research, you can look at around the development of people, giving them a sense of learning and growth. This is the first way to try to offset that burnout. And all the people who have left the industry, you know, have their own accord. So if we can get back to a place where we're training people, I think that they are going to get more out of their job, they'll be more fulfilled, they'll feel like they're at play again. I think though, one of the things that you notice, if you've been in newsrooms is that people really like their jobs on some days. And those are the days when they feel like they're collaborating, they feel like they're tackling that breaking news story. They're feeling like they're developing and producing that big scoop. You know, there are times where people are just lit up, the energy in the room is just palpable. And we need to find more of those days. And I think that AI is actually going to help us get there by taking away a lot of the drudgery, or at least assisting us as we get through some of the drudgery so that we have more time for learning and growth and training and collaboration and creativity is something as simple as having AI, you know, take your meeting notes for you and send out summaries, you know, does that change your organization? No, but it's a drop in the bucket of like, how are we changing so that we're doing less So the the wrote practices and tasks that AI can do for us and spending more time being humans and collaborating, and leading and training, and doing those kinds of things that make us feel like we're really alive. And we're really part of this business. And I think that, in a strange way, all of these robots and all this technology, you're going to help us be more human than we've ever been.

Nikita Roy  30:21  
Yeah. But setting aside that rose colored glasses for a second, what are you seeing as the biggest limitation for AI right now that you've been bumping into, other than just like, I know, the hallucination of AI has been the biggest concern. But other than that, what should newsrooms be keeping in mind in terms of the limitations of AI?

Mark Briggs  30:42  
That's a difficult question to answer simply because it would need to come with in this situation, like what is the use case that we're talking about. And if we're talking about generative AI for consumer facing news, then certainly it comes back to where is the information coming from and the vetting of that information. I believe that what AI is doing the generative AI tools in terms of using pattern recognition to match words, is doing 80% of the work in a lot of cases. And I think as long as people understand, that is what you should expect, you should expect 80% At most, there's still 20% human intervention that needs to happen with anything that AI is doing currently, then your expectations, I think are more accurate, and your expectations are less likely to be disappointed. When it comes to the risks to privacy, the copyright and those kinds of issues. I mean, it feels like real quickly, we all got to the point where the large language model that Chad GPS is built upon, is great for some things. But it's not great for proprietary information. It's not great for like Smith, Geiger, as an audience research firm primarily. And so we do a ton of audience research. For big media companies and local news companies and all kinds of companies, we would love to use chat GPT to go through these, you know, 1000s of open ends on a survey and come up with all this great insight. But we're not going to put our proprietary data and our customers data into chat GPT, we are going to build a private secured, you know, firewalled repository of our own information, then use that chat GPT technology on top of it. So that we're protected, as we're using the tool to sort through 1000s of open ends and find the key insights sets that are going to help our customers and our clients and we're going to save so much time by doing that. So I think it's just a matter of understanding where the technology can work for you. And, you know, obviously, where the line is between trying to use it just to be more efficient, but also know where you're gonna get yourself in trouble and take on too much risk.

Nikita Roy  33:04  
And you know, while on that topic of chat, GBT, I want to talk more about tools, specifically, because I learned about some tools from you, like pies, which was an AI powered Communication Coach, we were on a zoom call before and you told me about this. And it quickly became my go to tool for helping me become a more effective communicator. So I really want to know more about what tools are you find the most useful right now that is helping you in your day to day tasks?

Mark Briggs  33:34  
Yeah, I love poised. And it is interesting how once you get past the first, I think first report on your resume, quote, unquote, performance, you understand that there's no ego with the AI. And so when it says things like you sounded tired, you don't get offended. When it says things like you talk too fast. You're like I know. And when it says you use too many filler words, you understand that? It's just trying to help you get better. And I think that's important to understand with any of these technologies. Interestingly on that, before I answer your question, they're now developing and already seeing that there will be a poised like, feature for doctors. Imagine this. So you're the patient and the doctor is listening to you with AI. And the AI is now going to recommend follow up questions. And the AI is going to recommend, what more information do you need? And so, okay, is that do you want to outsource and replace your doctor with that AI? No. But would you like your doctor to have AI? Probably. And so I think that's a good way to sort of open your mind to the possibilities of again, how is it going to assist us? It's not going to replace us. I think my favorite tool other than poised is definitely Oasis, which we did talk about already. But Oasis is a smartphone app that takes your text or your speech, or as I call it, my word vomit and it turns it into really eloquently written prose for a LinkedIn post or work email or a memo or it has all these different kinds of outputs that you can choose. And you just speak a few sentences into it. And it produces, you know, many sentences, it's not paragraphs, what you are trying to say, again, it's giving you 80% of the work, and you have to expect that you're gonna go in and add the 20%, and edit it and clean it up and take away some of the hallucinations, which are kind of entertaining, honestly. And that's probably my favorite other tool right now that I'm using is other than maybe the ai dj on Spotify, which I've also found to be pretty fun.

Nikita Roy  35:38  
Oh, cool. The ai dj. Yeah. So

Mark Briggs  35:41  
every every Spotify user, if you click on the music button, x is the ai dj, and he's actually a real employee at Spotify, apparently, and they just synthesized his voice. And then he'll tell you, Hey, this is some stuff you've been listening to recently, or, Hey, this is what you were rocking last summer. And it'll play you some songs from your catalogue based on what you've been listening to. So I just got back from a run. And I was listening to the DJ on Spotify. So that's kind of fun.

Nikita Roy  36:08  
And, you know, as we wrap up all of these cards, this conversation today, what I'm really interested in hearing is looking into the future. How are you seeing AI going to be continually evolving with newsrooms? And where do you see the whole culture of management and leadership evolving towards and incorporating AI as they support their newsrooms through this transformation,

Mark Briggs  36:35  
I hope that AI forces organizations to finally fully address the cultural and organizational effectiveness challenges that so many have put off to the side for so long. The culture in most newsrooms that I've been in, and I've been in a lot, embrace, communication, embrace accountability, embrace trust, all of these aspects that, you know, business, schools and management consultants would recommend, until news breaks. And then when there's breaking news, or someone else comes in with something more important, they push all that to the side. So the short answer is culture and organizational effectiveness, have for too long been a nice to have for news organizations. And I think AI is going to force it to be a must have, because I don't believe that organizations are going to be able to fully implement and leverage the power of this once in a generation technology, unless they get their house in order with regard to communication, and clarity, and adaptability. And that's going to take some really hard work for people to change their cultures, I've had the opportunity to basically redesign blow up and redesign newsroom meetings, editorial daily meetings, in 20, plus newsrooms, and I can tell you that and half of those, they just reverted back to their old ways of doing things. Because the culture as we know, eats strategy for lunch, a well known phrase. So as you try to implement any of these AI tools are trying to get the organization interested in experimenting and learning, which of the tools will work best for which situations, it will require a level of clarity, a level of collaboration, a level of accountability and visibility, that, frankly, isn't inherent in most news organizations. So for me, it's a really interesting crossroads that news organizations are facing, and that is, you know, can we get the structural organizational pieces in place to actually level up what we do thanks to this new technology? Or are we going to, you know, outsource it or, you know, form a team or a person and expect them to sort it out all for us. But again, until you have that leadership, until you have that culture that can embrace it. And really be clear on the benefits and also the risks, you're not going to be able to fully leverage the potential that these tools are going to offer.

Nikita Roy  39:20  
That was some ways where it's there, I think, yeah, importance of having a culture in the newsroom. And organizational structure is important for us to be able to leverage AI in today's world. And it's been fun looking at AI with the rose colored glasses that you had on and hearing all of your thoughts today. And thank you so much for sharing all of those important insights with us. And joining us on this exploration of AI in newsrooms, and thank you for joining newsroom robots.

Mark Briggs  39:50  
Thanks so much for having me. This has been very fun and it's been a pleasure talking to you.

Nikita Roy  39:56  
That was smart breaks. The author of the book, John Listen next. This podcast is made possible. Thanks to the Harvard Innovation Lab Spock grant. I'm Nikita Roy, and this is newsroom robots.

"
newsroom_robots,14,"Wed, 12 Jul 2023 16:44:59 GMT",Dalia Hashim: Building an Ethical AI Strategy & Tips for Engaging with AI Vendors,https://www.newsroomrobots.com/episodes/dalia-hashim-building-and-ethical-ai-strategy-tips-for-engaging-with-ai-vendors-vW0IxmXa,"<p>Dalia Hashim joins Nikita Roy to unpack the nuances of incorporating AI into journalism. She provides critical questions to consider when engaging with AI vendors, elaborating on facets of clear communication, comprehension of tool limitations, and the importance of oversight. Dalia also delves into the ethical quandaries with AI use in newsrooms, particularly around potential job displacement. She offers insights on building an ethical AI strategy. Dalia also shares the future plans of Partnership on AI to help newsrooms.</p><p>Dalia Hashim is the Program and Research Lead for AI and Media Integrity at Partnership on AI. She focuses on the intersection of AI and local news and works extensively on understanding how AI policies and interventions can minimize the harmful impact of AI in various industries. </p><p>Before this role, Dalia made significant strides in AI policy development in the Ontario Government. As a founding member of their AI policy team, she helped write and pass Canada’s first digital law. Most recently, she served as a Senior Policy Advisor to Ontario’s Chief Digital and Data Officer, providing key insights on Ontario’s digital and data strategies.</p><p>Referenced in the episode: </p><ol><li><a href=""http://docs.google.com/document/u/0/"">Partnership on AI’s Responsible Practices for Synthetic Media</a></li><li><a href=""https://airtable.com/shrQeIsvzGoTbdp7b/tblvwDhL4X23V1pTp/viwN8zctay9H2N0ir?blocks=hide"">AI Tools for Local Newsrooms Database</a></li></ol><p>Thoughts or questions? You can reach us <a href=""https://forms.gle/egyJZDsGjogiyNTH8"">here</a>.<br /> </p><br /><hr /><p style=""color: grey; font-size: 0.75em;""> Hosted on Acast. See <a href=""https://acast.com/privacy"" rel=""noopener noreferrer"" style=""color: grey;"" target=""_blank"">acast.com/privacy</a> for more information.</p>","Nikita Roy  0:02  
This is newsroom robots, the Podcast where we explore the intersection of artificial intelligence and the news industry. I'm Nikita Roy, a data scientist, media entrepreneur, and one of the many founders currently building their ventures at the Harvard innovation labs. On the newsroom robots. I'm excited to bring you insightful conversations with industry experts about how AI is impacting the way we do journalism. Joining me on the show today is Dahlia hushan. The program and research lead for AI and media integrity at partnership on AI. She focuses on the intersection of AI and local news, and works extensively on understanding how AI policies and interventions can minimize the harmful impact of AI in various industries. Prior to this role, Dahlia made significant strides in AI policy development, and the Ontario government. As a founding member of their AI policy team, she helped write and pass Canada's first digital law. And most recently, she served as a senior policy adviser to Ontario's Chief Digital and data officer where she provided key insights on Ontario's digital and data strategies. In this episode, we touch upon the key considerations, newsrooms should take into account when procuring AI tools, and discuss guidelines for building an ethical AI strategy.

Dalia welcome. And thank you so much for taking the time to join the newsroom robots podcast.

Dalia Hashim  1:37  
Thank you for having me, Nikita, it's great to be with you.

Nikita Roy  1:39  
So I'm really eager to hear more about you from all the work that you're doing. Your organization partnership on AI is truly spearheading the cause of responsible AI use. And so I want to start right there for our conversation today. What does responsible AI usage really look like? And how is partnership on AI playing a role in this field?

Dalia Hashim  2:05  
It's a fantastic question. Responsible Use of AI really just refers to like understanding the entire ecosystem that a AI system or AI tool that is being used exists in. And so it's just a way of not just evaluating the use of a particular tool itself. But to also be able to understand how that tool was developed, where the data was sourced from, how it's being implemented, what impact does it have on like libre, on the organizational culture, on the entire ecosystem in which it exists? And how can we prevent the negative impact of AI throughout that entire process within that entire ecosystem, and not just looking at the AI tool or system on its own, kind of independent from all of the other impacting forces that might exist around that tool?

Nikita Roy  3:00  
That's basically talking about all of the different topics that I want to touch upon with you today? And I like to really get a sense of but how are you currently helping journalists navigate this complex landscape of AI? And can you share more about the work that you're currently doing to shape the landscape of use of AI in newsrooms?

Dalia Hashim  3:18  
Sure. So we received a Knight Foundation grant a couple of years ago to be able to do a lot of the work that we're doing along with some of the other organizations that are doing similar work on responsible AI in newsrooms, including the AP and the New York lab, and others. And so what we've been doing is trying to create a toolkit for the responsible use of AI that's directed at newsroom that kind of provides them with resources to be able to support AI adoption, understanding that a lot of local news organizations are at the very beginning stages of using AI in the newsroom. Either they've used it very lately, or they haven't used it at all and are kind of just thinking about it. So putting ourselves in the newsrooms, shoes, what would be helpful to have as far as resources are concerned, and that's kind of what spurred on the toolkit. And it was really spurred from feedback that we had received from local news organizations and news organizations at large. What when, you know, we went out and asked, you know, what, what are you looking for what can kind of support your current ecosystem, because that's like a big ethos of how we operate at partnership on AI, is through convening, bringing folks around the table and really hearing from them what's needed, but also being incorporated of their feedback in the work that we do every step of the way. And so we started off by developing an AI tools database that can kind of just catalog the tools that are already out there that are being used by newsrooms, or available for newsrooms to use than our AI tools. And one of our biggest ads to creating this database came from newsroom saying, you know a lot of the websites that we see talk about AI tools, but we don't really understand a lot of the jargon that's being used on these tools, and what their value add will be to our newsroom. And we feel like we're being oversold on a lot of these tools. And so the the main value add of the database wasn't just a catalog what the tools that existed were, but it was also to be able to play in language, what they did and what their core offering is, so that at a glance, you can kind of get an idea of what the core offering of a particular tool is, and what was kind of sprinkled marketing, you know, in a sense that you can kind of get from their website, and then we kind of included as much additional information as we could, including the level of like technical knowledge that you need to have in order to operate it, what type of AI you'd be dealing with. And to the best of our ability, the cost I'll be a lot of these tools don't are not very transparent in principle, the cost of of using them. So that was kind of the first phase was the database. And then we wrote kind of like an analysis blog post, kind of looking at the field in general, and trying to do an assessment of the various types of AI tools that are available. So we categorize them into like five broad categories. And then we did like a little bit of an assessment of like pros and cons, like, here's how it might help your newsroom to use this types of tools. And here are kind of all of the risks that are associated with using these tools, so that you know what you're getting into when you're saying, Okay, we want to use a tool to help support audience engagement, for example, your all the things that you might want to keep in mind in that process. So those kind of are the first two products from our toolkit. And then the third one that we're currently working on are in the final stages of publishing is the procurement guidebook. So we're working on a guide book that really walks newsrooms through the entire process of procurement for an AI tool and starts at the very beginning, you're just thinking of procuring an AI tool and goes all the way through not just the procurement, but the adoption, the governance in the newsroom, and then takes you all the way to the end of when should you consider retiring the tool. So it kind of, you know, goes through the entire lifecycle and isn't just intended to serve, you know, newsrooms that are looking to purchase a tool or to procure them. But also, if you're like, kind of creating them in house, which is what we see a lot of newsrooms, do they have the ability to, though develop their own tools in house. Okay, what kind of questions should you be asking even within your newsroom one year developing a lot of these tools. And again, this is not a guidebook that we've kind of created in a vacuum. It's been informed by a steering committee that we put together. That includes some of the larger newsrooms, including the AAP, the BBC, the CBC, and others, but also includes other civil society organizations like journalism AI, and includes tool developers like lead AI, and includes academics as well from various academic institutions that are doing research around the field, just so we can kind of get a rounded group together that can provide direct input into the work that we're doing. So it's not just me and my laptop and my research typing away. That's kind of an overview of our current work and what we have going on on partnership in AI. Let's focus on newsrooms, I know this was a long winded answer, but I really wanted to get into it with you.

Nikita Roy  8:12  
Yeah. Well, that's exciting to see the broad range of products that's coming out to help support newsroom's. And I want to delve a bit deeper into regarding AI tools. Specifically, there's a lot going on in the AI world, as you know, a lot of vendors, plugins, generative AI tools, people just promising solutions that will transform the way that you work. And as newsrooms, when they come across all of these tools. What are the key considerations that you think that we need to be thinking about when engaging with any external AI vendor? Be it like a tool, or a company that's promising to build something for you? What should we be considering?

Dalia Hashim  8:50  
There's lots to kind of consider from the get go when you're thinking of you no adopting an AI tool, first, within your newsroom, right? To be clear on why you need an AI tool, like what are you solving for? Is there a particular problem that you're hoping that like a technology piece added to it can solve? Is there an area of work that you're not able to get to and you're hoping that you know, this AI tool helps you broaden the types of news that you're able to provide to your listeners, readers, users, whatever media you use to kind of provide news in, but being very clear on why you need a technological solution is kind of 30% of the journey. And it's very important, because that's how you're you can ask those questions of the tool developers to make sure that what they're selling you on isn't just something that is super cool, or really trendy and you've heard other newsrooms are using it, but it's something that you actually need and will fill a gap. And so being able to answer that question from the get go, being able to say, Okay, this is where we're at as a newsroom, and like going back to the audience engagement. kind of question. This is where we're at an audience engagement, we hope that adding you know, an AI tool can help us reach new audiences, whether through like different languages or in different mediums, or even being able to like optimize our content online so that it reaches new audiences. But here's our baseline of where we're at right now. And this is what the additional tool can help solve for us. So then, once you're meeting with all of, you know, these tool developers, or you're, you know, looking through their websites, you have something that you're measuring against, does this actually help me accomplish a school or does it not? So that's kind of the first step of the way. And then when you're looking to evaluate the tool itself, you get to ask questions about how was this tool created? Like for what purpose was it created? Is audience engagement, for example, the main offering of this tool or is it that in addition to, you know, three or four other offerings, because that's what we see from a lot of tools that exist in the market is that they offer to do transcription, but also translation, but also, you know, post online for you and post on different, you know, social media platforms. At the same time, there's no way that they're doing all five of these things, you know, to an equal caliber. So what is their core offering? What is the main thing that they're really good at, that they're selling you on? And what are the other tangential nice to have, because if you're looking for something that will do translation, and the core offering of a particular tool is actually transcription really well. But translation sometimes are in you know, only one or two languages really well, and you're buying it for that reason, then it's not going to give you what you're looking for. So kind of being really clear on the other end, as well, from the tool developer, as to what the core offering of that particular tool is, you know, is really, really important. So that's kind of the questions that you should ask, like, just at the very beginning of considering the tool, then when you're talking to the tool developer themselves, some of the questions that you might want to ask from the tool developer include things like, Are there any additional customizations that we will need to kind of incorporate as a news organization in order to be able to use that tool and the way that we want to? Is it kind of set in the way that it's created? Or do I have to customize it to my needs? And what does customization and upkeep look like? Does it come with an extra cost? How much control do I have as a newsroom over how the tool gets developed and gets used in the future? So I think that's, that's important to kind of be clear about at the beginning. And then, you know, what is the cost? Is it a reoccurring? Or is it a one time cost? And then do the products of this particular tool belong to me? Or do they belong to you? I think that kind of is an important question to discern, because then that brings us to the question of data, especially if you're pulling or the tool is pulling data from your audience, who then owns that data, you might have access to it as a newsroom. But ultimately, the tool developer might end up owning the data. And if they own the data, that means that they can reuse the data in any way, shape or form that they want to. So then that begs the question of how are you reusing the data? How will it kind of impact your future offerings? How can we as a newsroom be transparent with our users that their data is being collected for XYZ purposes? Did they reuse as of these data agree with our values as a journalism or as a as a newsroom? So all of those are like important questions to ask from from the get go. And one of the things that we've seen sometimes is, sometimes tool developers will develop the tool for a newsroom, but it's not lucrative to use it in newsrooms anymore. And so they kind of take back the tool, and they're like, oh, who could we market it too? And maybe that new audience, if they can market it to our enforcement agencies, because they collect data from individuals in a way that's useful for enforcement agencies? So then the question becomes, are we as a newsroom, okay, with the data being collected from our audience being reused for that purpose. And so those are all things that you need to kind of be clear about from the onset. And especially because a lot of the times, if you're going to train your team, you're going to spend time to train your team on using a particular tool, you're going to incorporate it in your like newsroom production process, it becomes very difficult to then go back and remove the tool from that entire process. So that's why, you know, the huge part of our guidebooks is really encouraging people and newsrooms to ask all of their questions upfront, so that they're going into that procurement process, eyes wide open, and they ensure that like the tool does for them what they had intended for it to do from the beginning. And then you can ask questions as well. We encourage you to ask questions about the efficacy of the tool and how you can measure if it's doing what it's intended to do. Does the tool developer provide you With any of those metrics, what do those metrics look like? And how do they measure against, again, the baseline that you've previously developed? And then last but not least, kind of being able to get more information from from the newsroom about what consent, they provide, like, do they? Do they have like a content disclaimer, if the tool is audience facing? Or do you have to develop your own? What kind of notification are they going to give you if the use of the tool changes? So again, if they start marketing it to a new audience? Are they going to let you know beforehand? Are they not? Those are also important questions to be able to ask. And then are there any ethical considerations that were considered by the tool developers when they were creating the tool? And if so, what mitigations have they put in place for those ethical considerations? I know that's a huge and tall order. But I think that, you know, some of these questions might not apply the same to all of the tools that you're reading. Again, you're not gonna like call up Grammarly and be like, Hey, how's your data being used? Because like, you know, most people already use Grammarly. But if you're using something that's highly technical, and very specific and highly customizable to your use room, you will 100% should spend the time asking 1620 25 questions of the tool developer to understand what went into creating those tools.

Nikita Roy  16:20  
That's an extensive list of questions to be talking about, then thanks for that bring y'all bout a lot of different topics. And I really want to get into more about like the subset of general AI. And like all of those generative AI tools that are coming about and charge GPT being the biggest one that people are currently using. So like what questions specifically do people need to be thinking about when they come across any of these like fancy new tool on the internet, which is just selling something to you in terms of like thinking about how to incorporate that? How should they be judiciously going about that process?

Dalia Hashim  16:54  
I think if a tool is using generative AI, and I'm going to steer away for a second from like Chad GPT, and like the very public tools, because I think those have their own set of considerations about how you use them in a way that is specific to every newsroom. So I think every newsroom needs to have like a very open and frank conversation about how they're willing to use things like dolly and try GPT in their newsroom or not at all, which is like a fair kind of decision to be making. But if you are going to use it, in what ways where is it acceptable? What type of oversight? Are you going to have? Who can use it? Is it the editors? Is it the writers themselves? You know, and what's the checks and balances to these like super open and healable tools. But if you're talking about something that's like, you know, a little bit more focused or directed towards journalists, so we have bought writers have been around way longer, as in charge. GPT has been around and they've been put to use pretty extensively, especially in Europe, in reporting, you know, sports news or in reporting, real estate news. Those I think have their own set of considerations when you're vetting a particular company to procure their services for a bot writer. One is to understand what their limitations are, in what areas did these bots perform really well? And in what areas are they unable to kind of support you in your writing process. So I know you had a J on the on the podcast a couple of episodes ago, and I was talking to him a couple of weeks back. And he was saying, you know, we've looked at these generative AI tools that are available. And we've kind of tried to expand our offering beyond sports and beyond kind of particular use cases of when these auto writers can be used. And he's like, they just, they're garbage, like they don't perform in the way that we want them to in a way that lives up to our editorial standards of how we would want to produce some of these articles. And so instead of expanding, we've kind of just kept it to our main offering, which is, you know, sports and real estate. And so understanding in what ways some of these bought riders could be used and in what ways they can I think it gets you a huge part of the journey there. And the reason a lot more organizations are comfortable using it for things like sports is because it doesn't need a ton of editorializing. You're just saying, you know, X game happened at y time, this was the score, you're not adding a lot of color and context, which is where a lot of those like auto writers kind of fail. Right. And so understanding where the the limitations lay is is really important. I would say it's kind of like a first step for using some of these generative AI tools. The second thing is, again, understanding what oversight looks like if you're going to use them who gets the final say who was reviewing it? And is the person reviewing it well equipped to make those decisions within your newsroom organization. So for example, if a writer is the one providing oversight for the use of a generative AI tool, are they empowered to then say, Hey, we're not going to run this Article, we're not going to include it in, you know, for the next deadline because it doesn't meet our standards, or are you just kind of providing tokenistic oversight? So that's a question. The other question is, is the person who's providing oversight actually have enough time for the evil incapacity to be able to provide oversight. So sometimes what you see is that, you know, it's one editor, but they have oversight of like 100 kind of articles or news pieces that are coming out, oh, there's no way a person is going to be able to devote enough time and energy to be able to properly vet 100 news pieces. So it kind of does the volume, batch the good, the oversight, all of those, I think are limitations that we should really think through. And

Nikita Roy  20:45  
certainly I think that's a really strategic and thoughtful set of questions to be thinking about when integrating AI and understanding how to fully realize its potential. I'm really curious to know more about the way we approach AI strategy in newsrooms have to consider the ethics behind it and making sure we build an ethical strategy for our newsrooms, how can use rooms ensure these considerations? And what ethical considerations should they be incorporating in your AI strategies from the start?

Dalia Hashim  21:14  
One, I'd say, transparency and disclosure, I have to be very clear on how we're going to be transparent with our audience about when AI is being used. That is both a kind of from a journalistic standard, something that we owe our audiences, but also just from like a protection standards, because the AI will make mistakes in the same way that humans will make mistakes. And you don't want to be letting your audience know that this mistake was made by a bot or by an AI, in the same breath that you're letting them say that it made a mistake. So hey, by the way, we use AI. And also, by the way, I made a mistake, I think kind of engaging the audience's early on and letting them know where AI is being used in your newsroom, even if it doesn't directly affect them is important. So you kind of see, right now, a lot of newsrooms will have like a page dedicated to their AI tools, where they're like explaining this is but the tool that we use, this is what it does. This is the tool we use this what it does. Well, a lot of the readers see this, probably not. What kind of begs the question of like, is this transparency for transparency sake, we'll set that aside for now. And but I think it's important for those who are looking for it to be able to find it, and then when it is facing the audience. So if you are, you know, using bots to help support even in writing an article, or in the footage that people are seeing, you know, if it's if it's generated by an AI and isn't real footage, or whatnot, so really go the extra mile to let the audience know that that's the case, I think it's very important that we are transparent with our audiences in the various ways that we're using AI that directly impact the news experience that they are seeing, or reading or what have you. So I think that that extra layer of transparency is important. And it's important for us to be clear about it from the get go.

Nikita Roy  22:56  
Also, just talking more about that specifically, we're having tools coming up that would generative AI tools coming up that would mimic the way you write and the sphere of like the journalists jobs, how do we specifically address that ethical question of what it means for newsrooms, what it means for their employees and their journalists to use such gendered AI tools? How would they navigate this ethical issue?

Dalia Hashim  23:22  
So you kind of have to take it step by step across the whole process of using these tools? When are you kind of making that conscious decision from the onset that they can or can't use these tools? To? How are they meant to be using them? What are the avenues that they're allowed to be using some of these tools? And what are avenues that we've decided as a newsroom that it is a no go for us to be using some of that either, you know, generative content, fake content, however you want to like, kind of describe it in the news offerings that we have. And being very clear at the onset with that with journalists is important socializing your journalists on that, as well as important on why you're incorporating these tools. Is it to replace the current journalists that you have? Is it to support their ongoing work? Is it to alleviate some of the mundane tasks that they have to do on a regular basis? I think that communication piece is important. I think listening to the journalists in your newsroom and talking to them before you even start considering adding some of these technological pieces is important to get there also input as to, you know, what are your current pain points? What are some of the tasks that are super repetitive that you hate doing that you think technology can solve for? And all of a sudden, you're bringing journalists along in the process instead of creating an inherently antagonistic kind of relationship between them and the technology that you're proposing that they use. And so I think, again, doing the work beforehand, and as you're incorporating some of these technologies, will help mitigate a lot of these ethical risks that we're talking about. And then brings us back to not just the over sight, but how are you monitoring on the long run, that the AI tools are performing the way that you want them to? So that there's like the oversight on like, you know, this particular use piece, you know, we're making sure that like someone's reading over or someone's like providing meaningful editorial oversight over the production of this particular news piece. But when we're talking about things like recommender systems, or AI tools that do like kind of personalize the news experience, or what have you, how do we ensure that they're performing the way that we want them to on a regular basis? Is there like a regular audit that we're doing of our AI tools? Is there something that we're doing to continually monitor how they're being used? Are we just kind of setting them free into the wild and hoping for the best because that's when you get problems of like bias? Or like echo chambers of news or, you know, showing your audience even just one type of news very repetitively because they clicked on like a basketball article once. So it kind of gets you into things that might even backfire on you as a newsroom and do the exact opposite of what was intended from an AI tool.

Nikita Roy  26:07  
Yeah. And you touched upon it slightly about the risk of bias. And a couple episodes ago, we had Dr. Gregory Conway on the show, who spoke about his research with generative AI outputs, having inherent biases, like Chad GBT, regarding countries from Africa. And that just brought up this really valid concern of how AI tools can unfortunately, just perpetuate and amplify these biases very seamlessly in their outputs. And how do you see newsrooms implementing measures to detect and kind of mitigate all of these biases that could come about an AI driven contents is this rise towards generative AI is more incorporated within newsrooms, or advocates,

Dalia Hashim  26:47  
it starts with integrating the data sources of the tools that you're using. And being clear with the tool developers, whether they're in house or external to your organization on what the data inputs are, if your tool is being trained specifically in only in the English language, then be clear and transparent about it. And only use it in those contexts. Don't try to force kind of, you know, translating the content intent into different kind of outputs, knowing well, that it only applies to kind of a western audience, or is only trained on like, Western on etc, or whatever it may be right, so interrogating the data inputs at the beginning is important. And then once you are kind of using it, and you have all these outputs, having that oversight is important having the areas where you know, there are continual audits that are being conducted on those outputs to ensure that they're operating the way that they ought to. And then also kind of being mindful of the areas in which you wouldn't want to use an AI tool. So things like breaking news, things that are, you know, moving really fast. And you know, for a fact that you're not going to be able to have that oversight that you would normally have for any other news piece. Maybe then we don't use the AI tool during you know, a breaking news incident or an incident that that has continual updates, stuff like that, I think is important looking and comparing the outputs of AI tools for headlines, for example, across the board. So kind of as part of that audit saying, Okay, here's some samples of the headlines that were being generated by our AI tool. Are they being sensationalized or biased when it comes to a particular racial group over others? Again, if that is the data that the system AI system is being fed as to like our previous history with headlines that you know, we all know, falls into a number of biases and pitfalls previously? Then how can we expect that same tool to generate anything that's different? And the only way we know unfortunately, is if we're being called out on it by our audiences? Or if we do our own due diligence on the back end, and really spend time not just with oversight, but with like, kind of system level audit that I'm talking about?

Nikita Roy  29:02  
Yeah, I love that's a really interesting point about being careful about the data sources. And one of the issues with like generative AI tools that exist, like tag GPT is not knowing what their data source is really dead brings in all of that inherent bias risk. And I think that's an interesting point that you brought up there. I'm really curious from all of your research, really, so far, where do you see the biggest impact of AI on newsrooms?

Dalia Hashim  29:27  
I think where we're seeing it right now is in automating a lot of the tasks that journalists don't want to do, but are forced to do because of the nature of, you know, social media and test the, you know, the internet and all of that being introduced to journalism. So there are pieces in the news production process that I don't think journalists are too thrilled about doing but kind of have to do as part of the job that can kind of be automated now using AI tools. And I think that's kind of the biggest value add I know we kind of like to talk about the big generative AI AI pieces or, you know, some of the almost transformational AI tools. And I think the time for that will come, don't get me wrong, I just don't think they're as good as we would hope for at this stage to be able to use them and incorporate them as seamlessly. I do think the AI tools that have been put to good use are ones that kind of do automate regular and repetitive tasks for journalists, or kind of provide avenues for us to be able to share news in multiple formats in a way that would have previously required a translator, to be present social media editor to be present a video creator to be present. And now all of a sudden, you have all these like tools that are fairly effective at you know, translating content or being able to turn, you know, a podcast, like the one we're discussing into a video with kind of transcribe content on set video, so that people can watch endless and at the same time, so all of those are, you know, distribute what we name is like kind of distribution tools, I think are also a good avenue for for newsrooms to be able to expand their audiences and reach new audiences. And it also impacts their sustainability. Because if you can reach new audiences, those are all kind of new income revenue. So

Nikita Roy  31:15  
that's been really valuable to see all the different ways in which you are really experimenting with AI and seeing newsrooms looking at AI. I'd really love to know more about as we wrap up our conversation, just really wondering about what can we expect more from partnership on AI in terms of all of the resources, guidance and support? What future Are you building for us to help newsrooms?

Dalia Hashim  31:37  
So we have right now, as I mentioned, we have our guide book that we're working on, it's on its final stages. And we're hoping to publish it in draft format for for feedback from newsrooms and other folks in the field, before we kind of finally publish it as a final product. So I think that folks can keep an eye out for and give us feedback for as well, when when it's shared publicly. The other part is, we have a synthetic media framework that we have published previously. And it was published by our AI media integrity team, which I'm part of, and they've worked for the past year and a half or so with some of the biggest tech companies to say, okay, how can we provide specific guidance and principle based approach to the use of synthetic media? What does that look like for both the user, the creator, and the tech developer? So it kind of covers all three pieces of that production cycle, to say, you know, what does responsible AI through the entire process look like? And so far we've had 10 companies adopt that that framework, including a meta Microsoft, Tiktok, bumble, and so what we're really trying to do is bring some of the biggest generative AI and synthetic media creators around the synthetic media framework. And I think it provides a great starting point for newsrooms as well who are thinking about using synthetic media, in opening doors and questions around what Responsible Use looks like. And so I think that one of our next steps is to kind of bring some of those themes of disclosure and transparency that are highlighted in the synthetic media framework closer in application to newsrooms in a more targeted in a specific way.

Nikita Roy  33:19  
Wow, that's really exciting to hear all these resources. Thank you for your commitment to supporting newsrooms helping you navigate this AI landscape. And then thank you for joining us and shedding light on all of the work that you're doing.

Dalia Hashim  33:31  
Of course, thank you so much for having me.

Nikita Roy  33:34  
That was Delia Hashem. The program and research lead for AI and media integrity at partnership on AI. This podcast is made possible thanks to the Harvard innovation labs background. I'm Nikita Roy, and this is news from robots.

"
newsroom_robots,13,"Wed, 05 Jul 2023 20:18:46 GMT",Santiago Lyon: How Adobe’s Content Authenticity Initiative is fostering digital provenance,https://www.newsroomrobots.com/episodes/santiago-lyon-how-adobes-content-authenticity-initiative-is-fostering-digital-provenance-UfAgPgDM,"<p>Santiago Lyon joins Nikita Roy to discuss how Adobe's Content Authenticity Initiative is taking an active role in combating misinformation through digital content provenance. He discusses how Adobe addresses ethical issues and brings transparency to its AI-enabled products, like the new generative fill feature in Adobe Photoshop. He also touches upon the transformative impact of generative AI on the roles of creatives. </p><p>Santiago Lyon is the Head of Advocacy and Education for the Adobe-led Content Authenticity Initiative. He has more than 35 years of experience in photography as an award-winning photojournalist, photo editor, media executive, and educator. As a photographer for Reuters and The Associated Press, he won multiple photojournalism awards for his coverage of conflicts around the globe.  In 2003 he was a Nieman Fellow in journalism at Harvard University before being named Director of Photography at The Associated Press, a position he held until 2016. Under his direction, the AP won three Pulitzer Prizes for photography and multiple other major photojournalism awards worldwide. He was Chair of the Jury for the 2013 World Press Photo contest. Lyon serves on the boards of directors of the Eddie Adams Workshop and the VII Foundation. He also teaches regularly at the International Center of Photography in New York.</p><p>Thoughts or questions? You can reach us <a href=""https://forms.gle/egyJZDsGjogiyNTH8"">here</a>.</p><br /><hr /><p style=""color: grey; font-size: 0.75em;""> Hosted on Acast. See <a href=""https://acast.com/privacy"" rel=""noopener noreferrer"" style=""color: grey;"" target=""_blank"">acast.com/privacy</a> for more information.</p>","Nikita Roy  0:02  
This is newsroom robots, the Podcast where we explore the intersection of artificial intelligence and the news industry. I'm Nikita Roy, a data scientist, media entrepreneur, and one of the many founders currently building their ventures at the Harvard innovation labs. On the newsroom robots. I'm excited to bring you insightful conversations with industry experts about how AI is impacting the way we do journalism. Joining me today is Santiago Lyon, the head of advocacy and education for the Adobe lead content a fantasy initiative, which is working to combat misinformation through digital content provenance. With over 35 years of experience in photography, Santiago has won multiple journalism awards for his coverage of conflicts around the globe, as a photographer for Reuters and the Associated Press. During his tenure as AP as Director of Photography, the AP earned three Pulitzer Prizes for photography along with multiple other photojournalism awards around the world. He's also been a Nieman Fellow and journalism at Harvard University. In today's episode, we learned about the role of Adobe's content authenticity initiative in fostering digital provenance, and discuss the future of visuals in news media in the AI era.

Hi, Santiago, welcome to newsroom robots.

Santiago Lyon  1:30  
Pleasure to be here. Thank you for having me.

Nikita Roy  1:32  
So Santiago, I'm very excited today because you are actually our first guest on the show who has an extensive background in photojournalism. And now with your work at Adobe working on digital provenance. I'm really excited to hear all about your thoughts on generative AI today. And I want to start off first on getting your thoughts on the current generative AI era that we are in as you are someone who was an award winning journalist for so many years, I'd love to start off the conversation by hearing your personal thoughts on AI generated images, what's your take on it?

Santiago Lyon  2:08  
Well, it's a really a remarkable new area of technology that is moving along at lightspeed there seem to be changes every day in the generative AI space. And it's sort of alternatively exhilarating and terrifying at the same time, because it's really empowering people all over the world who have access to technology to ferment and enhance and, you know, experiment with their creativity in a very basic way. On the one hand, when we talk about generative AI, we're talking about using prompts if you'd like to either generate text, or the work I'm doing right now is prompts around generating visuals. And so a simple prompt can all of a sudden, generate an entirely synthetic or artificial image of whatever the user wants to play with or experiment with. And so in that sense, it's it's exhilarating, it's sort of democratizing creativity in some ways. But it's also a little bit scary because the output of these machines is increasingly indistinguishable from quote, unquote, real content. And so there are some concerns, especially in the world of photojournalism, where it's possible for bad actors to create images of events that never happened. And so the work that I'm doing at Adobe right now, around the content authenticity initiative, is really all about transparency, and labeling content, whether it's generative AI content, or any other kinds of content that are out there, labeling it very clearly so that the viewer has a clear sense of what it is they're looking at. Where did it come from? How might it have been altered in the editing process, and then ultimately displaying some or all of that information to the viewer to the reader to help them navigate what's an increasingly confusing media landscape?

Nikita Roy  4:09  
Yeah, exactly. And I mean, Adobe asked this question 30 years ago, how would we verify what you're seeing is true or not? And now the work that you're doing over with the content tends to be initiative, I'd like to know more exactly in terms of how does it work? And what features are people able to use to know what they're viewing is true or not.

Santiago Lyon  4:30  
So the content authenticity initiative was started by Adobe in late 2019, in response to the problems of missing disinformation, and with an appetite or a view towards fomenting or increasing transparency in digital content. And from the very getgo we wanted all of our work in this space to be open source, which is to say the underlying code is available for anybody and everybody to use, including Adobe's business competitors and at the same In time, it's being incorporated into flagship Adobe products. And so really what we're talking about is a fast growing community of major media and technology companies and others who are coming together to implement the open standard around provenance or transparency so that people can understand exactly what it is they're looking at. And so the way this technology works is that we have focused in on three main areas starting with capture or creation. And on that front, we're working with hardware manufacturers, that is to say camera and smartphone manufacturers to integrate this technology into their devices at production, so that when an image is created, or a video is recorded, it's empirically provable that the file was created with that particular piece of hardware. And in addition, all of the metadata fields that most hardware devices nowadays generate things like EXIF, Nex, MP and IPTC, which contain a lot of very valuable information, but which are unfortunately not particularly secure. They're quite easy to hack into. One of the things that the CI technology does from the get go is as secure as all of that information using cryptography. And so it sort of binds that provenance information or that information of source or origin to the digital file. And then the next area we look at is the area of editing. And so here, we're busy incorporating this technology into editing programs, both Adobe and non Adobe, given the open source nature of our work. And here any changes that are made to the file, let's say in the case of a photograph, and images cropped or toned or darken or lighten or elements are added or subtracted, each one of those actions gets captured as secure layer of metadata that then accompanies the file along its journey. So really, what we're doing is creating a secure edit history around that particular file. The next stage of the journey is typically publishing. And so here, we're working with publishers and CMS manufacturers, who for the most part currently, and routinely stripped metadata off of files, as it makes its way through their systems for a variety of reasons, what we're doing is working with CMS manufacturers and publishers to leave the metadata intact. And the reason that we're interested in leaving this metadata intact, is because then it's possible to share some or all of it with the viewer, so that they can get a better sense of what they're looking at. And so we call these layers of secure metadata content credentials. And they're visible at any point in a piece of contents journey, to have this deeper understanding of where something came from, how it might have been altered. And then, like I said, sharing some or all of that information with the viewer to enhance this notion of transparency.

Nikita Roy  8:07  
You brought up an interesting point about that publishers tend to strip out all of that metadata and the content credentials, and that's something that you're working on right now. And so I want to shift focus into knowing more about as newsrooms began to use all of this and since you work a lot with the different newsrooms, I'm sure you have insights on how we should be working today. And what role would newsrooms how to play in ethically using generative AI? How can we contribute towards building trust with our audience and contributing towards building provenance?

Santiago Lyon  8:41  
Well, I mean, newsrooms are just coming to terms with generative AI and having, you know, detailed discussions about how best to use it and where it fits into the newsroom flow. I think it's fair to say that generally, newsrooms are being very judicious and careful about how they integrate generative AI into their workflows. Because the last thing that they want is to either deliberately or inadvertently use generative AI and represent something that may never have happened or, you know, that isn't in line with the facts. So there are two things going on the judicious use of generative AI in newsrooms, which is a nascent thing, and then the desire in newsrooms to have transparency around what is generative AI and what isn't. And that's where the technology that we're delivering is coming into play. Increasingly, we're seeing a desire in newsrooms to achieve this level of transparency using the tools that we're developing.

Nikita Roy  9:48  
And how can you use rooms that are not currently part of the content authenticity initiative, use these tools and become and learn more about this.

Santiago Lyon  9:56  
So the content authenticity Initiative is a large community of Now over 1500 members, including many of the major journalistic organizations, both on the agency side, just to say agencies whose main business is to license content to consumer facing news organizations, and then consumer facing news organizations themselves. And so joining the content authenticity initiative is very simple. It's a web form on our on our homepage, content authenticity.org. It's entirely free. And once one is in the community, then we're able to, you know, keep the community informed, we have community events on a regular basis, we put out newsletters, and we also offer some technical support on a very vibrant discord channel that we run for people who are looking at our tools that we've built and looking at the underlying open standards specification, and all those sorts of things.

Nikita Roy  10:55  
And I also have to talk about, well, Photoshop coming up with a lot of different AI capabilities, and a lot of new AI products coming from Adobe, the new generative AI capability. Anyone can really make Photoshop edits now with just putting in a prompt and having things changed automatically and having AI manipulated. So what I'm really interested in is, it's really cool for people who don't have that much photoshop skills, but at the same time, it's really scary with the potential of misinformation and just frightening deep fakes that could be made with this tool. How is the Sci Fi now helping with integrating all of this into the way Adobe tools are functioning? And what would the future look like with like misinformation being produced at ease?

Santiago Lyon  11:43  
So Adobe's foray into the generative AI space is through a product called Firefly, and in Firefly, from the get go, we wanted to enable this level of transparency, so all of fireflies output has content credentials on it, that very clearly states that this particular piece of content was made by a computer as opposed to you know, by human are reflecting, quote, unquote, a real event. So we're getting that level of transparency from fireflies output. And then in addition, in Photoshop with generative fill, if one activates the content credentials feature in Photoshop, it keeps a track of what tools within Photoshop were used, if generative fill was used if other tools were used. And so we're able very quickly to establish this edit history that would allow a viewer later to go back and say, Oh, look, this is how this particular piece of content was created. So on the one hand, we're developing very sophisticated generative AI tools. And on the other hand, we're developing very sophisticated tools around transparency. And we certainly don't see those two things as being mutually exclusive. In other words, Adobe's mission is creativity for all. And at the same time, the CIA's mission is all around transparency. And we think in this day and age, actually that those two things logically go together, and help make the internet and digital content generally a safer experience

Nikita Roy  13:13  
and the content credentials. That's something that people have to go and opt into, and had that metadata generated, is that the way it would work for people who would upload images online now?

Santiago Lyon  13:24  
Yes. And so the way this is working is that the content credentials are generated, you know, when something is being created, and the next phase of the work is really critical, which is to get those contact credentials in front of people. And to that end, we're working with publishers and CMS manufacturers to maintain that workflow, so that eventually, this notion of provenance will become so ubiquitous, that it will be expected that every piece of content out there will have a little provenance icon next to it, that the viewer can, you know, mouse over or click on and display or uncover some of the information or all of the information around where that particular piece of content came from. In fact, I'd go so far as to say that we think that over the next several years, the notion of provenance and transparency will become something foundational to a great many things digital. So we're focused right now on the news media and generative AI, but we also have a lot of interest from a very wide variety of other sectors, things like insurance, or law enforcement, or auditing, or medical and scientific imagery, or E commerce or brand reputation. Because when you think about it, we take great leaps of faith every day with content that we see online and we make a lot of assumptions as to the veracity of something either through where it's housed or because you know, we believe in a particular brand or whatever it is, but in the same way that you know, secure internet true transactions initially, were sort of shaky and scary, you didn't know if you are online with your bank, for example, when you were doing a financial transaction, and then over time we got in a secure servers. And now you have a little padlock icon in the upper left of your browser that indicates you're on a secure connection with, you know, whoever it is you're doing business with. We think that provenance and content credentials, in particular are going to become ubiquitous. And like I said, Something foundational for a great many things digital, and it will be precisely the content that doesn't have content credentials attached to it, that will merit a closer look. Yeah. And

Nikita Roy  15:41  
while Adobe's doing all of this work on provenance, it's also important to address the ethical issue surrounding creating AI generated products. And I'm wondering if you could talk more about how Adobe is addressing all of those ethical issues of using generative AI and its products and having image being generated by AI.

Santiago Lyon  15:59  
So Adobe has been very careful in the generative AI space around the data training sets that we use for Firefly. And so we're only using data training sets that are made up of material that we either explicitly have permission to use, or that has, you know, is out of copyright and is available for anybody to use. And so by doing that, we're necessarily creating a safe experience, because the machines are trained on safe, ethically sourced data. And that's really important, because as you probably know, there's a fair amount of controversy out there around data training sets. And you know, there's lawsuits going on, etc. So we're proud to say that the output that comes from Adobe Firefly, is ethically sourced and is, you know, risk free, and we're able to offer those guarantees to our customers. And

Nikita Roy  16:51  
with Adobe, still producing all of these products. How do you see the role of illustrators, artists, designers, evolving with AI generated content, people can now also, just with a simple prompt, create all of these images? So how do you see the artwork being affected?

Santiago Lyon  17:09  
Well, I think there's a couple of things. First of all, the sort of skill set is shifting, starting to hear people refer to synth ographers, as opposed to photographers, and for many people, the skill is in the prompt. In other words, how detailed can a prompt be, and how does the detail in a prompt change the output, so you have the ability to specify whether you want to output an illustration or a photograph, or even more specifically, you can talk about certain lenses and focal lengths and shutter speeds. And, you know, color palettes and images in the style of a certain photographer, or whatever it is. So the the whole prompt area is increasingly sophisticated. And then the other thing is that for some creatives, they're using generative AI as a sort of a co pilot. In other words, let me put in a prompt, let me see what the the tool gives me from that prompt. And then maybe I take the output, and I bring it into a creative program like Photoshop, and I enhance it or I finesse it. So I think it's really about shifting skill sets, in the interests of creativity. And for many creatives, I think it's going to be a tremendous opportunity. And it also I think, is can be quite efficient, in the sense that if you're able to generate something, whether it's a finished product, or whether it's an idea or a concept, you're able to do that with really great ease. And then you can, you can take that and build whatever it is you want. A lot of creatives that we talked to are very excited about the notion of, of generative AI because it can depending on how it's used, enhance your creativity, enhance your efficiency, enhance the amount of content that you can generate, depending on what your needs are.

Nikita Roy  19:05  
I'd love to get your personal take on the whole AI generated images, would they be considered artworks in their own? Right?

Santiago Lyon  19:11  
Wow, that's a really interesting question. And the copyright office in the United States is, you know, going on listening tours to try and determine what is the nature of copyright around generative AI is there sufficient human involvement to make it copyrightable. And this is such a new field and copyright laws in our were established many decades ago. So I imagine there's going to be quite a lot of legal back and forth and movement, trying to determine the answers to those questions.

Nikita Roy  19:39  
And I kind of want to know more about the CI the content authenticity initiative now in the broader context of transparency and trust on the web. As we move out, you spoken quite a bit on how you see that's going to be the future. Where are we right now? And how long do you see that process? is going to take for us to move into? Well, I

Santiago Lyon  20:03  
think that we need a way to establish trust online or reestablish trust online in some cases. And it's a very complex issue. And I don't believe that there's a single turnkey, or LightSwitch solution to this. I think that the notion of provenance and transparency is very important. And the tools that are being built and that the content authenticity initiative is busy building will become fundamental tools over time. But tools themselves I don't think will solve some of these problems. In my mind, there are other pillars that are very important in the fight against missing disinformation, for example, media literacy, and creating robust curriculum materials to help educate students around media literacy. And we just finished creating a bunch of those materials which are available for free on on one of our education websites, aimed at middle schoolers, high schoolers, and university students, to help guide them through this really confusing media landscape and help establish best practices and help teach young people to be, you know, exacting, and skeptical, and rigorous about the methodology that they apply to consuming content. So media literacy is fundamental, I would say also very important is the area of policy, where increasingly lawmakers and policymakers around the world are reacting to generative AI, you know, you have proposals making their way through the European Parliament and the UK Parliament and other governments around the world about, you know, directionally mandating provenance around generative AI to help protect citizens and consumers. And so Adobe's government relations team is working very closely with a number of, you know, lawmakers, policymakers, legislative bodies around the world, to make sure that those people are well informed about what's possible technologically what the status quo is, what's coming down the road. And so we think that's another important pillar. And then the last one I'll mention is around the area of detection and fact checking. And while we don't think that detection technologies, per se, are a winning proposition, in the sense that they're not particularly accurate, they're not scalable, they can be very useful on an ad hoc basis, especially when combined with journalistic fact checking. And so there is a value to that aspect of things, although we're not focused in on that at the content authenticity initiative. So when we look at that landscape, we're really talking about four pillars, fact checking in detection, policy, media, literacy, and transparency and provenance. And we're actively involved in three of the four. And so we think that the combination of those pillars, you know, moving together forward, he's going to really be a very valuable front in the fight against myths and disinformation and help make the internet a safer place for everybody.

Nikita Roy  23:11  
How do you see the news industry as well, taking a step towards digital media literacy and informing citizens and their audience more about what they're seeing? How should we be communicating all of that information to them? What's your take on that?

Santiago Lyon  23:26  
Well, I think media literacy has sort of two components broadly speaking, the classroom component where teachers can interact with their students and you know, incorporate this into the the teachings that they offer in their in their institutions. But then there's also another aspect of it, which is consumer media literacy. So if you can imagine a world in the not too distant future, when content credentials begin to appear on a news app, or on a news website, it's going to be who've, the publishers of that website or that app to educate their consumers as to what they're looking at. So I can imagine a scenario where a publisher says, dear reader, you will have noticed that as of such and such a date, there is a little contact credentials icon, you know, adjacent to or next to pictures or video, here's what it is, here's how to interact with it. Here's what it means. And really, what that does is it helps bolster the existing trust models, between consumers and media organizations. Because at the heart of all journalism is trust, whether it's the trust between consumers and media outlets, whether it's to trust between the journalists and the people that they're interviewing or eliciting information from trust is at the heart of it all. So this is another layer of trust, that really benefits publishers, because they're able to say with confidence, what we are publishing has very visible trust signals attached to it that offer guarantees above and beyond what you might call only beginning in the trust area from that particular publisher. So in some ways it's codifying existing things. In other words, when the New York Times publishes a piece of content, the fact that the New York Times publishes it. It's because a whole series of editors and sub editors have vetted that content, have done their checks and balances, and it goes out with the New York Times his name on it. And that is in and of itself, a label of trust. What we're saying is that these content credentials bolster, or buttress that label of trust, with some empirical evidence that proves the things that are provable around the provenance and the transparency associated with that particular piece of content.

Nikita Roy  25:43  
And I'd love to hear more about building trust is such an important issue for newsrooms. And so being a part of the content authenticity initiative, what's the future looking like? What could we expect more from the work that you're doing?

Santiago Lyon  25:54  
Well, we're working hard towards adoption. In other words, we've got these tools in some Adobe products, it's in there in Photoshop, now they're in Lightroom is a beta, we anticipate them to be another products that are on, you know, stock photography, all of Adobe stock photography, when it's downloaded has content credentials attached to it, a Behance, which is a very large community of creatives, it's a sort of a showroom for creatives to show and unlicensed, our work, some of that content has contact credentials on it. So on the Adobe side, you know, we're moving quite rapidly to integrate content credentials into into our products, Firefly, our generative AI space, as I mentioned before, is another one. Now what we're looking towards while we're doing all that work, is looking towards implementation by media publishers. And so we're working with a cohort of media publishers towards the goal of implementation. In other words, the media content workflow is typically, you know, in the area of photography, for example, photographer in the field, makes some pictures, processes, the pictures at its thumb, sends them into their media outlet, they get published. And so there, we have an opportunity to intersect at every point in that workflow. Starting with the hardware manufacturers, you know, we're in advanced conversations, and there is work being done by these hardware manufacturers. In fact, at the end of last year, like, and Nikon, two major camera manufacturers came out with some prototype, secure capture devices that demonstrated that it was possible to get this provenance data from source at a hardware device and attach it to the files that those devices generated. So those companies and other companies are working towards production, secure capture devices. And then you know, with the publishers themselves, were looking at the differing, you know, technological aspects of that, with a view towards in the not too distant future, seeing this out there live through the interface of contact credentials, icons, next to published content, which will then allow the viewer or the reader to interact with the content and have those guarantees that that particular image or that particular video clip actually did come from the source that is in a claims to have come from, this has

Nikita Roy  28:17  
been a valuable conversation to learn more about what you're doing. And to wrap things up, I kind of want to get a final insights from your years of experience working in the newsroom. And now on the other side in the AI space. What's your take on what the future will look like using all of these generative AI tools for photos, illustrations and visuals and news media?

Santiago Lyon  28:41  
Well, I mean, at the core of all photojournalism is this notion of veracity, this notion of you know, you're looking at an image of a real event, and it was captured by a trusted photo journalist, and was published by a trusted and respected media outlet. So those are very basic principles that I don't think will go away. I think they're fundamental to the notion of truth in journalism. And by extension, trust in journalism. What I do see happening is the use of generative AI, perhaps to illustrate things that are really hard to photograph or video. And so currently, how are those things illustrated? illustrations, data visualization, using maps using data points, all of those things are currently being done, you know, in many newsrooms, to help illustrate things that are difficult to illustrate sort of abstract concepts of financial information or things of that nature. And so I can see generative AI being used to enhance the visualization of certain aspects of storytelling, and perhaps in in an exciting way. But I think it's really important to be able to distinguish between what is an image of an actual of That's something that actually happened in the physical world. And what is an image generated by a computer in response to data inputs or prompts. And as long as those two areas are clearly identified and not conflated, and there's no confusion there, and I can see generative AI being quite an exciting tool for newsrooms, when used judiciously when used with those sort of guidelines or rules in place. And you know, having been in the news industry myself for almost 40 years, in a variety of roles. I know that the people who run newsrooms, the editors, the executive editors, the writers, the photographers, the videographers, they all have a very, very deep commitment to the truth and to veracity. And they're in journalism, because they want to reflect that truth and veracity and help people interpret it. And so I don't see a scenario where, you know, those borders are going to get blurred, or there's going to be confusion. And I think what's going to help maintaining those two areas separate from one another are precisely the kinds of tools that we're developing around transparency. So that if you have a doubt, or if you just want to double check, or if you're not sure, you can click on something and it'll tell you where did this come from? How was it altered, who made it when and all these various data points that will help give you confidence in the nature of what it is you're looking at?

Nikita Roy  31:26  
Thank you so much. This has been such an interesting conversation, getting your perspectives on really how the future would look like with us building trust and how we can use the tools that you're working on. And thank you so much for coming on the newsroom. Girlboss. This has been such an insightful conversation.

Santiago Lyon  31:42  
My pleasure. Great to talk with you, Nikita and look forward to staying in touch.

Nikita Roy  31:48  
That was Santiago Lyon, the head of advocacy and education for Adobe's content authenticity initiative. This podcast is made possible thanks to the Harvard innovation labs parkland, I'm Nikita Roy and this is newsroom robots.

"
newsroom_robots,12,"Wed, 28 Jun 2023 18:12:32 GMT",Gregory Gondwe: Uncovering Stereotypes in Generative AI Models and How Journalists in sub-Saharan Africa Use ChatGPT,https://www.newsroomrobots.com/episodes/greg-gondwe-stereotypes-generative-ai-models-how-journalists-sub-saharan-africa-use-chatgpt-qGZVRici,"<p>Dr. Gregory Gondwe joins Nikita Roy to discuss the embedded stereotypes and biases in Generative AI models that put the Global South at a disadvantage. He also shares his findings on how journalists in sub-Saharan Africa leverage ChatGPT, with insights derived from his recently published journal article, <a href=""https://www.degruyter.com/document/doi/10.1515/omgc-2023-0023/html?lang=en"" target=""_blank"">""CHATGPT and the Global South: how are journalists in sub-Saharan Africa engaging with generative AI?"" </a></p><p>Dr. Gregory Gondwe is an Assistant Professor of Journalism Studies at California State University, San Bernardino,  and a Rebooting Social Media Visiting Scholar at Harvard University's Berkman Klein Centre for Internet and Society</p><p>He studies emerging media trends and their implications on society, particularly in Africa. His current projects include how people in sub-Saharan Africa use social media — particularly how individuals orchestrate online communities, outsmart government censorship and surveillance, and navigate through biased social media algorithms. His other works include cross-national studies on mis/disinformation in sub-Saharan Africa related to gender, geolocation, age, and media literacy. </p><p>Dr. Gondwe’s research works have appeared in various peer-reviewed journals, including Digital Journalism, International Journal of Communication, Journalism Practice, Journalism Studies, International Communication Gazette, and African Journalism Studies.</p><br /><hr /><p style=""color: grey; font-size: 0.75em;""> Hosted on Acast. See <a href=""https://acast.com/privacy"" rel=""noopener noreferrer"" style=""color: grey;"" target=""_blank"">acast.com/privacy</a> for more information.</p>","Nikita Roy  0:02  
This is Newsroom Robots, the podcast where we explore the intersection of artificial intelligence and the news industry. I'm Nikita Roy, data scientist, media entrepreneur, and one of the many founders currently building your ventures at the Harvard Innovation Labs on the Newsroom robots. I'm excited to bring you insightful conversations with industry experts about how AI is impacting the way we do journalism. My guest today is Dr. Gregory Gondwe, an assistant professor of journalism studies at California State University, San Bernardino, and the Harvard visiting scholar at the Institute for Rebooting Social Media at Harvard University's Berkman Klein Center for Internet and Society. In today's episode, we learned about Gregory's research on how journalists in Sub Saharan Africa are engaging with generative AI and discuss in detail the issue of stereotypes perpetuated through generative AI models, which position the global south at a disadvantage.

Hi, Greg, welcome to newsroom robots.

Gregory Gondwe  1:14  
Thank you. Thanks for having me.

Nikita Roy  1:16  
Greg, I'm really excited to have you because your research offers a fresh perspective on AI in journalism and a much needed perspective really on how journalists in Sub-Saharan Africa are engaging with generative AI, and tools like ChatGPT, and you've just published a journal article on ChatGPT and the global south. And so I want to start off there by delving deeper into your research. Could you give me an overview, really, of what your research is? And what led you to explore this particular topic?

Gregory Gondwe  1:50  
Thank you. Yes. So before I get into that, before we delve into the topic at hand, I would like to provide an explanation regarding the rationale behind utilizing the term sub Sahara Africa. You know, I know most people are not comfortable with that, not just in the West. But even in Africa, South Africa is not a country Sub-Saharan is too huge to be studied, it is important to acknowledge that we are individuals who will contest such labels or there are individuals that contest such labels due to the well known controversy surrounding the notion that Africa is not a country, but it's crucial to actually emphasize this should not hinder us from studying systems. When we study Africa, when personally I study Sub Saharan Africa, I'm not studying a particular continent. I'm studying systems. So like, given our history, given the colonial aspect of say Africa, there are many characteristics that we share in terms of systems. So our media, for example, in the in Sub Saharan Africa is characterized by the British media, there are many elements that we can point to, that are similar, you know, in different countries. And so when I actually approach the topic in that manner, it's not that I'm undermining the differences that exist around different countries. And if let's say we had to follow the same logic would probably not even study a country. You know, I give an example of, for example, the distinctions that are there in Kenya, you have the Messiah, who are totally different from the Luo. No, the Kikuyu and that will be the same as in Brazil, where you have the Fivera and the other groups, India is the same. So if let's say we are that strict, then we cannot study any country at all. So I have to acknowledge that I do understand, but what I'm actually studying is the systems. Now, going back to the question, you know, the motivation that I had was one the speed of, you know, the internet itself. 5-10 years ago, this would not have been the conversation in Africa, you know, like, we had to wait, let's say, the internet comes in, you know, it takes 10-20 years before it actually gets to Africa or to the global south. So most of the issues we're facing, though different, were kind of similar to the issues that the West had earlier faced. So we actually knew the answers to those. But today is different, you know, like generative AI or ChatGPT, became a buzzword in around November, September, November, I think. And by December, Africans, were already engaging with generative AI, they were part of that. And I think there are a lot of repercussions surrounding that, given the fact that we are, you know, engaging with it at the same time as the West that are still grappling with how to use it. And it becomes more challenging in Africa, because we are we are not, we do not participate in the creative of such, you know, tools. So the question is we just consumers we not creators of such and I think that motivated me, especially in the context of journalism. Also, given the debate surrounding generative AI you know, as you remember, there was there are questions of misinformation, questions of plagiarism, questions of bias. And I wanted to take a global south perspective. I know that is huge word. But uh, you know, I wanted to take a perspective of also bringing the global South, what challenges are they facing given the current generative AI? So that in general was kind of my motivation to pursuing the topic? 

Nikita Roy  5:23  
And could you start off by really describing the current news media landscape in the countries that you researched? You looked you mentioned a lot of issues related to internet penetration and how that would affect the lack of data databases that these ChatGPT and generative AI chat bots were built upon. So could you talk more about that? And how are journalists really using ChatGPT Keeping all of that in mind?

Gregory Gondwe  5:49  
Yeah, so my my pilot study, or I've been studying Africa, I know, people would say, again, don't study Africa. But you know, I've been doing research in different parts of Africa for several years now. And my experience has been that, you know, the media system. If, let's say we delve deeper into it kind of still mirrors, the Western media, you know, we there have been attempts to actually African eyes, the media, but that's very difficult, you know, because one, the education system is still wasted. You know, we don't have at least in African countries that I've seen, we don't have books that are written by African scholars. In the curriculum, you know, we still use a Melvin Mencia, which is American, we still use books that are written in the in the UK, and those inform Korea. And when it comes to technology, when we go into the field, we use the Western technology, you know, so we have to know the way in which of course, there's the context, which is different, and it kind of shapes how we do most of the things. But even with the local media, you'll find that most of them are funded either by churches, let's say, if let's say they're Christian, we have the Catholic Church funding this local media. And then also the UK is a big funder of such kind of local media, and other NGOs from the United States. So there are many similarities in the media that we study, or that we actually can point to and those polls as hallmarks for how the media is perceived in Africa. Of course, there's the British and then up there, there's the French media, you know, even today, I think less so we receive BBC Africa. You know, I know there are African journalists working for that, but it's BBC Africa, we have now the Chinese media, we have our Jazeera, and all those are the major media outlets. So yes, and that actually justifies. And I feel like it's fair to acknowledge the fact that similarities is there. And when we studied systems, we can thus think in the context of the media that we actually do have, and when it comes from journalists engaging with that sometimes, you know, they get some or they or they benefit from such kind of media. And also they lend specific ideas of ways of actually engaging with technology from such kind of international media. But still, they need to contextualize that in their own environments. Yeah.

Nikita Roy  8:09  
And you mentioned about moonlighting and the culture of freelance journalists having to also do a lot of other work to support their livelihoods as journalists and the strategy btw being a tool for them, how are they using it?

Gregory Gondwe  8:23  
Yes. So, you know, initially, I think it was difficult if let's say you had to work for two media houses, many of them would have to be there physically, you know, if let's say, I'm working for two media outlets, so if I'm a blogger and the other media, it was hard for one to write a story. But today, I think those experienced journalists, us to some extent, leveraging shot GDP in working out those stories, making it more efficient, not as efficient as it could be. But I think most of them said they use it less for grammar. So they'll collect information. And it's easy to actually ask data to be to organize your content, and write a story. So within maybe three, four hours, they're able to write two or three stories and post them or send them to different media outlets.

Nikita Roy  9:08  
And about your research. Specifically, could you talk more about the people that you interviewed and the countries that you were speaking to, were they mainly a lot of freelance journalists, or people working for media houses?

Gregory Gondwe  9:20  
So I had both, you know, I wish I just focused on the few with the specific characteristics, but I looked mostly, I mean, I did a convenient sampling approach where whoever came in, you know, and had certain characteristics they qualified for my study. So I had people from, like the Congo, Dr. Who are French, you know, then I had people like from Zambia, from Tanzania, from Uganda, and from Kenya, so those places which gave me generalists, some work for the government media, others work privately in private media outlets, and they are those that have just emerged as bloggers and others. You know, kind of, it's hard to contextualize some media outlets. In Zambia, for example, we have what we call, we want to media. This is a media outlet that was started by a young boy. It's just a festival media. And it has become more popular than the government media. But I was also able to actually engage with such kind of journalists, you know, which in general says some people would say, that's not journalism. But it you know, it is journalism, because these kids are whoever they are. They're really contributing to journalism practice, even compared to the government media.

Nikita Roy  10:33  
And did you see nuances or differences in the way each of them were using Chad TPT. And what was like the general use case that people weren't having for Chad TPT just wasn't writing stories,

Gregory Gondwe  10:44  
many of them, it was writing stories, because, you know, initially, they thought they could use it for other things. Who doesn't want to plagiarize? Other than because the law actually doesn't allow you to do that, you know, it's more efficient for most people, I mean, look at the students. And that's the challenge we had, by the way, not everyone was so precise, that was meant to be a job. But the idea is, it charged up makes things easier for most people and journalists wanted to take advantage of that. They don't want to sit down and continue writing a story, or change a story that are reporting about a different country where they are not, it was easy for them to just take such DBS check TP write this for me, and especially for the media outlets, like where one two that are not so much restricted by government rules. So first, I noticed that most like government media, most journalists in the government media are kind of older, you know, an older generation. And I think they're a little bit reluctant in learning how to use generative AI. And these bloggers, people that own their own media, or people that are freelancers, were more open to using these generative AI tools. So that was the difference. So like government media, journalists would say, No, I think we still follow the traditional approach. And then they said, No, we're just excited about using this and that,

Nikita Roy  12:05  
were they talking about how quickly now they were able to produce content and reach their audience quicker? How would they see the possibility of Chad TPT as a potential to reach a wider audience really.

Gregory Gondwe  12:18  
So basically, that was the the idea from the beginning of the thought that was watching would happen. But then they were disappointed because Chad GDP did not operate as it was supposed to. One example somebody gave was that they wanted to write a story about the president of Zambia abolishing death penalty, which I think was a big story. But that story was mostly reported in Zambia, and maybe one or two other countries. So when they put their statue up to do that, charge GDP, give a report that sounded like Wikipedia. But it wasn't there wasn't enough content to rely on. So when they looked at this, they said, I think I can write something better than charge GDP. And that has been the experience. And I also give an example where, you know, one journalist wanted to write again, from Uganda. And I think what we know about Uganda is the President is pushing against, you know, homosexuality and things of the kind. This is what is happening, and they wanted to write a story about that it's charged up could not actually allow them to do that. It wanted to take a different narrative, not suggesting anything, but I think that tells us what chatter repeat can tell you to do and what it cannot tell you to do. So there wasn't much information don't get. And it's the same with the, you know, questions of democracy. If you want to write, say, you want to tell the church up to write a good story about one character that everyone knows as a bad guy charged up, he's not gonna do that.

Nikita Roy  13:41  
Yeah, I found that example really interesting in the way you had phrased it that Chad TPT would never help, right? Something that is against Western narratives. That's what the journalist said and chatted up tells you what is right and what he thinks is right. And that's what it's really outputting. So that really brings me into my kind of next point about the stereotypes that you were your journalist that you interviewed, were encountering regarding Chad GPT, a lot of them were saying that they tended to see that African countries were portrayed in a negative spotlight and having questions all about anecdotes with power ADC is corruption. Could you talk to me more about how Chad GPD has all of these embedded social stereotypes and what really were the journalists encountering when they were trying to write stories? But

Gregory Gondwe  14:29  
yeah, so basically what they said they did actually acknowledge that first chatted up attempted to be positive, you know, so like one thing that says, Oh, tell me about this country. It will start with a good story to tell them how beautiful Africa is, you know how beautiful that country is. But they were disappointed that at the end of the story, there will still be these highlights of this of poverty, disease, corruption, you know, like, because those are the things that have characterized Africa for many, many years. So it wasn't really talking about what is happening there. I mean, it would in a positive light, but there's always a point of reference to those things. And they thought, I think this is biased and stereotypical of generative AI.

Nikita Roy  15:13  
That's really interesting, because I think it's something that all of us just using tattoo you need to be careful about in terms of just these embedded stereotypes that are just there within this generative AI models and how it could just very seamlessly come about in a text that is generated right? In. So how do we kind of move forward for these AI tools? What do you see should happen in order for these AI tools to have more of a cultural understanding to be able to tell stories that really are reflecting global perspectives? And what should we as global journalists really need to be aware of,

Gregory Gondwe  15:45  
you know, one of the challenges I actually noticed was also with our governments in Africa, most governments still have their data in their traditional Library's you know, they'll have the newspapers, like, for example, the government of Zambia, I'm using the government of Zambia, because I'm from Zambia, they have a national media, yet, it's really difficult to find when a news story, a current news story on their website, because the website does not work, you know, so what becomes more effective is these bloggers, and sometimes, you know, individuals who just write information, and many of them are supported by NGOs, or the West, you know, maybe they are taught or you have to report on, let's say, LGBTQ, say, maybe democracy, but these are mostly western perspectives. So my point is, who is creating data for generative AI? You know, it's not the government's you know, the governments have little influence on what actually gets into the database. So the information we have might not be the most accurate information might not be the information that most governments wants to be in such kind of databases, which I don't think most government realize, you know, the search, just let it be. But, you know, I think it's a big thing that governments need to actively participate to actively engage in the creation and design of the kind of information that goes into the database. Then the second thing that I talked about is, you know, the question of civil and uncivil or incivility, I think that designers have to give room to the other cultures to participate in a way they want to persuade, as opposed to just the Western way of doing things, you know, certain ways sit in language is considered uncivil, even in terms of protests online, as I talked to most people, because it does not conform to Western standards. So what that means is that that content does not go online, the first thing, because to be flagged by Facebook, Facebook, and WhatsApp are the main platforms that people use. So it doesn't get into the database, what gets into this database is just, you know, standardized language, Western style, language and show. And it also this, I think, goes is mirrored in journalists as well, when I talked to them, they said, you know, they don't, they have no time to tolerate language that is not clear. And when, when they say it's not clear, they mean, maybe language that has caught switches. And that's how we speak in most cultures, you don't just speak clear English, you know, you use your mother tongue language, then you add some English, or sometimes we use the cultural context, which to many people might not make sense. And hence, all that does not get into the database. So what gets into the database is something that is still organized within the framework of the West, you know, journalists, African journalists might be participating, but most of them are working for NGOs most and has the content that gets into the database becomes waste. So the biggest thing I think, is like, you know, governments, African governments have to realize that it's important to participate in the creation of data, you know, and then the second thing is, I think, I don't know how this is an ethical concern, we need to participate in designing our own databases, you know, because Chungi to be relies on database. So it's knowledge, let it not just be formal language, but also a formal language. I know that trying to actually do that. But it's not enough. You know, they're trying to do that for languages that are famous Swahili, for example. But Africa has a lot of languages, and there are many others that are developing, which I think we can really add to that. And the only way we do that is to actually actively engage the local people, because they're using HTTP already. They're using Facebook, they're creating in one way or other databases.

Nikita Roy  19:43  
I really found that entire issue that you highlighted about the lack of data, specifically from African people not making it into the database and that limited corpus that charge GPT is really working on as a result that perpetuates that Western bias. And so I really want to understand more about really the differences between the civil and uncivil language that you're talking about. Can you give me really an example of what you mean by that? And how is charged between not getting those nuances correctly? What would you like it to be?

Gregory Gondwe  20:17  
Yeah, so you know, we speak differently, not just in terms of language, but in the way we actually present the cultural artifacts, you know, cultural language. I'll give an example. I know, this is extreme. But you know, in some cultures, it's easy for somebody, they're joking, let's say you, I'll kill you, they don't mean that they will kill you. So if, let's say something like that is posted, is automatically flagged, but also that goes to things like, you know, couches, say in some couches, in Africa, bear breast is not nudity. So it's a cultural thing. People are expressing themselves, which is different. I mean, they're in Africa, let's say, being in a swimming costume is probably more nudity than bare breasts, you know, women actually do breastfeed in a on a bus, and no one actually is concerned about that. But you know, in short, all those things are still not so much considered as part of culture. They are flagged, you know, it's okay, you can walk in your underwear. And that's not nudity, but you cannot breastfeed in public. So those differences are what actually push us towards Western perspectives, you know, Western standards. Because when we bring in our own cultures, when we bring in the way we speak, when we use code switch language, that's uncivil, but to the western standards. So Can there be a context that is just you know, reflecting and allowing people to participate? Or express themselves in the way they've always expressed themselves as opposed to learning civility as the West? What?

Nikita Roy  21:51  
Yeah, and I found it interesting, this theme throughout your paper of data as the new form of colonization that was being mentioned. Could you really talk to me more about that? And how would you see the future really looking like in African countries?

Gregory Gondwe  22:09  
So yeah, you know, I also talked about agency, in the sense that, you know, we need to actively participate in the whole process, not just of the design, but also, you know, in creating what has to be there. I joke that the funny part is, most people that are in tech, those design tech, actually have a global soft background, we have a lot of people from India, waking that a lot of people from Nigeria, a lot of people from China, the question is, how do we forget to add, you know, the cultural context and just stick to the western context. So that is still a paradox to me. I don't know how that happens. But you know, in perpetuating the standards of the West, we are also kind of killing our own standards, you know, in the next 2030 years, or maybe even sooner, we won't be seeing things that we've considered Africa. And I think, what is it, who are we without our identity? You know, it becomes but I think the beauty of whatever place, whatever country, whatever continent is the diversity, diversity for diversity in the way people speak. And I think if we appreciate all those contexts, and we also acknowledge that what they are doing is important, and even if we do not agree with it, then we need to actually safeguard that. And this is not happening in most African countries. Technology, yes, generative AI people argue that it's neutral, you know, but it's about what it carries, and where it pushes people. That makes it a question of colonization of neocolonialism, you know, and it should be a deliberate effort to deconstruct such kind of narratives that you form, what it is Lamby Sibella, wrote a very good piece on the Ubuntu and relationality. And he also pointed to some of the things that we need to do, and some are mirrored in my paper, you know, like, where we just have to do a deliberate thing. I know, this is an ethical thing. There's no legal context to this, you know, bite cause for everyone, and especially those that are actually designing technology to realize that we need more input from outside the western context. And I think that's what makes it beautiful, as opposed to just the name normal standards.

Nikita Roy  24:29  
This is a really interesting perspective of as content becomes more AI generated, people use all of these AI tools, being aware of all of those stereotypes and bias if it's just coming from a Western perspective, kind of homogenizes all of the perspectives and that's really what your research was kind of talking about, and it's finding so far. Right. And I want to delve more into with journalists who are currently using it in your research, what kinds of issues related to plagiarism and misinformation how aware where'd they have all of these different issues? And how concerned were they of using AI tools?

Gregory Gondwe  25:05  
So the question of misinformation came in, you know, and it was a concern, but it's most of us sometimes do not know, or it's hard for us to know what is happening somewhere else. We mostly rely, let's say other news sources. But we also know that most news sources are biased. It's hard for me to write any story about Russia, because when I don't understand the language, and all kinds of stuff. So the question if, let's say, I used a chart GDP to write a story about Russia, to what extent is it going to be giving me accurate information, you know, so there's that level of perpetuate perpetuated misinformation, which actually is embedded within the design, or is embedded within other powerful media outlets or cultures that want us to take one single narrative as opposed to the other by one thing that I think I was happy about was the question of plagiarism, which they said, you know, so it's not, it's almost impossible to plagiarize. And the reason was, because they were actually writing, it's hard for tragedy be, like I said, to write something that is local, because there was nothing about it. I mean, there's a temptation of actually plagiarizing with church GDP. But at this stage, I think it's difficult unless you're writing an international news story, let's say for BBC, or anything else, which is also very difficult for you to do using church because they already have the information out there. So most of them wanted to write stories, local stories, or maybe a story of their neighboring country, you know, say, like a giving going back to Zambia, when the president, President Harker in the chilima, you know, abolished death penalty. Some other countries wanted to write about that, but they couldn't. Why because there wasn't enough information. The easiest would have been, you know, to go to the country and report on that. But it's also very difficult once Zambia was not active, let me did write something, but there wasn't enough information about it for other countries to collect and write something. So like I said, what Churchill was doing was just, you know, spitting out something that looked like a Wikipedia story. And most people, I mean, you can get information, but most information on Wikipedia also is limited in the sense that he doesn't give you the whole context. So that's a disappointment to them. But it's a blessing in disguise in the sense that it can't plagiarize they don't trust, charge it up is efficient enough to give them what they want.

Nikita Roy  27:30  
So kind of brings me to my next point about there has been a lot of concern, especially in the Western world about our is AI going to be taking away the job of journalists. But it seems like from your research, a lot of the journalists have been embracing AI and chatty, PT and using it for their work. Have they been as concerned? Has that concern been something that has been quite prevalent in that region?

Gregory Gondwe  27:53  
At the moment? No, you know, I think a couple of years ago, I did a study on just technology itself. And some of the questions I asked were their perspective on new technologies, and the migration from traditional to digital media, yes, that affected them. But at the same time, I think it helped the media outlets, it was expensive to print, and, you know, ship all these papers in different places. Now, they just had to, you know, send a digital copy to a different country, and they had people to sub people subscribing to that, but then they still had to keep some other papers out there. Because they do not just rely on subscriptions. There are still people that read and more people actually here in the West is mostly or odd. People are using that when they are read newspapers. But they're even young people are still buying why because not everyone has access to to the internet. So some lost jobs, but some found it more efficient. And the positives actually outweighed the negatives when it came to that. But when it comes to generative AI at the moment, I don't think anyone is scared that it's going to actually take over their jobs. You know, we I've seen in other parts of the world where they have these generative AI writing news stories, and even presenting such kind of news stories. I know we almost rushing at the same speed in technology. But I don't think we've reached that stage yet. And mostly it's because our databases are not representative. And it will take time for new technologies to accommodate all the different databases for us to tell a story. Yes, we could have somebody or maybe a I actually read an international news story. But it that I mean, we we've had people journalists with such kind of jobs, but that's not the only job they have, because most of the time would monitor BBC News. You know, we just infuse it into our reports. So to help but no one I don't think anyone at this stage. I know it's an overstatement. I don't think it's really a threat to the most generous

Nikita Roy  29:59  
Yeah, and with all of these issues that you've been mentioning, specifically with Chad TBT, in relation to the African continent at Broad, at this current stage, can the global south really effectively and fairly use all of these AI tools? What's your perspective on that?

Gregory Gondwe  30:15  
Effectively? Yes, fairly not, you know, in the sense that, you know, I think most journalists, for example, that I asked, are using AI for grammar. So they think it is really helping them, they don't have to spend a lot of time to rewriting the story or sending it to the editor, they're still doing that. But I think it's it comes out very clean, just from the first reporter, in the sense that once they write, I think AI is able to correct those things. So that was the challenge. You know, we were both countries in Africa, I can Zambia we speak English by is different kinds of English. So to make it or meet the standards, I think there's a lot of work that was required from the journalists and from the editors, such that they don't make any typos or any errors in their stories. And Chuck GDP has been very helpful in that manner. And most of the journalists are using church GDP specifically for that supports to, you know, generating stories by itself. So I think that's where, you know, the efficiency is coming in. But in terms of fairness, I think we still need more, to really claim that we are fairly or charged GDP is being fair, in the way journalists are using it. in Sub Saharan Africa,

Nikita Roy  31:29  
this has been really just an interesting perspective that I have not been able to get a lot of information on. So it's been such a very insightful conversation for me, and kind of wrapping everything up, one of the major things I've taken away from this entire conversation is that AI and journalism in the sub Saharan region, it's really having a more increasing role. And these rapid advancements of technologies are really pushing the boundaries of probably what we previously thought could be possible. And journalism, the industry has kind of not been untouched by its influence. So given your extensive research in this field, how do you see journalism evolving in the sub Saharan region? Now, with the increased use and development of AI tools? What will the future look like?

Gregory Gondwe  32:12  
First, it's really hard to make a clear prediction, because we are at a stage where I know governments do care, you know, they do the censorship and surveillance, but we are at a stage where almost anyone can create content. It's easy. Now, I've seen people that have become, you know, influencers. And they have like, maybe 10 million people, followers, and they're just on Facebook, you know, they create some news, they do all that things. And one example I gave was the web to media, which was started by a young guy several years ago, in Zambia, and it has grown into something bigger than the government media. The challenge is that, you know, influencers or people that would cause claim as journalists, I mean, I still call them jealous, because they do a great job. But they'll have great influence in decision making, you know, in policies, you know, like, these people can actually meddle into politics, you know, voting behavior. And the difference is that, you know, these are not celebrities that people can endorse. And we know that, oh, this is a celebrity. When they said this, maybe they are paid. These are just ordinary people, maybe they're just young, in one place, and they have a narrative that they throw out there. And sometimes, as we saw in Ghana, these people are used by governments or by the opposition, say, or send this message. And because you have 10 million people, then your message can get to most people. So yes, we seeing a lot of people being able, especially young people using generative AI, because I think they are tech savvy compared to the older generation. And that, I think, is something that we need to be considerate, especially governments really need to see or look into that as something serious, as opposed to all people just I mean, I'm not suggesting people should not express themselves that what's public space, and what's the internet is. But I think, again, I go back to the point I made, the government should actively participate in organizing what actual represents a country, as opposed to anyone you know, who feels inspired by the Spirit?

Nikita Roy  34:17  
Thank you. Yeah, this has been such an interesting conversation generally, to get this, as I said, very much needed perspective, really, on how people apart from the Western world have been using generative AI, what are the issues that have been facing and I've taken away so many insights, and learned so much from your research? So thank you so much for the work that you're doing and talking about all of this. And thank you so much for educating us on all of these different perspectives.

Gregory Gondwe  34:43  
Thank you so much. I know you know, there's a lot to talk about, and I keep talking and talking because ideas continue coming, you know, if so, so very fascinating to me. And also thank you for giving me this opportunity to to actually share some of the ideas and I hope some people pick one or two things

Nikita Roy  35:00  
Yes, absolutely. I have taken away a lot of insights. So thank you so much for joining us on The Newsroom robots. Greg. It's been lovely having you

Gregory Gondwe  35:08  
Krisha. Thank you.

Nikita Roy  35:11  
That was Dr. Gregory Conway, assistant professor of journalism studies at California State University, San Bernardino, and the Harvard visiting scholar with the Institute for rebuilding social media at Harvard University's Berkman Kline Center for Internet and Society. This podcast is made possible thanks to the spark round from the hub and innovation labs. I'm Nikita Roy, and this is newsroom robots.

"
newsroom_robots,11,"Wed, 21 Jun 2023 19:06:08 GMT",Ryan Restivo: Inside the Product Life Cycle of Building an AI-Powered SEO Tool,https://www.newsroomrobots.com/episodes/ryan-restivo-product-life-cycle-generative-ai-powered-seo-tool-yeseo-CjQxUG5n,"<p>Ryan Restivo joins host Nikita Roy to discuss the product life cycle of building a generative AI product. As a Reynold’s Journalism Institute (RJI) fellow at the Missouri School of Journalism, Ryan developed <a href=""https://www.yeseo.app/"">YESEO</a>. This free SEO slack tool uses Natural Language Processing and Generative AI to help newsrooms with SEO best practices. Since its launch in March, over 160 newsrooms have adopted the tool. </p><p>Besides his work on YESEO, Ryan holds the Director of Product position at Newsday. He has more than a decade of industry experience in digital media.</p><p>In this episode, we hear about Ryan’s journey building the YESEO app and  explore the unique challenges and opportunities of building generative AI tools</p><p>Thoughts or questions? You can reach us <a href=""https://forms.gle/egyJZDsGjogiyNTH8"">here</a>.</p><br /><hr /><p style=""color: grey; font-size: 0.75em;""> Hosted on Acast. See <a href=""https://acast.com/privacy"" rel=""noopener noreferrer"" style=""color: grey;"" target=""_blank"">acast.com/privacy</a> for more information.</p>","Nikita Roy  0:02  
This is newsroom robots, the Podcast where we explore the intersection of artificial intelligence and the news industry. I'm Nikita Roy, a data scientist, media entrepreneur, and one of the many founders currently building their ventures at the Harvard innovation labs on the newsroom robots. I'm excited to bring you insightful conversations with industry experts about how AI is impacting the way we do journalism. My guest today is Ryan Restivo, the founder of the SEO a free SEO slack tool that uses natural language processing and generate AI. To help newsrooms generate SEO friendly headlines and descriptions. Ryan developed good SEO as a 2022 rj Fellow at the Missouri School of Journalism, which over 150 newsrooms have since adopted. Besides his work on SEO, Ryan also holds the position of Director of Product at Newsday. In today's episode, we dive into the product lifecycle of AI based products, explore the unique challenges and opportunities of building gendered AI tools, and learn more about how Ryan developed the SEO app.

Ryan, welcome to newsroom robots. Thank you for joining us.

Ryan Restivo  1:21  
Yeah, thank you for having me.

Nikita Roy  1:22  
So I'm really excited to talk to you today about how you went about building your agenda of AI product. Yes, SEO as part of your RTI fellowship for the Missouri School of Journalism. I mean, this is a really emerging technology, and you've been actively contributing to this space. So I want to begin first by understanding all about the story behind how your CEO came to be. And how are you helping over 150 newsrooms with harnessing the power of generative AI?

Ryan Restivo  1:52  
Yeah, so like my RGA project idea came around January 2022. Right, I was approached by an editor in my experience rate that she asked me about a story that didn't particularly rank well on Google. And we made a Google sheet, we looked at all of the different elements on that page and compare them to the competitive market rate of what the story was about a home health care aide that did some particularly bad things. And once we made that comparison, right, of all of the things on the page, we quickly realized that we just didn't have the core elements of what we needed on the page, like the who, what and when they were just not there compared to the others. So then that idea evolved into the idea, like, can't make hundreds of Google Sheets for folks could we make like a tool where people are using slack and they can get responses and understand their stories better. And that's eventually what became the the idea for my RTI fellowship and then working with, you know, all the folks that are GI and Mizzou, right, be able to evolve that idea past what that core use case is thinking about the story that just exists to then a story that maybe doesn't, maybe something is before publication, and trying to extract the data out that way. And try to think of it in those terms and try to give journalists more useful tools. And then, you know, six months into an eight month fellowship process, this whole chat DPT stuff starts popping up and thinking about how to kind of position it in terms of the things that I believe in, right. The reason I want to do my RJ fellowship is because I you know, I've made useful tools in the past. And I've wanted to try to use these skills to help more newsrooms. Right. And that connects with ArcGIS mission of providing free practical innovation to local newsrooms. So yeah, so then trying to figure out how to use generative AI in this space, and kind of thinking drawing on my experience rate. And we'll talk about this, I'm sure a lot, but I kind of settled on this idea of suggestions, write recommendations. I talked with the newsroom in British Columbia recently, a couple weeks ago, and talked about how like technology plus newsrooms equals fear, right? So how can we kind of lower that fear, we try to lower that fear in the SEO by spoofing the surfacing these suggestions, so you suggested headlines, you know, they're not meant to be and appeals if they're perfect, you can copy and paste them, you know, in, but they are meant to kind of get your brain go and get that kind of process flowing. And think about a maybe these are, maybe there's some things that are good in here. Maybe there's things that are okay, but don't fit my style. But then I could take them and repurpose them into a better idea that I could put on my on my page. So that sort of kind of thought about that. And yeah, I'm really happy with how well supported it's been by the community. And yeah, I look forward to continue to build on it. But yeah, it kind of started a very long time ago. But since then, it's it's been really awesome to build something for folks and to see local newsrooms pick it up, and they get a lot of valuable feedback from him. It's been exciting.

Nikita Roy  4:31  
And what are all the different features of guest co like, how is it helping newsrooms with producing their content and use generative AI in their newsroom?

Ryan Restivo  4:40  
Yeah, right. So so how it breaks things down either you can use a an existing link, or not existing story, so you could copy and paste that in. I like to say it's as easy as copy and paste, right. So you can paste the link, you could paste the story, and you could see what happens right? And what it's doing in the background is it's using like natural language processing, which I like to sometimes call Like the the AI before all the generative AI was cool, but it's doing it using that to kind of extract what's in my story. What are the main kind of subjects? What are the main who, what, when, where's And why's right. And that is kind of using that to then draw out a bigger understanding if it's an existing story. It's saying, Okay, well, how strongly is my headline related to what's in my story, like, are those strongly or loosely related? Like, we could tell that with some math, right, we can count how many times somebody's mentioned in the story. And then we can figure out, hey, if we're not mentioning it in their headline, maybe we're not giving people when they click in the thing that they're actually looking for. And then conversely, when we're talking about using general AI, right, we're generating a headline off of that story, to hopefully bring somebody in that would be interested in reading that content. So it's kind of trying to do that in both different in kind of two different ways. Right. It's also taking those keywords, it's trying to use a trends API that I tried to look up some real time data just to get some data backing behind it. Right. So if I'm have a story about Taylor Swift that's in the data, I think just I just saw in the logs, right, I could kind of get some related links, or what would be the strongest will be kind of the strongest queries related to Taylor. And then some other searches are rising queries in my area at the right time. So it's trying to figure out how to surface that data at the right time for users and try to eliminate try to reduce the time it takes to get from story to get it out on the web.

Nikita Roy  6:17  
Yeah, and we are in this interesting era where we are having bots, right for other bots, like the search bots, you know, so we have like, you're having guest SEO and now suggesting you headlines that is more SEO friendly for the search engine bots. But how do we kind of move on and have a human voice? Are we entering an era where there might be similar headlines? Because just because for a major news story, you have multiple newsrooms covering the exact same news and what's different is the headlines, how is yes, you're kind of dealing with that issue of generative AI, and not leading to just like homogenizing, all the different headlines and suggestions that are given? Yeah, so

Ryan Restivo  7:01  
a good example I've drawn, I've actually drawn up pretty good examples recently. So a couple of the newsrooms that I've talked with so far, that UCSC Oh, they talked about different scenarios where they'll use it, right. So one talked about where maybe one of their stories wasn't drawing as much traffic as they thought. So they said, oh, we'll put it in SEO, we'll see if we can generate a different headline to see if we can drive some more traffic to it. Right, something they expected and maybe didn't get exactly where they want it. For a couple of newsrooms talk about how this is kind of a thing on newsrooms, right, where they'll make a headline channel, headline, ideas channel. And right now, what they can do, instead of just drawing or kind of looking at their story and generate some headlines on their own, they can invite the SEO app in there, they can hit this just headlines, button, and bang, they have five different ideas they can work off of, and they can use them to get to where they want to write, I think that to what you're saying, I feel like a human is always gonna be part of this process, right? The SEO app works in Slack, it doesn't work with your CMS, it's agnostic to any CMS. So you know, all the different content management systems out there, as great as they are. Right? It doesn't matter which one it is, because it's not, it's not writing that immediately into your CMS. So it's never going to, it's never going to take that step, there's always gonna be a person who's going to have to take these ideas and activate and think about, okay, what is the best thing for me, and then kind of make that decision. So I felt like, you know, these things are useful tools, we both know, you know, this is supposed to be a tool to help people make better decisions. So as long as we're leading towards better decisions, and hopefully better decisions faster, that means that people who are already strained doing a lot of different jobs during the day can hopefully have a little more time to do some of those other jobs that they're looking to do.

Nikita Roy  8:35  
Yeah. And it's very interesting to hear how you went about thinking about building SEO and the role you're seeing it playing in newsrooms? And I think there's a lot to learn from that. And I want to learn more about how you went about building a generative AI product, because this is an emerging technology that's been changing rapidly. How were you navigating the different product lifecycle stages when building SEO?

Ryan Restivo  8:57  
Well, I had to build a lot of SEO without help with GPT, right, because I was still building for a while. So like, it was not easy when you know, you're looking through a lot of manual documentation to figure it out. But no, I built like a, I had a prototype that I started with, back when I started the RJ fellowship that I talked with, to very good developers to get ideas about how I should develop this. And I decided to scrap that entire prototype and start over basically. So then I had a better prototype that I worked on, I put on like a little raspberry pi, right. So that's like one of these little tiny computers. So I had that to test against rate, which was good. And then I had to had to rebuild it to deploy to put it on, like, put it on like a service, right? A cloud service, what you wanna call it, so I need to rebuild a bunch of pieces to it to then get it. One of the things I wanted to always do is write the multiple be able to install on multiple workspaces. I had never worked with the technology called OAuth before that you need to do right this little exchange when you hit Add to slack. It's doing all of the perfect stuff though. Knock on wood now because there was a lot of imperfection before when this initially launched where people will get out Were screens that they had to work pretty hard to install it initially because of mistakes that I've made. But I think I believe now it's a lot easier to install, right? So so trying to figure out ways to kind of remove that friction and get people in has been one of the tougher parts using GPT. Right? I talked with a developer in December, who's much smarter than me, which is one of the keys, right? Talk to people much smarter than you. And I was looking at it, I was playing with it, right building documentation and stuff. And then he talked to him. And we talked, and he's like, you know, I'm using this to learn Ruby, right? I'm using this to learn Apple TypeScript, I'm using this to learn all these things that I just didn't have time to learn in the past, but I can use like assistance to learn, right? And that changed my mindset from where I was at where I was trying to like, Okay, I'll use this as like an assistant that will build some docs for me for when I develop later in my core code, right? And then that got me to the idea, okay, how can I use what's here to apply towards giving a user something different that they might not necessarily see before? And that's where I kind of landed on the idea of like, when I have this data from a from a story, could I use it in a way that will help somebody kind of do that part of the job better? So that's where I landed like, Okay, well, let's feed some, some text into this. And let's ask for some headlines and see what happens. And it was initially built for TPT, three, and then TPT, 3.5, and four came out, and you have to change the little calls that get made. But eventually, yeah, it became this little button that, you know, it's really great. Because, right, you don't need to develop anything, this tool exists that's free out there. All you have to do is put a story in and hit the button, you don't need to worry about build versus buy, right. It's already out there. So so if you're one of those newsrooms, who wants to try, you just need to go in, put a story and hit the suggest headlines button, and you've already done it, right. So we've really lower that barrier to entry for folks like that's, that's really where I've wanted to kind of position this thing, right, I want to make sure that it's easier for people to get these kinds of insights across newsrooms everywhere, and especially small local newsrooms that I've really found some value out of it.

Nikita Roy  12:02  
Yeah, and I'm quite interested in knowing because you've had quite a bit of experience building products previously. And now when you land on building a general AI product, were there any similarities or differences in the development from digital products and any AI specific hurdles, or challenges that he didn't anticipate?

Ryan Restivo  12:20  
A ton of hurdles and challenges? Right, especially building this through my RTI fellowship? You know, I talked with a lot of newsrooms throughout the process of building this product, right? Where are the things that are going to what are the things that are gonna be valuable for newsrooms, right, and how to kind of think about what the most important things are. And one of the most important things I got from that was about the headline we've talked a little bit about now. But like this headline is the thing that journalists has the most power over to make sure that their work is read. So all the things we've already talked about and further, are kind of trying to put that at the center they're trying to put is relating your headline to what's in your story. And then also relating what's in your story to generate a headline, and then the keywords outside of it. We're trying to kind of use the headline as the center and kind of span out. It's just one of the things that I heard initially, in like, initial research was like, think of like your SEO, we think of like your, think of like the tags or like your keywords is like this, like kind of like, like the wheel, right? That was something in the center, and then all the things kind of fan out, they kind of come out a little bit. So trying to think of the headline as the center kind of everything else stretches out. So yeah, so I feel like that's really helped me kind of figure this out. And then the SEO app is pretty unique in terms of slack apps that I've made. It's probably the most advanced slack I've ever made using the slack bolt framework, which is like a more recent update of how Slack has made apps before. In my background, right? I've built one of the reasons I learned to code was because of slack, right? I noticed the slack apps were starting to pop up and like 2017. And then I just tried to pick it up just to see if I can write something that'd be cool. And I made this one bot. I'm not very original with naming things. So it was called not Ryan Restivo. And all it did was this, it just did a bunch of different bots stuff. It just looked up all this different stuff. And I hooked as many things I could learn at the time into it. And I got insights from the newsroom and working with and they're like, you know, it'd be really cool if we could just check the breaking news email newsletter right before and have the copy desk and the editors just sign off on it before we're four ready to go. And so I built that in like two minutes. And then it was like most used thing ever. I had been working on it and testing it locally on my machine. So that actually meant that I went on vacation and I left my machine running at my office just to have it running. We eventually put it on the servers, of course, but that was kind of like my first foray into like learning about product and like learning about how like the different what is going to be valuable to folks could be very different than what you try to build. But the SEO app right? It tried to try to keep the principles the core principles of what people told me at the center. I had some ideas other ideas around like, like core vitals and like speed and certain stuff like that, and I showed it to an editor one time Um, during this process, and she's like, well, this doesn't really do anything for me. And that gave me good insight because it made sure that I want to make sure that I want to do the thing for newsrooms that was going to do well. And it was focused on the headline, right? And focus on that. And tangentially, right? Core vitals are a valuable part of SEO, but, but you don't have a lot of editors caring about that too much, right. So. So I was trying to make sure that I had kept the what needed to be at the center of the center and kind of build off of that. And the one thing I mean, in terms of the experience with digital products, I just feel like things are never done. Like I've been making tons of changes from early March, when this when this came out the SEO, right? I've made tons of different changes. And this code changed a lot in here to maximize some efficiencies. But also I'm experimenting, trying to drive off of all of the feedback I've gotten from users, and trying to figure out how to make this thing better for for people who come in and people who use it now.

Nikita Roy  15:51  
Yeah, and I want to get a bit technical with you about the product. And for others who are looking to dabble into building generative AI products. What is your tech stack with the SEO? And how are you kind of helping so many newsrooms with this app?

Ryan Restivo  16:07  
So I write in Python, right. So I'm a like a lot of folks. But let's see, I think it's like 39 scripts now that run this app. So it's a pretty big beast. And I kind of started with the idea of like, what the story was, the story is like a giant, like, you call it the dictionary of Python, where it's just like a giant like place where you just put a bunch of different kinds of data, and you try to understand each piece of it. And then eventually, that data from people's commands goes into, like a Mongo database. So that's like a non relational database, I got very good advice from a friend to kind of think about using that. And then, as I learned more about how Slack needs to work, and how and how all of the other things that I wanted this thing to do work, really trying to store them on relationally, it worked for me, because it just meant that I would always have some data that I could always come back to and refer to, every time I needed to. So eventually, when I built this and kind of continued to build it, a lot of the buttons that are in the SEO app, when you actually finish your request, a lot of those buttons are already ready for you. It's just you need to press them. So that helps me kind of in the efficiency side, because all you're doing when you press that button is you're just summoning the data from the back end, you're not really you're just summoning that message that message already exists. So one of the things I try to think through is about like, elf, a lot of people are using this at once, I want to make sure that it's not going to get like choked up, or something's gonna go terribly wrong. I mean, in my mind, I feel like there's always gonna be something that's gonna go terribly wrong. I broke stuff this weekend, right. So I would just try to figure out like, how I can make it as efficient as possible that people aren't going are tripping all over each other to get the things they need. And that's kind of where I've kind of come back on and write in Slack serves up messages in this kind of like blog style, where it's like, Jason, so like, you know, feeds, right. So like trying to just build these things, that kind of gets surfaced, and kind of just every button is is kind of a different level of that. So as long as all that data is getting added in the proper place, it's always serving up the things that people are looking for. And the kind of every different action has a different reaction that it listens for. But then he I'm trying to add things on top of it. That makes it a little difficult, because sometimes I'm trying to add something into an existing an existing data, I'm trying to think about, okay, how do I insert this kind of piece that I want to? I'm trying to think a little bit more about some feedback I got in terms of like, how can the app know what the main subject of your story is? And trying to trying to kind of not just think about that more, but also draw on like, Okay, if I figure that out, what else can I tell the user about? What SEO knows about the story? And what else could be useful and vital and helpful at that time?

Nikita Roy  18:39  
Yeah, and with GPT, 3.5, GB, four, you're having all of these different models coming out and more coming soon. And as it advances, you having a different, like higher cost to deal with, with all of these different GPT models? So how did you approach your validation? In terms of what generative AI modeled to us? What was the deciding factor for you?

Ryan Restivo  19:00  
So yeah, I'm indecisive. That was a good way to put it. And you've done this too, right. So I worked with Nick the Acropolis out at Northwestern, right. And his generative AI in the newsroom project, right. So one of the things I initially focused on for that was, let me evaluate GPT, four and 3.5 to generate headlines. Everything in the SEO app says that you're using GPT to generate headlines. It doesn't tell you which one it's using. It was like a wink wink Nanda that we're not telling you for now. But every time you generate those headlines about 30 seconds later, you get a prompt that says were these headlines useful to you? Right? Yes, no, we're not sure. So we're trying to track that data. So I've been kind of a be my first test, which you can find it yes to that app slash study was a test of whether or not GPT four right, which is 15 times much is more than GPT 3.5 was going to generate better headlines for these newsrooms. And the data was actually pretty marginal based on the prompt that I had at the time. I've already done a second test that I'm going to wrap up very soon. That I added a little bit more to the prompt. And I've seen a very big jump, like a 10%. Jump on both. So I'm pretty happy with that. So now I'm trying to think about, okay, let me see if I need to now I'm gonna kind of close that test that kind of test. Another thing, I have it in my head, I don't have the code down yet, but trying to think about just learning building, you know, going from idea to building to learning to measuring and all that kind of stuff. And, you know, taking that away, and then kind of building more experiments on top of it. So I've kind of used both for now, I haven't really decided whether or not one will be better than the other. But I've had good feedback in terms of you know, I get little feedback notes from newsrooms, right. They're like, Oh, that they've used it or that it's worked right. One newsroom out in Oklahoma was telling me last week that they will kind of mix headline ideas that they'll take one from one piece and one from another to kind of mix kind of what they want to do. And that's what it's meant to do. Right? It's supposed to help people get to their ideas faster. So, so that's exactly the kind of thing I like to hear about it. But yeah, I think that like, the different, like in terms of which version to use in the future, I think that I'm still evaluating it. And I think that I want to kind of continue to build and evaluate how well it does. And then that'll help me kind of that'll inform me for future decisions that I got to make.

Nikita Roy  21:12  
And I was seeing that, yes, yo can be used for other languages other than English. And that got me quite interested to hear, from your perspective, how effective is genitive AI, with other languages? Have you had newsrooms using it? What has their feedback then?

Ryan Restivo  21:28  
So far? A couple newsrooms use it. Right. So in testing, one of the testing newsrooms that I work with published in French, so when they started using it, and it was all in English, they were like, This is not very good for us, right? The English model is not gonna work for us. So that's when I really took that feedback to heart and thought, Okay, well, how can I do this? So in the process of the SEO app, right, when you enter that story, your story, it doesn't actually apply them, it kind of reads your story, and then says, Okay, I'm gonna apply the English model to it. So it's actually reading your story first, or reading your headline and saying, Okay, this headline is in French, I'm gonna use the French model. And then from there, it'll make the other decisions, right, they will use the French model to draw out those French, the French entities and, and do any other kind of kind of work to for keywords and stuff. And then the General Via piece of it right, kind of, it'll use a prompt that says the prompt needs to be in language, and then kind of make sure that that that that gets used properly. I know that a couple times, there have been issues with that. But I believe that yeah, it should be pumping out headlines in let's see French, Spanish, Portuguese, I don't remember all of them off top my head, I believe it's up to eight languages. Now I keep adding based on the models that I'm using for the natural image processing, which is a library called Spacey. So I've just tried to add as many as possible to because right, the idea is to help newsrooms and unfortunately, I only know English. So all of the text in the user experience is in English. But if you were putting a story in there in Spanish, it will understand that it's in Spanish and apply Spanish models to what it would need to do.

Nikita Roy  22:54  
And it's the Spanish model or the other language models that you find them as effective as the English for genitive AI,

Ryan Restivo  23:00  
I think so I actually had to look back. And yeah, that's probably not a great answer. But I probably have to look back on the data to make sure because I know that the majority of users are using it in English, which has been good. But yeah, I want to make sure that it's just as good in every other language that it is. And then it isn't English.

Nikita Roy  23:16  
I can't go without talking about a generative AI product without touching upon the question of ethics and bias. And when you were building it, what kind of ethical considerations you had to account for when developing a generative AI product like SEO?

Ryan Restivo  23:29  
In my background, around 15 years and digital media? I feel like there have been a lot of different things that have happened to digital media, right? The rise of the Internet, social, mobile, all the stuff in general AI is there's another piece of that right? Early on very couple of months. And I think I was telling folks, right, this is like the iPhone, the first iPhone, right? Like, you know, it used to only be used on ATT, it could text very well, you know, your phone calls would drop out all the time, we're still trying to find the things that actually mattered in here. And, you know, many months later, the App Store came out and and kind of things flourish, right, the App Store has created a new industry that was just based on us wanting to use our phones a lot. And I think that in terms of generative AI, I think through that lens, because, you know, I've had experience in newsrooms, you know, obviously talk with and work with a lot of folks that have, you know, adopted the SEO app and try to make sure that it's reflecting things that they're looking to do. I think that, you know, I really try to position it to make sure that people know that I'm not here to take anybody's job. I'm here to help people get to what they want to faster. And that's where I feel like yes, your app has a unique advantage, because it's using data that you otherwise already have. And it's trying to just get you better ideas. It's not trying to replace anybody. It's not trying to it's not trying to like maximize efficiency in a certain way that you wouldn't otherwise do. Because a human always has to be part of the equation. And I think that it's just trying to help people make better decisions with the limited amount of time and resources that they have. It's trying to be a good resource. For folks that maybe otherwise wouldn't have had a chance to develop a resource like this. So it's trying to be a useful system for folks. And I think that the more that it can do that, the better off it'll be.

Nikita Roy  25:11  
Yeah. So it's just another tool that users can use to help maximize what they're doing currently. And I want to get more insights for listeners who might be looking to develop ai ai based products like this, what advice would you have from them from your lessons that you've learned building SEO,

Ryan Restivo  25:28  
lessons I've learned, especially as our GI fellow, I got very good advice early on, to remember the reason I wanted to do this rate, that the reason I won't do this was to develop something, to stretch my skills to help more people than I've previously helped. And those all we've talked about connect to ArcGIS mission of helping small newsrooms and make sure that the reasons you want to do something are reflected in the work that you want to do in the future is really the thing I would tell folks, is I know that's a very broad answer to kind of using using anything. But I think that as long as what you want to do connects with, with how you want people to use it, I think you'll be you'll be in a good place.

Nikita Roy  26:09  
Yeah, going back to that why of why you building a product is important so that we maximize our goal of building the AI product. So I see newsrooms of all sizes right now are also just recognizing the importance of AI across the world and adopting AI. It's not just about tools, but also about like a people and culture. So in your view, how critical Do you see it for newsrooms to invest? Not only in AI technology, but also in like training and journalists about AI?

Ryan Restivo  26:40  
Well, yeah, I think it's, the box is open, right? Like ever, the floodgates are open, now people are using this stuff. It's being incorporated across industries, right. So people are going to be affected by it, whether or not you want to be involved in or not so. So for the industry, writ large, are kind of speaking broadly, they kind of have to understand how this will affect them, and what kind of opportunities will present a kind of go back to the idea that, you know, journalism, what we're doing, we're trying to tell people stories are trying to give people information that will help them have live better lives. So it's about how we're surfacing that information to people, and making sure that people understand what we're telling them, and that they're getting that value out of it. So I feel like there's always going to be people in the mix, which is, I keep talking about people, but you know, we are people that people business, and we're keeping people in the equation, this just about how people are gonna get supposed to us might change, and how to kind of learn, I guess, learn some of the lessons from the past disruptions to make sure that you aren't left behind in the future ones.

Nikita Roy  27:41  
And we're standing on the cusp of this, like new era where AI is becoming an integral part of journalists and a lot of conversations that are happening. And, Ryan is you've been someone who has worked closely on both sides of the newsrooms, what are your thoughts really on, like looking into the future? How our interaction between human journalists and AI tools really going to be coming together?

Ryan Restivo  28:05  
I'm trying to think of I have a good answer for that. I like I think the SCO is uniquely positioned right to be a tool for journalists, right. I think that our journalists, I guess, I maybe I could speak broadly to journalists, right. But like the job of what the journalist has to do on a day to day basis is not easy. And I think that there's somebody who has, who has maybe written like, maybe like a couple bio lines in his life, you know, understands, right that like, the job of doing that work is not easy. So when I think of it from my angle adjacent to helping journalists, right, I tried to think about it as what are things that can be done that'll help people do their jobs better. And, you know, tools like SEO and other tools out there will help people kind of get to you do parts of their jobs faster. There are tools out there that help with a lot of stuff already, like transcription, and also other stuff that somebody still has to do that job. So how do we figure out how to help the journalist do their jobs better? We'll be interesting to see moving forward. But I know with the SEO that I'm invested in helping journalists get to all the critical information they need to to help with SEO best practices. And I hope that they'll all start to use it.

Nikita Roy  29:13  
Ryan, I really enjoyed talking to you and getting to know more about how you volti SEO because I really see that message that has gone throughout where you're talking about how you could use your skills to just help more local newsrooms use generative AI and I think that's a really neat product that you've dealt and the mission of our GI that has really helped you with it. So thank you so much for joining me on newsroom robots. It's been such a fascinating conversation to get really technical with you and hear more about the whole product lifecycle stage of building a generative AI product.

Ryan Restivo  29:46  
Thank you so much.

Nikita Roy  29:49  
That was Ryan Restivo, the founder of VSCO. If you like what you hear on the podcast, subscribe rate and review the show on Apple podcasts, Spotify, or wherever you listen to your podcasts. This episode is made possible thanks to the hobbit innovation labs spark grant I'm Nikita Roy and this is newsroom robots

"
newsroom_robots,10,"Wed, 14 Jun 2023 16:22:53 GMT",Jay Allred: How a Local Newsroom in Ohio Uses AI to Automate Sports Reporting,https://www.newsroomrobots.com/episodes/jay-allred-local-newsroom-automates-sports-news-stories-fCYKiL5u,"<p>Jay Allred joins host Nikita Roy to share how his newsroom uses artificial intelligence to automatically generate sports content by converting data into news articles. </p><p>Jay Allred is the CEO of Source Media Properties, a nationally recognized local news organization serving nearly half a million readers in Ohio in the United States. The Source newsrooms have become known for their tightly focused local coverage, entrepreneurial culture, and national leadership in audience engagement, revenue generation, and solutions journalism.</p><p>Jay is also the co-founder of Lede AI, an artificial intelligence startup developed inside Source Media’s newsroom. Lede AI builds reliable, easy-to-use automation tools for newsrooms informed by the needs of readers, journalists, and communities. </p><p>Jay serves as a board member of LION Publishers and was a 2022 Sulzberger Fellow at the Columbia Journalism School, where his project focused on the development of easy-to-use SAAS tools for local newsrooms around the globe. </p><p>On today’s episode, Jay highlights his team’s journey building Lede AI, how his newsroom is carefully experimenting with generative AI, and discusses the future of the local news landscape. </p><br /><hr /><p style=""color: grey; font-size: 0.75em;""> Hosted on Acast. See <a href=""https://acast.com/privacy"" rel=""noopener noreferrer"" style=""color: grey;"" target=""_blank"">acast.com/privacy</a> for more information.</p>","Nikita Roy  0:02  
This is newsroom robots, the Podcast where we explore the intersection of artificial intelligence and the news industry. I'm Nikita Roy, data scientist, media entrepreneur, and one of the many founders currently building their ventures at the Harvard innovation labs. On the newsroom robots. I'm excited to bring you insightful conversations with industry experts about how AI is impacting the way we do journalism. My guest today is Jay alread, the CEO of social media properties, a nationally recognized local news organization, serving nearly half a million readers in central Ohio in the United States. Jeff is also the co founder of lead AI, an artificial intelligence startup developed inside the social media newsrooms that uses natural language generation to automatically generate sports content by converting data into news articles. He serves as a board member of Lyon publishers, and was a 2022 Salzburger Fellow at the Columbia Journalism School. On today's episode, Jay highlights his team's journey building lead AI how his newsroom is carefully experimenting with generative AI and discusses the future of the local news landscape.

Hi, Jay, welcome to newsroom robots Podcast. I'm so excited to just get into all about local news and how you're using AI today.

Jay Allred  1:32  
Oh, that thank you, Nikita, I'm really grateful to be here represent the team and talk about talk about this really interesting and fast moving subject, that it's moving at the speed of light right now. So slowing down for a few minutes to talk about it with a person like you is is great.

Nikita Roy  1:48  
Yeah, I remember being at your OMA panel last year, where you were talking about using AI and automation in the newsroom along with USA Today. And I was really fascinated that a small local newsroom in Ohio was using AI to kind of produce stories. And that really caught my attention. And that's why I wanted to have you on the show to hear about how did somebody in Ohio and newsroom in Ohio. That's not something that I really picture with, like aI related. It's usually in like, the Bay Area or something in the East Coast, New York and Boston. And so I want to know, how did that journey really start? And could you give us an overview really of your newsroom and how you started lead AI?

Jay Allred  2:32  
Sure. I think the thing to remember about Richland sources that we really have built a very entrepreneurial culture over the last decade, and we have always been interested in emerging technologies, they don't always show up as part of the products that we produce, or the the news report that we produce on a day to day basis. But we've always been interested in that. And I became interested in natural language AI at a South by Southwest that I attended, I think back in 2015, or 2016, I was in a session. And I listened to a person whose name I can't remember from the AP talk about how they had automated earnings reports, using structured data. And I thought, My gosh, first of all, I it occurred to me that a person had to write this before. But then when I realized like, oh, my gosh, an earnings report is the same for every company at scale. And yet, it's interesting to the people that are interested in that company. And so when I learned that the a that the AP had done that I thought wow, that is what a great use of technology, and how useful to audiences if it can be used in the right way. So that just kind of sat at the back of my mind for at least a year. And we work in a co working space here in Mansfield, Ohio, and inside the co working space was a person that would eventually become my co founder, Evan Ryan. And Evan was running a small nascent AI development company called teammate AI. And it was a one man show. And we were as cliche as this sounds, we were standing around a water cooler, and talking about artificial intelligence and our thoughts on it. And this was back in 2000, I think 2000 late 2017, early 2018. And we had the source had a relationship with a company in California called score stream score stream is an app that allows people and fans that are at high school sports games to update those scores live and in real time. And there's a data set that exists with this. And it's a data set that a person like myself or our company can could license. And so we began thinking about what kind of a project could we work on together with no intention of this becoming a company or a service that anyone would want. But what is a project that we could work on together where we could learn more about natural language Think about it in the form of something practical that would be usable in a local newsroom, and just kind of dive in right and start experimenting on something that no one was really thinking about. So what we decided that we would try to do was, we would partner, the three of us score stream myself, the source and teammate AI, and Evans team. And we would, we would partner together to see if we could do this thing. We asked ourselves, what if we could cover every high school sports game in the state of Ohio, accurately, automatically, and while our editors were sleeping? Could we do that, and that was the goal that we set for ourselves to try to figure out if we could pull that together. And we started work on it in May of 2018. And we published our first stories on the kickoff of high school football season in Ohio in August of 2018. So we did about 90 days worth of really hardcore development, to try to get it to a prototype and published in May of 2018. And it was truly something where we were just experimenting, we wanted to see if we could do it. It worked kind of, you know, the language wasn't what we wanted, the there were things about it, that we wanted to be different than better. But we covered like 500 games that night, across the state of Ohio, and we delivered results. And then we were stunned to realize people were reading them. And so we we just said, Okay, well, we have this prototype here. So and then we just took off, and we started to iterate on it, work on it. And we tested it for the entire year. For that school year. We just, we just worked on it and tested it and tested it and tested it and tested it until I think April or May the end of the school year of 2019. That's when we made it public that we had this thing. And if someone else would like to use it, we would sell them that service. So we it was over the course of that testing that we thought maybe we have a product to the lot that

Nikita Roy  7:07  
people would want. So this is all based on natural language generation. So just for our listeners, can you take us behind the tech of it? And like really how that's different from all the generative AI buzz that's going about right now?

Jay Allred  7:19  
Yeah, for sure. So lead AI is natural language generation, but it is not generative. The best quote on generative AI I ever heard thus far was a guest on the Gary, I'm sorry, that Ezra Klein podcast where he said that chat GPT is very confident and often wrong. And I thought to myself, can I think of a worse job description for a journalist then very confident and often wrong? And I mean, is there anyone like could there possibly be the worst description. And for that reason, we do not use generative in lead AI, what we're looking at is very reliable, structured data, that can be sorted and grouped by geography or sport, or any number of other variables. And then that data gets analyzed and poured into human written templates that are based on that are chosen based on the analysis of how that game went. And so we're then wrapping language around reliable data and creating an output that's accurate and reliable, and is journalistically sound. And it's it's AP style. And so it meets the needs of that very particular customer, which is a local newsroom, but it doesn't include generative, we're testing generative, we're looking really hard at it for areas where it might have a benefit to newsrooms and how that could be used. But we have not, we still do not have the confidence in it yet that we could deploy it at scale, and feel like we weren't going to be able to take care of our customers in that way. Because you just can't be wrong, you know, the worst thing you can do is be is to have hallucinations at scale, which is the danger right now with with GPT, four and GPT. Three, we think that there's a future there, but we just don't think the future is now for this particular application.

Nikita Roy  9:15  
And so if you could walk me through right now, how are these stories currently being generated? Is there any human input that goes into it? Or are they all like automatically published,

Jay Allred  9:25  
it's the choice of the client or the newsroom that is working with us on this, the vast majority of our clients are on what we would call full automation, meaning that stories are published automatically. And they go on the website automatically. And it happens every night, you know, shortly after the games are reliably over for a particular geography that they're covering. But there has been a human in the loop on it all the way through to the point of those stories publishing and what I mean by that is our entire bank of story variables or the To the different ways that you could write about a blowout, or a close game or a tie. All of those have been written by AP award winning sports writers and editors, then they've been edited. And then they've been run through a second editing group that's looking at them for cultural relevance is this language that is relevant to the folks that are going to be reading it? Is there anything here that we don't like, or that could be better, we're looking at every period, every space, every semi colon, every adjective, every verb. And so by the time that a story publishes on a website, for a local newsroom, it's been through dozens of human looks. So we're very confident at that point that there's no reason why you would not publish it, because the variables are team names, location scores, but the way that the story is written is is as good as we know how to make it right now, given the data that we're working with.

Nikita Roy  10:58  
And I'd really love to hear more about you building that product in the initial stages of doing that. First of all, how did you specify or like, get into sports specifically? And are you looking at like other areas to kind of broaden the coverage right now? And really, what challenges were you facing? Well, developing it for the first time as a newsroom?

Jay Allred  11:18  
That's a great question. The thing about this is that I would love to tell you that we had had done dozens of user interviews and had gone through venture design thinking and had done proto, we had not done any of those things. We did nothing of those things. What we thought was, we had this hypothesis that we knew that we knew that small local audiences cared a lot about high school sports, particularly in the region that we were in. Because we were, we were solving a problem for ourselves, we knew that there were far more high school sporting events than we could possibly even begin to cover with people. And we had a very reliable, consistent scaled dataset, in score stream. And it's nationwide, it has reliable data from coast to coast, there was good penetration, we were able to license that data and their founder was a great partner in helping us build the product and partnering with us to help build the product. And it fit a need that we had, and our audience had, which was, who won. We just wanted to answer the question who won? And they you know, in in the general sense, how did they win? Did they come from behind? Was it a blowout? Was there a tie? Did they change the you know, did the game go up and down. And that was it, the goals were very simple. And we just knew there were certain things that we knew about local news and high school sports. For example, we knew that 40% of High School Sports subscriptions generally across the 40% of news subscriptions, when measured by large companies and and local newsrooms, if you're covering, if you're covering high school sports, about 40% of your subscriptions come through that funnel. That's a big number. We knew that advertisers like to be next to High School Sports, we knew that it was a specialized form of coverage, kind of like business reporting is or health reporting is, and not every local newsroom has that specialized reporting, ability to even cover results. And we also knew that local newsrooms across the country had been decimated by staff cuts. And we knew that they couldn't cover the sports that they used to cover and the depth that they could. And so we looked at it like, well, if we can do the rudimentary part, tell people who won. It will open up space for high school sports reporters to interview athletes talk to coaches write profiles, and do the kinds of things that help them drive subscriptions and drive ad revenue. So, you know, we didn't really think about covering crime or, you know, the number, the most dangerous intersections or we didn't look at any other datasets at that time, because it just felt like this was a problem. We knew that we could try to solve in 2018. Having never done anything like this before. So it's just like, I mean, if you can imagine a group of enthusiastic amateurs who had no idea what we were doing, and learned as we went, that's us. That's what we were. We just had so we picked the things that we thought that we could work on.

Nikita Roy  14:33  
And so when you start it off, not having done this ever before, what was this learning lesson that he took away from that entire experience building an AI product for your newsroom?

Jay Allred  14:44  
I think the thing that we learned was you have to rely on people's unique abilities, and let them do the thing that they're good at and trust that they're going to do the best job that they can. Evan was learning to code Python and learning to to write the code around this as he was going. So this became his experiment and how to write reliable code that plugged into an API that generated an asset and wrote a headline and SEO tagged it and, you know, did the things that needed to do to make it useful, but we had to sort of go okay, well, we're gonna let Evan and teammate AI work on that. Our Managing Editor, Larry Phillips, who is an AP award winning sports writer, and his team wrote all of the content. And we learned that when you're writing, what turned out to be hundreds of variations on the way that games go, people have opinions about language, as they might like, they have opinions about writing style they have opinions about and we had to constantly be checking in with readers or test groups to figure out what's the right, should we be writing this really straight up? Does it need to have a little bit of flair? How does it need to sound in order for it to be to be palatable to a reader, we didn't want it to sound like a robot. But we learned that we kind of over indexed on making it sound, it almost sounded to human like, there's a little too much poetry in there, we needed to back it up. And then on my part, where I did a lot of the things around customer acquisition, as we started to productize it, we just made so many mistakes, you know, we priced it wrong. We thought about pricing it, we thought about the way that people would use it incorrectly, we made assumptions that we shouldn't have made. And so we had to all like there were a lot of times where we would try something and then we had to start over and try again. But it was it was okay. Because we sort of knew that we were doing this at a time when no one was really thinking about it. I mean, this was 2019 Chat GPT was not a thing at the time. And so we just adopted a real experimental mentality with it, you know, as a kind of a very humble, experimental mentality. And we knew that we were going to screw a bunch of stuff up, but we were going to try to keep try to keep making it better as we moved along. And to try to keep learning as we went along. And we had a lot of great partners early on that tried the product or tested the product and gave us feedback on it and they were really instrumental to it.

Nikita Roy  17:13  
I want to shift focus a bit on to the whole generative AI buzz and source media. Specifically, can you talk us through the social media properties and like how many newsrooms and what you cover? are you approaching generative AI in your newsroom now.

Jay Allred  17:29  
So source media properties is just basically a an umbrella for what we're we're more well known for our flagship property Richland source, which is about a decade old. We're a pure play digital, local news site that has done some innovative and interesting things here in the middle of Ohio. And along with Richland source, we have two other sites that cover neighboring counties, Ashland source.com, and Knox pages.com. They're all part of a family, we cover three of Ohio's 88 counties and about a quarter of a million people in total. And obviously, we've been using natural language AI here at the source since 2019. But with generative, when that hit when chat GPT was launched, I think in November of last year, it altered the whole landscape of the way that our industry thinks about it, how much it gets talked about. And so what we're doing here, and the way that we're thinking about AI is we tried to very early on, pull together a team, a small team of people that were interested in the technology here at the source, and we're just adopting a very test learn and report methodology around this for so this is a team of about a half a dozen people. They come from all different sides of the business. And they meet relatively frequently there's a Slack channel that we communicate in. And what we're doing with this is we agreed together that from the group came to this agreement together, I didn't want this to be a top down thing that came from me, the group agreed that the best way to do this was we would use it to try to solve a problem and then report back on the results. So for example, our graphic artist may her hypothesis or her question she might ask is I use Dali to try to help me generate representative proofs for clients. And I got this results from it. And we're trying to ask good questions and think about problems that we can solve with it. And then key to this is to report out those results to the rest of the team so that we build some momentum around both usage of the tools as they develop but also monitoring and some healthy skepticism. Like do they work? Is it solving a problem for me? This is where our experience with lead AI I think has been helpful because this is not new to us. We've been comfortable with natural language generation. So when when generative came out, I'm comfortable with those testing methodologies with it. And I think that our team generally is to we've adopted those. And we're using it now. In editorial I've seen it used to help rewrite a lead to make a lead more interesting or to to give me three variations on this lead. I've seen editors haven't helped them work up a headline, if they're stuck on something. Our marketing department is using it extensively to write variations of social copies. So when we're writing social posts for Facebook, or we're helping a client with web copy, it's very useful there. We've used it to help write press releases for employee promotions, or when we're helping a small business communicate something to its clients through our branding studio, it helps solve the problem of the blank page. But we're just experimenting and reporting back. That's the method that we're using. And it seems to work.

Nikita Roy  21:03  
And how big is your newsroom size right now? And like How is everyone using these chat TPT and these generative AI tools,

Jay Allred  21:11  
so our company has around 20 full time employees overall, right? That flexes and varies a little bit, about 50% of our company is on the news side. So the reporting side of the business and then the other 50%, roughly, is works on our business team. When we thought about implementing generative, one of the things I absolutely did not want to do was force people to use it that we're not comfortable. People exist on a spectrum of comfort with this kind of technology. And it was really important to me and to everybody on the team that we were not making people do something that they weren't comfortable with or weren't curious about, which is why we we formed this small team. These are all folks that are early adopter type personalities, they're all interested in the tech, and they're all willing to experiment with it. And they've all committed to reporting back to their colleagues about hey, I was worried about this, I tried to solve this problem, I got these results. And I either think the results are really good. And I want to show you how to do it. Or I wasn't happy with the results. And my recommendation is that we either keep working on it, or we abandon it for now, because I don't think the tech is reliable in this context. So no, not everyone in the newsroom is using it. We've got some skeptics in the newsroom around it, actually. And that's okay. Like they're absolutely part of the adoption process and the inquiry process. We need those folks in our life to make sure that we're not accepting the technology too quickly.

Nikita Roy  22:41  
And talking about guardrails. So the people who are using it in your newsroom, how are you communicating the risks of generative AI to them? And kind of like what guidelines have you set in place for your newsroom?

Jay Allred  22:53  
So this is a very developing thing for us. We have not settled on hard and fast guidelines yet. We know that places like the Associated Press and the society professional journalism, we know that these organizations are working on this. The partnership for AI is working on this. I'm full disclosure, I'm on one of their steering committees, but we're working on these kinds of things. So what we're doing to answer your question is, first and foremost, when we use AI of any kind, including LEED AI for sports scores, we're transparent with our audience about it. So if we generate representative art, we're going to tell our audience that this was generated with a tool called Dolly, etc, etc, etc. If we use generative or other AI tools to write something that we're reporting out, or to help us research where we're indexing on transparency rather than the opposite. I think first and foremost, that's what we're doing. When we think about the guardrails for usage inside of the newsroom. What we're doing is less about guardrails right now and more about communicating with one another. We're asking each other questions where we're talking through it as a team, the small cross functional team is, is thinking about these sorts of applications and paying attention to both the concerns that they have and the ways that they think that they're finding around those concerns or through those concerns into A into an acceptable place. There are big questions to ask about this, though, right? For example, AI transcription tools have been around for at least a half a dozen years, and folks use them all the time. We never disclose that we used an AI transcription tool to take a recording and turn it into a transcript. We simply go through the process of verifying that the quote that the transcription tool wrote out is actually what the person said. We don't tell our audience that we did that. We just do that because it's the right thing to do. And so I think this we're in this moment, local newsrooms are in this moment where they're really thinking about deployment, and how AI is going to be deployed. And I think that is the central question that the whole industry has to answer for right now. I think that is the thing that I think that I worry the most about. It's the thing I think about the most as a participant in industry, it's the thing that we work on the hardest with lead AI is to really be thinking about how is this tool going to be deployed? And how can it make the lives of local newsrooms better, and enhance their ability to reach audiences that they want? And I think that it's just it's really the thing that we have to think about the most.

Nikita Roy  25:50  
And the skeptics in your newsroom, I mean, it's really important to give that applies as well to understand hear their perspectives. And so I want to know more about what questions and concerns are they really raising about these tools? And how are you addressing that?

Jay Allred  26:05  
I think some of the we have seen through the experimentation that chat GPT and other general tools just make stuff up sometimes. And so they have very real, I think all of us have very real concerns about okay, well, how much of this data can we actually trust? And is it? We've had folks who've asked, Is it even worth using this tool? If I have to check everything that it says is correct? Like I have to if I've got a fact check the whole thing? Like what's the point? And I think it's a very real, it's a very real criticism, right? We've had concerns about for generative imagery. When you think about building representational imagery, you have to ask yourself sort of the question of saying, well, would I have paid a human artist to make this piece of representational art that I'm going to use in this enterprise story? Or would I have used terrible stock art. And what we're looking to try to thread the needle with is that if we would have paid a human to do it otherwise, that we would continue to pay a human to do it. But if the choice was between terrible stock art, and pretty good, Representative are built by Dolly, we're leaning toward Well, let's go with pretty good representative art anyway, because no human artists last here. But those questions come up, because we have we actually have, we have a graphic artist on staff full time. And she notably has, has raised questions about, well, this is not that good. I could do this better. And she's right. And so the the idea here is, again, you go back to that question of deployment, right? And the ethics that you bring to the deployment of the tool, is it helping this artists produce very fast, let's say client focus proofs to show a client four different ways that the art could be represented? And the client picks one, and then the artists produces the actual content? Does it speed her work? And does it make it easier on the on the newsroom side? If you're writing a story about midwives, and you say, Okay, show me five variants of oil painting, five pregnant women in a room soft lighting talking to one another, and it shows you five different variants of that, can you get to the one that you want the most? And then can your artists make the final version of that, but it's about the ethics of the deployment. And I think that we're working really hard to try to navigate that in a way that, at the end of the day, lifts the newsroom up, and creates more resources so that they can do better, more impactful work. That's what we're all about. And that's the way that we're trying to deploy it and manage through those very real, though very thorny questions that you have to manage your way through.

Nikita Roy  29:04  
And another thorny question that's really circulating is about the privacy risk with all of these AI models. And so how are you looking about how concerned are you about the privacy aspects when using all of these tools?

Jay Allred  29:17  
Okay, I think there's two contexts for this, at least in our business, on the creative end, when we're working with clients on the marketing side, not very much, because we're sort of building things out of thin air, you know, write me social copy for this, you know, hamburger stand to help them sell more hamburgers. This is generative is really good at that. It's very helpful. I think in the newsroom context, things get a lot more different, a lot different and a lot more consequential and the stakes are higher. I think they, in our case, I think we're not pouring in a lot of personal information into generative models, even when we're looking for help on writing headlines or whatever. And we're balancing that With a very real with the stark reality that most of us have given up astonishing amounts of privacy in exchange for miraculous improvements in convenience. And we're doing it right now, as we record this podcast, I am, I am on an application on the internet, and I am talking into a microphone which you are recording. And I don't know where this recording goes at the end of the day. So I think it's it's this balance point between between being realistic about how much privacy that we give up in order to gain convenience, but also being super vigilant about things that, you know, we don't do a lot of confidential sourcing, or blockbuster investigations. But if I'm an investigative reporter at The New York Times, this is a big deal. For me, this is a huge question. If I work for Politico, or if I work for, you know, an investigative team. This is a big deal. And it's not a thing that we're thinking about a ton. But it's a thing that I'm sure journalists are absolutely and should be thinking about.

Nikita Roy  31:08  
This has been such a fascinating conversation. And I kind of want to bring things together and see like back in 2018, you stepped into this world of AI and now with the AI all coming into it, there's a lot of promise, really, for local newsrooms, and you've been part of that journey for local media in the country. And I want to get your insights into where do you see really the future of local journalism? For newsrooms like yourself covering like rural areas in Ohio? How are we going to be evolving now with the US and with the opportunities that generative AI is bringing along?

Jay Allred  31:42  
So I think that I'll answer that question as simply as I can. I think that the potential upsides far outweigh the potential downsides, if the way that this tool is deployed, is with great intentionality around creating a tool for a newsroom to be able to do more than it could before and to create a tool that a newsroom is able to provide more value to its audience that than it could before. This is where I when I said the real question is about deployment. This is what I mean, I think we're at this nexus or at this crossroads, where the industry now has access to an incredibly powerful tool, that it has choices about what it's going to do with that tool. And if you go back to 2008, and 2009, when the social media platforms were ascendant, and the news industry decided that they would just give away all of their content to the social media platforms as these third party intermediaries, and they would benefit from all of the traffic that would come from those third parties. I think AI represents an opportunity for us to get closer to our users to claw back market share and value that we have given away over the last decade, decade and a half. Because the industry at large has had to cut so many people in order to try to turn itself into a digital industry. And in doing so it's given away obituaries, marriage announcements, the kinds of information that is not journalism. But that is important to a community. I think AI has the opportunity to put a lot of that information back in a news organization, in the pages of a newspaper, or, more realistically in the pages of an online news organization like ourselves. And if it's deployed in that way, the future is really hopeful. And that's what I think that's where we have the most opportunities, we just have to think about now is the time for us to not rush blindly into generative AI, you know, just sort of rushing into the embrace of Sam Altman and the good people at open AI, I think we need to be really thoughtful about the way that we want to deploy this technology. Because if we're not, and we don't control our own future, our future will be decided by other people for us. And I think we're at a Nexus right now, when we get we have a lot of influence over the way the tool is going to be used. And I think that the upsides are higher, for sure. But my optimism and my hope is not without a generous, generous leavening, right. I mean, where's there? Definitely, you know, it's not it's not blind hope and optimism, for sure. I think it's good. But we really have to be concerned about deployment, and think a lot a lot about it, and act ethically and accordingly.

Nikita Roy  34:42  
There's a lot of big questions to be asking, but it's really exciting that the future that could be possible for local newsrooms and bringing back information that had to be cut for people. So that's a really exciting feature. You're painting for us by local news and the future of journalism that we could be all part of the agenda of AI. So yeah, thank you so much for being on newsroom robots. Jay, this has been really exciting. I love talking local news. And the work that you're doing has been really great to hear all about.

Jay Allred  35:14  
Well, thanks, Nikita, I am just really honored to have been asked to come on and to this has been a great conversation for me too. And I have enjoyed the show. And thank you very much for doing this because these conversations need to be had and now that they're being had in public, that means more people can have access to them. And they can find the folks that are on the podcasts and reach out to talk to them more if they want to, which is great.

Nikita Roy  35:37  
Yeah. Thanks, Jack. Thank you so much for being here. That was Jay alread, the CEO of social media properties, and the co founder of lead AI. If you like what you hear on the podcast, subscribe rate and review the show on Apple, Spotify or wherever you get your podcast. This episode is made possible thanks to the Harvard innovation labs spa grant. And Nikita Roy and this is newsroom robots.

"
newsroom_robots,9,"Wed, 07 Jun 2023 23:14:44 GMT",David Cohn: Copyright Challenges & Audience Engagement in AI-Era Newsrooms,https://www.newsroomrobots.com/episodes/david-cohn-u_BZxohz,"<p>David Cohn, the co-founder of Subtext joins host Nikita Roy in this episode to discuss the recent doomsday buzz surrounding AI, copyright challenges and how generative AI can change the way news publishers interact with their audiences. </p><p>Over the past two decades David has worked at the intersection of technology and journalism, with a focus on new products, business models, audience growth, customer experience and incubating new companies. He helped pioneer crowdfunding at Spot.Us, explored mobile first news at Circa and led the charge into social video at AJ+. Today he is a co-founder of Subtext, a platform that lets news organizations, reporters and content creators text with their audience to increase audience engagement, develop new revenue or increase subscriber retention.</p><p>Tune in to hear David’s perspective on the potential of AI to reshape the relationship between news publishers and their audience.  </p><p>Thoughts or questions? You can reach us <a href=""https://forms.gle/egyJZDsGjogiyNTH8"">here</a>.</p><br /><hr /><p style=""color: grey; font-size: 0.75em;""> Hosted on Acast. See <a href=""https://acast.com/privacy"" rel=""noopener noreferrer"" style=""color: grey;"" target=""_blank"">acast.com/privacy</a> for more information.</p>","Nikita Roy  0:02  
This is newsroom robots, the Podcast where we explore the intersection of artificial intelligence and the news industry. I'm Nikita Roy, a data scientist, media entrepreneur, and one of the many founders currently building their ventures at the Harvard innovation labs. On the newsroom robots. I'm excited to bring you insightful conversations with industry experts about how AI is impacting the way we do journalism. My guest today is David cone. He's the co founder of subtext, a platform that lets news organizations, reporters and content creators text with their audience to increase audience engagement. Over the past two decades, David has worked at the intersection of technology and journalism with a focus on new products, business models, audience growth, customer experience, and incubating new companies. In today's episode, we touch upon the recent buzz surrounding AI and focus on the opportunities that generative AI presents for audience engagement.

Hi, David, welcome to use your robots. I'm really excited to have you on the show today.

David Cohn  1:12  
Happy to be here. Thank you for having me.

Nikita Roy  1:14  
So I really had a lot of fun last week on This Week, additional media and subtext and I really got to interact a lot because of the whole doomsday buzz that was going about, and it was pretty timely to hear a lot from others in the news industry, and talk to them about what they were thinking. So that is something that I want to really delve into straightaway for today's episode. Because last week, all of the big tech folks and open AI, Google DeepMind, Microsoft, you've had Bill Gates, Geoffrey Hinton, everyone's saying that warning that advanced AI systems can really be as dangerous as like pandemics and nuclear weapons and really pose a risk of extension to humanity. And I want to just hear your thoughts. Really, how much of a risk? Do you see it? As do we should we be afraid of AI? regulate it or really just embrace it?

David Cohn  2:07  
Right. So I mean, that is a big question. And one of the things that's interesting about right now is I feel like I can often argue both sides of of any question, because it's just so murky, I would say, you know, my first thought or inclination is that, you know, whenever there's new technology, there's a lot of, you know, over concern, right? I mean, that's sort of like the classic story of technology. Right? When when they invented writing, I think it's the famous saying is that there was a Greek philosopher who thought people were going to lose their memory, and, you know, so on and so forth. And is this just a bunch of doomsday ism? I mean, to that argument, I would say this, like, most generative AI still requires a push from a human right? I don't think that that it's sentient in a kind of, you know, Terminator two sense, right, it's still requires a push from a human to give it direction. That said, once it's given direction, there's this concern of momentum, right? Like, maybe you pushed it in a dangerous direction, and it snowballs out from there. And a great example, this is I think it was Google Bard, was asked a question in, I want to say, a Pakistani language, which it had never been programmed, and it didn't know that language, but because its job was to answer the question it when it learned the language, and then it responded back in that language, which blew the developers of Bard away right there like because that's an emergent property, right? It learned a new language that it was not programmed in. And it taught itself, essentially. And it was still doing its job was just in the service of of answering a question, which is all we're supposed to do. And it had given that initial push, it's just that it was pushed in a direction. Nobody had ever anticipated just learning a new language. So again, do we have like a super intelligent AI that you know, is out of our control? No. But it feels like maybe we're playing with a petri dish, and like, we're starting to see signs of life. And at a certain point, maybe that does get out of control. You can definitely go sci fi with it real quick. I actually think the existential concern for me is more along who we are as humans, and what we think of ourselves in some respects. All right, and again, we can go into that direction. But I'll pause there.

Nikita Roy  4:17  
Getting into that more, I feel like the risk is already kind of imminent in the sense of like, mediocre AI that we've been playing around with really, all of the misinformation that has been coming out and the threats to humanity just with how it could impact people's opinions. So like the advanced AI systems that people are talking about, that seems too far off. I mean, we are already there with the risks. And so how do you kind of see where we are at this time of moment?

David Cohn  4:43  
Yeah, I mean, the misinformation is probably the most immediate risk, right? I mean, if you thought misinformation and disinformation was bad, and you know, 2016, like buckle up, right? Because it's not just that there will be more of it, which I think there will be and it's not just that it'll be more convincing, which I think it will be. But I think it's going to hit at an emotional level that we are not prepared for. Right? The example I often use is VR, because in VR for a long time people have recognized that it can like actually change kind of how you think, right? If it's used to treat PTSD, right word to treat phobias, it is there have been studies in Stanford where like, in a VR experience, you would chop down a tree, and people actually used I think it was like 20, or 30%, less paper afterwards. And you can imagine a more extreme example, like you had to virtually slaughter an animal maybe become a vegetarian. And that's because VR kind of hits at an emotional level that other media doesn't. And I've never been too concerned about that. Because you know, that hasn't hit mainstream, although maybe it will, with with Apple and the melding of VR and AI is, is interesting as well. But so you can imagine, again, a VR experience where you can say, with statistical significance, like people who go through this are 20% more likely to vote one way or the other. And that becomes really scary that you can just create that experience. And AI, while not quite as emotional as VR is still more emotional than most media because it can be personalized, right? The extreme example of this is, and this is not far fetched getting a phone call, it's in the voice of your mother, and she's telling you X, Y or Z, right? Obviously, you could eventually call back your mom and confirm like, Was that really you telling me to vote for Proposition B, or whatever it might be? But that's the level of emotion that they can get to is like, in the voice and in the language of someone who you know and love? Right? I mean, it'll be personalized in that way. And from a media literacy perspective, I don't think the average person is prepared to combat that.

Nikita Roy  6:36  
Yeah. And how do you see really like newsrooms playing a role in that? Because how do we get our information into the hands of people when we are competing with everybody else is AI generated content?

David Cohn  6:47  
Yeah, I mean, there's a very positive outlook, where in an environment where everybody starts to recognize just how drenched in information, you know, we become that there is a resurgence of desire for trusted sources, in which case, news organizations can still drop the ball on that, but could reclaim the mantle of like, we are trustworthy. And while we are using generative AI to help us be more efficient, more productive, and all these things, we're not using it to emotionally manipulate you. Right. And so so that's one potential outcome. I mean, who knows all the different directions that this could go, but that's a very hopeful outlook.

Nikita Roy  7:25  
Yeah. And with newsrooms currently, like the banner for a survey that just came out as well, last week, talking about that half of the newsrooms surveyed use generative AI, I think we're moving into a space where newsrooms are also using it. But there's also a lot of hesitancy in some of newsrooms that are not using it. And one of the questions is always will they be left behind? What do you think about people who are using generative AI versus not? How would that really impact the way they would be reaching your audience in the future?

David Cohn  7:55  
I mean, for me, right now, I think everybody should be using generative AI, but thinking carefully about what it can be best used for. Right? So for example, I'm really concerned about people using generative AI just to create an article out of you know, scratch, essentially or, you know, because, you know, and again, this is maybe a media literacy moment, but like, it's very different than looking something up and getting a fact, right. I mean, it's statistically predicting a fact, which, you know, can get really fuzzy really quickly, right. I think there was a story that came out last week, you probably saw it about a lawyer who argued was made an argument for a federal case, completely made from Chatrapati. And it cited, you know, legal cases, all those legal cases were made up, they probably sounded like legit legal cases, like he was citing legit legal precedent, but he was just fabricated. And so you could imagine, you know, just as that lawyer is now in hot water, a journalist would be in hot water for the same thing that said, generator, the AI is amazing at spurring creativity, for example, right? And it can do everything from like, it'll help me come up with five versions of headlines for this to you know, I think it can be used on the back end of like, Hey, here's the transcript of the conversation I just had, can you give me a summary, but you were part of it. So you'll recognize, you know, maybe what was hallucinated and whether or not it was a good summary. And I do think it will make people more productive, and will make newsrooms more productive in the best sense of the word. And so you kind of have to play with it, I think you you very well could be left behind at a certain point, just because you won't be able to compete at a certain point if you're not, but I also think you have to be careful and smart about how you use it.

Nikita Roy  9:34  
The biggest conversation that was happening with people on the subtext group last week was people were concerned about the risk of tech developing so fast with AI and publish shows on publishers content, and then publishers kind of being getting the shorter end of the deal over there. You're part of the media tech industry as well. So like, how do you see newsrooms kind of getting onto that bandwagon and still being able to protect their interests but still being able to to adopt AI?

David Cohn  10:01  
Yeah, that's a huge question. Because I mean, I think for the last 10 to 20 years, maybe 15 news organizations have felt like they've gotten the short end of the stick whenever they've started to engage with technology platforms, right? I mean, it's, it's been a Faustian bargain at best with like, Facebook and other social platforms. And so the concern is, is like, are we just jumping in, you know, what is it out of the fire and into the flames or something like that. I mean, it just, it feels like, we know this story. One. And again, this is not the case right now. But I can imagine this being a moment is just like, you can actually opt out of being searched by Google, for example, there's like a, you know, do not search script that you can put on your site. And of course, no publisher uses that because you want to be found by Google, because that's a great way to get traffic. But I can also imagine, perhaps, you know, you talked about regulation. And again, this is not the case right now. But I can imagine a scenario where people demand that there is a kind of script that allows your data to not be ingested by large language models, that you will not participate in large language models and the data becomes proprietary. And in that world, again, I think news organizations will think critically about whether or not they want to participate in this or not what they get out of it, in which case, then the platforms will have to really offer something, I think anything they offer will have to really come to the table and look at in the eyes directly look that gift horse multiple times over. But that is the kind of thing that I think I'm looking for in terms of leverage of being able to say like, look, I can include a script, you're not allowed to use any of my data. Why should I remove that script? Right, that changes the conversation? Again, that's not something that that exists to my knowledge right now. But I can imagine that being in that regulatory space, something that comes up.

Nikita Roy  11:45  
Yeah, and with the whole concern of places like MIT journey, and stability, and all of those image generation tools, using photos and images, how do you see kind of the copyright issue evolving? And what role would newsrooms have to be playing in adopting all of these specifically, like image generation tools?

David Cohn  12:06  
Yeah, I mean, an image generation is really weird when it comes to like copyright and legal stuff, the rubber hits the road. And I'll be honest, it's it is going to be something that would require greater minds than mine. Because it's difficult to figure out exactly like, what percentage to use a term of influence. If a an AI image is created, and it resembles, you know, something that another artists produced by hand, what percentage of influence was there? At what point? Does it look too much like it so that they can, you know, claim copyright or complain? I don't think anybody knows the answer to that right now. But I can imagine that that is something that eventually gets worked out through the courts. I mean, just to flip it, again, this is I mentioned this earlier, before we started recording. It's almost the flip side of chat GBT, like mid journey and image creation and the concerns, because I think with chat up, nobody's concerned about copyright. They're concerned about like whether or not this is a fact, like whether or not what I'm getting is true. And what the images, we know that it's not true. It's not a true image. But the concern is around copyright. So it's almost as like, if you let go of the idea of it being a fact, right, this image is a creation, we know that. But now it's who owns that creation, versus the text that's created from chat GPT no one really cares about who owns the text, or what percentage of it was influenced by certain writers. But it's immediately like, well, is this actually trustworthy? Can I believe this or not? I think that's maybe a result of the mediums themselves, like text versus image. But it's funny that those two are sort of inversely related.

Nikita Roy  13:40  
With Japan, getting into the AI train jumping into it completely and saying that, that they have announced that they will not be enforcing copyright on like the data used for AI training. Is that setting an example and precedent for like, what the other countries are going to be doing? And how do we look at that, especially as the news industry? How concerned should we be about that?

David Cohn  13:59  
It's certainly like, if you look at this from like, a game theory perspective, you know, Japan, by saying, you know, we're not going to pursue copyright issues here. It means either you like other countries will join them, or lose out to business, right? Because people will just start putting their operations in Japan and being like, well, I, you know, there's no copyright issues in Japan. So I'm gonna keep doing it. So again, from a game theory perspective, it kind of forces the hand of other countries, right to kind of find that lowest common denominator, that's, again, just me guessing here, that that's, you know, kind of a gauntlet on the throne that, you know, if countries want that business, they're going to have to be friendly in the same way. So I could see other countries following in which case, you know, it becomes fair game and just like, you know, every corporation is registered in Delaware, every image, AI image company will be based in Japan,

Nikita Roy  14:51  
then what's the real risk over there for publishers because, once again, we are the people who creating all of bringing all the photo journalists and creating these photos Capturing these live moments now, if something is just AI generated and built upon that, what's going to happen to the real authentic content that's being produced over there?

David Cohn  15:10  
Yeah, I mean, again, I think, and this is just my beliefs, right? No one knows anything for sure. Here. I think things like photojournalism are relatively safe. Because again, the the value of photojournalism is not just that it's something to look at, it's that it captured an actual thing that happened. So for AI images to sort of eat that space, it would have to be under the guise of misinformation. Disinformation, you can't claim that this is a photograph that of something that actually happened unless it really is a photograph, you're either tricking me or it really happened. And if you're tricking me, then kudos to you if you get away with it, I guess. But like your again, if you Value Trust, that's going to disappear pretty quickly. So again, I think photojournalism is protected in that sense. And then on the other side, image creation of like abstract ideas, right, like an image that might go with an op ed piece or, you know, a commentary, right? It's a picture of flowers wilting to represent the end of spring, that's actually where this issue around images are going to be created. But that's less for photo journalists, and more for what I'd call like art artists, which could include photographers, but less photojournalism, if that distinction makes sense.

Nikita Roy  16:19  
And I was looking at this report that had come out by an outplacement firm that called challenger gray and Christmas that said that AI contributed to nearly 5% of all the jobs lost and the United States out of a word total of 80,000 layoff announcements in the US just last month. And that really got me thinking in terms of a lot of people and a lot of art outlets, covering stories of how copywriters are being replaced. And AI is coming over coming to take over all of those white collar jobs really, that we would think that we're automation proof. How do you see AI really impacting the job market and the news industry, when you said photojournalist seem to be kind of safe from Ai? What other jobs in the news industry are really addressed over there?

David Cohn  17:05  
So I mean, again, this is one of those things where I could try and argue both sides. And I want to give like maybe the positive side, because I think the negative side is really obvious, right? Not not really obvious. But like, there are a lot of potential jobs, like you said, like copywriter, you know, there are a lot of types of stories that maybe can be automated more, right? I mean, and that's not new, right? I mean, I think the AP has been using machines to produce I think, like earnings reports, and maybe some sports game stories for a while now. But you can imagine this now, expanding out on the positive side, here's a scenario that I hope plays out to some degree. And I use the analogy of the ATM. When the ATM first came out, a lot of bank tellers were concerned that they were going to lose their jobs, and they're going to be replaced. And that did happen to some extent. But what also happened is that the cost of opening up, new banks went down. And so more new bank branches opened up. And even though they required less bank tellers per branch, overall, the number of bank teller jobs went up, right. And right now, I think, you know, what we would imagine a skeleton crew of maybe two or three could actually cover an area that's currently a news desert. And they might be able to do it in a financially sustainable way, because they could do more with the power of AI. Now at certain newsrooms, where there's, you know, New York Times or Washington Post or CNN, where there's like, oh, concentration of employees, perhaps it goes down there, because they need less people. But my hopeful scenario is that those jobs will actually there'll be more of them, and they will pop up in places that currently are uncovered. I mean, we've talked about news deserts, a long time in journalism. And the reason why those news deserts exist is because the market is not big enough to support a real news operation. But what if a real news operation actually becomes easier or requires less people? Then you can cover those? I mean, again, this is maybe too rosy of a picture that I'm painting. But but that would be a scenario that I can imagine happening and would be great for journalism.

Nikita Roy  19:06  
Yeah. I mean, it's it's a rosy scenario, but possibly real as well, because the AI market is now apparently $1.3 trillion. And so that also means it's a huge employment generator that's coming about and so maybe we're going to be seeing roles really evolve within the news industry and new job opportunities come up that way.

David Cohn  19:25  
Yeah, for sure. I mean, just as like, in the 2010s, social media editor, became a wholly new job title that didn't exist before. I think there'll be wholly new job titles. I've been saying, you know, AI, prompt engineer, maybe it'll be something else. But I think that will be a role in a lot of newsrooms. And that will be the person who just like the social media editor, mediated the space between the news organization and social media. That person will be the person who helps mediate the space in between the production of content and the AI that helps them and again, in a very sci fi future I've seen you know, video Let's talk about AI and how there'll be like a one person company IPO in the year 2030, or something like that. And, you know, again, it sounds very silly to us now, but maybe that's the case, right? But I can also imagine, you know, a one or two person organization winning a Pulitzer Prize in the year 2030, for their coverage of Hayward, California, or, you know, somewhere that currently is maybe overlooked.

Nikita Roy  20:23  
Yeah, it really talking about social media, I've been likening this entire AI revolution that's happening to like the social media revolution and seeing how we change the way we deliver content and wrote for audience, how do you see us kind of engaging with audience now with generative AI coming into the mix? What's the future looking like over there?

David Cohn  20:43  
That's a really good question. And actually, that's one where I'm, I get maybe more excited, because, you know, within journalism, there's lots of different, you know, kind of niches and the trust in journalism, but like, I've worked a lot of my career in what I might call like, audience engagement of journalism, making journalism more transparent, more participatory. And, you know, that is a lot of work. And it's possible that, you know, now we can listen to the audience in a way that we couldn't before, right? I mean, a lot of audience engagement is about listening to the audience, understanding them, again, there are entire companies built around this subtext itself is, you know, partly the ability to, to engage the audience and listen to them. And if you can start to do that, at a scale with AI that, you know, wasn't possible before. I don't know exactly what we'll learn. But I do think that there will be products and discoveries in that space, for sure.

Nikita Roy  21:35  
And how are you looking at all of the chat bots that are coming about? I mean, skift, which was the b2b travel publisher just came out with an AI generated chat bot that looks at all of their archives, and you can ask good questions. And is that sort of like a future in which we'll be engaging with our newest content?

David Cohn  21:53  
Yes, I absolutely love that. And I can imagine more. I mean, before a church, it was even released, actually, when I was just playing with my journey, you know, I wrote and theorized like, yeah, there'll be just like, you could write out and get an image, you'd be able to write out and get an article. And I'd said, you know, you'll be able to say, hey, rewrite this in the style of the AP, or rewrite this and style of Hunter S. Thompson, or in the case of skift. And it makes a lot of sense, rewrite this in the voice of my brand, right? Like, once you've got enough, you can almost embody the voice in a model. And again, that's that is actually where when it comes to generative AI, around language, where maybe there is now copyright issues, right? Because skift is allowed to say, hey, we have a chatbot now that has all this gift information and can write in the voice of skift. Or let's take the New Yorker, right? A real real voice, your voice, right? Am I allowed to create an article in the voice of a New Yorker or a specific New Yorker writer? They probably wouldn't like that. But you know, they could do that themselves and own it, right? And then be able to say, like, Hey, you can talk with a New Yorker writer, maybe not a specific one. But like, you know, in the voice of the New Yorker, I think you can start to personify brands, essentially, in a way that only singing characters on commercials could do before, right? I mean, that's what those you know, the especially like in the 50s, and 60s, you know, the Jolly Green Giant, all those ads, were just personifying brands and giving them character. Now, you could actually have a living, not a living, but like a, a seemingly living, interactive character, based off of a brand. Again, from a misinformation perspective, it gets really scary. But from a brand perspective, it's actually really empowering.

Nikita Roy  23:31  
What opportunities do you news publishers have right now, with audience engagement in the context of generative AI? All these products are still in development. But what's something that they could try and test out right now? Yeah,

David Cohn  23:43  
I mean, again, it is still early. Like, I don't think we've seen anybody truly, like unleash what would become a standard. So there's actually a few buckets that I think people are playing in. One would be what I just mentioned, the idea of listening, and maybe like, think of it as like a revitalization of comments, right? Like commenting on news articles, kind of has been on the downslide for a lot of reasons. And maybe this can bring that up. Another one would be in the sort of audience engagement by by changing or giving a TLDR version or whatever of content already produced, like, Hey, I produced this article, give me all the ways that I could share it on Facebook, Twitter, Reddit, etc. And also give me a kind of like, short version summary of it that I could put at the top of the article to see if people are interested. Alright, so I'll call that mixing. Another one that deserves exploration would be tools on the production side, right? How can reporters or videographers or whomever use tools to do what they're doing already, but do it better and faster and more thorough, right? So those are like the three buckets that at least come to top of mine? There's probably a few other buckets that people are playing with? And again, we'll kind of see, I will say this. You mentioned, you've been thinking about how this compares to social media, the social media revolution that happened maybe a decade ago, there were are a lot of second order consequences to that, which we did not predict. And again, to the first question that you asked, there are a potential lot of second order consequences that we just cannot predict. And that that is scary. But I don't think you can, you know, the genie is not going back in the bottle, so to speak. So you just have to kind of go forward with it in a cautious sense, but I think most news organizations are also thinking about what's the other shoe to drop?

Nikita Roy  25:22  
Can you talk more about that in terms of like, what the second order consequences are with social media? And what are you thinking about it with AI?

David Cohn  25:28  
Sure. I mean, like, when social media first began, or, you know, like, there was a kind of utopian idea of it, right. And, and I would say it kind of hit its peak utopian vibe around Arab Spring, right? Like, everybody's like, Oh, my gosh, right. Like, everybody has a voice now. You know, totalitarian governments can't stop us. And, you know, isn't it amazing that we can all chat with each other? And I'm, you know, I've got personality and or personalities that I'm engaging with, and, and, you know, the early days of Twitter were amazing, right? Like, when Twitter first started, I'll use Twitter as again, as the sort of standard here for social media. It felt like serendipity had finally been harnessed in a really positive way. And of course, the eventually, maybe I forget, when Arab Spring was maybe 2011 2012, something like that. 2011 Yeah, 2011, you know, only a few years later, 2016 or 2017, I might put as the like, the second order consequences, people started being like, Wait, there are a ton of people on here that are not real or genuine. I myself find that I am engaging with this in a kind of performative way. I'm not being authentic myself. I can't trust everything that's on here. It seems like things kind of went off the rails. Right. And so yeah, I mean, again, there's second order consequences, I think there's almost a rule to the internet, that there's going to be second order consequences. The Internet itself was thought of as pure utopian. And now it's, you know, this oligarchy, right, there's like a handful of companies that control a significant way in which we engage with the Internet. And so I think it is safe to say that there will be second order consequences to AI, I wouldn't know what they are going to be. That's the nature of of them, right? It's sort of like, you can't necessarily see what they're going to be until the first consequence has landed. And I don't think we're there yet. Like, I don't think we have the first consequence landed. But you certainly like when Google launched, you could not have predicted Facebook, you just couldn't have. I mean, maybe you could have, but you wouldn't have known how it actually would have played out. And I think we're in that spot now, where it's like, we're just seeing the Google like the the first foot landing, but social, which came out of the era of search and blogging. I mean, I don't even know, especially again, we talked about it since Apple did just launch their their VR thing. I was actually just at the augmented world expo. And the big thing on everybody's lips was you know, the metaverse has maybe fallen flat VR, you know, like it's never hit a kind of genuine moment. But instead of the way I look at it is it's not the AI is going to be in VR. And the metaverse I think the metaverse in VR will be subsumed by AI, I think it's going to be an AI world. But when you combine that with a Metaverse, again, a more emotional experience, you know, you're gonna have a again, not only will skift have a chatbot, but it will have a logo, and it'll look cute, and it'll giggle at me. And, you know, tell me about the next trip I should take, right? Like, it becomes a very, you know, Ready Player One, what would formerly have been pure sci fi type worlds.

Nikita Roy  28:29  
Yeah, this has been a lot of like, future looking into the future episode today is and it's gonna be interesting to see how this all plays out. And like six months down the line in here, we're back on this episode on how everything, what the predictions would be and like where we are, and like if this doomsday saying is still a big thing, but just like to wrap things up, I wanted to really hear about where do you see the future of the whole news industry really heading towards?

David Cohn  28:57  
That's a really good question. And I mean, again, obviously, all predictions should be taken with a grain of salt, right? Because there's just too many moving factors here. One other thing that I've always talked about with the news industry is a kind of pendulum swing between like, as many eyeballs as possible, and you know, advertising and we'll call this like the BuzzFeed era, which, again, has clearly waned, but like, again, probably would have been from like 2010 to 2017, that would have been the height of it like vice, Buzzfeed, Vox, anything that was about getting as many eyeballs as possible and social. On the other end of the spectrum, is I use the information right there less about as many eyeballs as possible. It's about paying customers, right. So think, subscribers, you know, again, the information, I think it's $400 a year I could be wrong, but you know, it serves a specific kind of interested business person. And if you get 10,000 people doing that, or actually I'm bad at math, you know, even 5000 people doing that as a very healthy business. And so I think the industry kind of shifts between that and we've been shifting towards the subscriber Right influence. And so I put that kind of cycle in motion at the same time as a technology cycle. And the technology cycle is usually technology leads, and we're catching up. And the direction that technology is leading in is potentially one where, again, I actually think there will be a requirement for direct relationship and trust. Again, maybe I'm being overly ambitious about the human species, but I think people will want to find the kind of kernel of things that they can trust and believe in. And so those actually go together and can be very favorable. So I actually do see in the immediate future, like actually a really potential positive swing here. But again, all of these things I always see is shifting kind of back and forth between two extremes here. And then, of course, the backswing of technology is, is that second order consequence, which it's hard to always to kind of envision, but it's sort of like, the technology ends up actually owning too much. And we end up chasing it, and in the weak position chasing it, and so they end up accruing more of the benefits than we do.

Nikita Roy  31:03  
Well, this has been really fascinating conversation to just dive into all of the buzz that has been happening in the industry right now and seeing where everything is going to be heading towards. And as I said, it's going to be really interesting to look back on all of these, like conversations and comments that you made today in like, a year from now and just see where we'd be right.

David Cohn  31:25  
Yeah, I mean, again, you have actually been doing a great job. You're at the forefront of this, in my opinion. Like I like all the episodes that you're doing, I think will be really interesting to look at years from now. Because, yeah, I mean, again, there's a lot of unknown unknowns, and you are having great conversations. And I don't think anybody is claiming or can claim that they like can tell exactly what's about to happen. But again, that's what makes it such an exciting time.

Nikita Roy  31:48  
Thank you. I didn't pay you to say that. No, no, I

David Cohn  31:51  
just, I mean, like, you've gone out and you've been like, look, this is going to be a big deal. Someone should start having conversations about this. So kudos to you for for doing that.

Nikita Roy  32:00  
Well, well, thank you. That's very kind, David. And thank you so much for joining me on the news and robots. And I'm really excited to kind of see where also subtext evolves with AI and the future of what you're going to be building. So thank you so much for joining me on newsroom robots and really lovely having you here. Thank you. That was David cone, the co founder of subtext. If you like what you hear on the podcast, subscribe, rate and review the show on Apple, Spotify or wherever you get your podcast. This episode is made possible thanks to the hobbit innovation labs spark land. I'm Nikita Roy and this is newsroom robots.

"
newsroom_robots,8,"Wed, 31 May 2023 18:14:26 GMT",Craig Newmark Graduate School of Journalism at CUNY Workshop: Empowering News Entrepreneurs with Generative AI,https://www.newsroomrobots.com/episodes/craig-newmark-graduate-school-of-journalism-empowering-news-entrepreneurs-with-generative-ai-Uol_APCV,"<p>This episode features a workshop held by Newsroom Robots’ host Nikita Roy at the Craig Newmark Graduate School of Journalism at CUNY for the Entrepreneurial Journalism Creators Program. Focusing on the practical applications of generative AI tools, she explores how these advanced technologies can empower news entrepreneurs to streamline their workflows and shares numerous use cases for their implementation in the newsroom.</p><p>Mentioned in this episode: </p><ol><li><a href=""https://bit.ly/3C1mCbY"">The AI generated video produced for the workshop</a></li><li><a href=""https://bit.ly/3WKJx4O"" target=""_blank"">How generative AI was used to create the Newsroom Robots podcast cover art</a></li><li><a href=""https://drive.google.com/file/d/1-or5iR2luf_Ag4jrBQVF7_Ku9w89FWWo/view?usp=share_link"" target=""_blank"">Use case: Having ChatGPT act as a salesperson for a  hyperlocal newsroom</a></li></ol><p>AI tools discussed:</p><ol><li><a href=""https://chat.openai.com/"" target=""_blank"">ChatGPT</a>: Text generation tool by OpenAI.</li><li><a href=""https://writer.com/"" target=""_blank"">Writer</a>: Another text generation tool geared towards businesses  with a focus on privacy and a competitor to ChatGPT</li><li><a href=""https://lumen5.com/"" target=""_blank"">Lumen5</a>: Converts text to video.</li><li><a href=""https://beta.elevenlabs.io/"" target=""_blank"">Eleven Labs</a>: Text to speech voice generator.</li><li><a href=""https://www.midjourney.com/home/?callbackUrl=%2Fapp%2F"" target=""_blank"">MidJourney</a>: AI image generator.</li><li><a href=""https://poe.com/Midjourney"" target=""_blank"">Poe MidJourney Prompt Bot:</a> AI chatbot app to help you create MidJourney prompts</li><li><a href=""https://openai.com/product/dall-e-2"" target=""_blank"">DALL-E</a>: Generates images from text powered by OpenAI.</li><li><a href=""https://www.bing.com/create"" target=""_blank"">Bing Image Creator</a>: Bing’s AI image generator based on text powered by OpenAI</li><li><a href=""https://zapier.com/"" target=""_blank"">Zapier</a>: No-code automation tool that connects apps to create automated workflows.</li></ol><p>Thoughts or questions? You can reach us <a href=""https://docs.google.com/forms/d/1NfOf6umHO-ESYDWZKCKfdp10fSsqnCrDMXjL7DLNehg/edit#response=ACYDBNhRTwLMoF5elD80B4zR28Isqaqus2lIKHR_RO-HU_g1Vzm6IInXuVUGHZfz9QPnKw0"">here.</a></p><br /><hr /><p style=""color: grey; font-size: 0.75em;""> Hosted on Acast. See <a href=""https://acast.com/privacy"" rel=""noopener noreferrer"" style=""color: grey;"" target=""_blank"">acast.com/privacy</a> for more information.</p>","Nikita Roy  0:02  
This is newsroom robots, the Podcast where we explore the intersection of artificial intelligence and the news industry. I'm Nikita Roy, a data scientist, media entrepreneur, and one of the many founders currently building their ventures at the Harvard innovation labs. On the newsroom robots. I'm excited to bring you insightful conversations with industry experts about how AI is impacting the way we do journalism. Today's episode is a special one, it follows a different format. I recently did a workshop at the Craig Newmark Graduate School of Journalism at the City University of New York for the entrepreneurial journalism creators program, which is 100 day online certificate program that has 21 journalism entrepreneurs from around the world, developing their skills and knowledge to strengthen and grow their niche ventures. In this workshop I discussed different generative AI tools that can be used to help news entrepreneurs optimize their workflows. Here's Jeremy Caplan, the Director of Teaching and Learning at the Craig Newmark Graduate School of Journalism taking off the workshop.

Jeremy Caplan  1:16  
Welcome, everyone, we are excited to have a special session today. As you know AI is seemingly the subject everyone is talking about day after day these days. And we have a terrific ask Nikita to talk us through that and to give us a chance to dive in, firsthand. So this is really a an interactive session. I'm super excited, this field is changing every single day, it seems like there's something new and there's so much to keep up with that it's really hard for any single person to do so. So I think it's really great that we have Nikita here to kind of walk us through, she has hosted a really interesting podcast about this whole arena and has been steeped into it. And it's giving us a kind of window into a world with a fast kind of shortcut guide to some of the key things as they relate to journalism specifically. So Nikita, thanks for being here. We're delighted to have you and excited for the session and for the opportunity to dive into the subject matter.

Nikita Roy  2:08  
Thanks, Jeremy. I'm really excited to be here. I'm a news entrepreneur myself and launched a new product. And so I know kind of firsthand what it's like being in your shoes. And I'm excited to kind of show you how generative AI has been helping me think about how I can automate workflows and be more efficient in the newsroom, and I'm excited to share that with all of you today. So just a little bit about me. I'm a data scientist and host of the newsroom robots podcast. I also founded the NRI nation which is a digital news startup for the Indian diaspora currently incubating at Harvard innovation labs, and I was a participant of the ICFJ is leading us innovation labs, where we are currently prototyping and launching a whatsapp based digital media literacy Chatbot. And my connection to the new marks J school was that I was part of the product immersion for small newsrooms just finished last month. And so before we get started, I just want to get a brief overview in terms of like, where all of us are in regards to generative AI. So I have a couple of poll questions to understand that. So thanks, everyone, for watching that. So how would you rate your current understanding of generative AI, they'll help me kind of understand where we should be heading this conversation towards. So I guess a lot of people are more in the second phase. So you know what generative AI is have a grasp on its basic principles. So that's great for the people who are not sure what generative AI is, we'll get into it briefly and kind of give you an overview of what it is. Okay, great. The second question is how, okay, how confident do you feel about applying generative AI? Not at all confident, okay, don't worry about that we will be getting started in terms of how we can use generative AI filled with use cases and examples. The way I've structured Today's presentation is I'll be speaking for 20 minutes giving you a brief overview, I'll be giving you a lot of information, just kind of to give you a taste in terms of like what is possible with generative AI a lot of tools. And from there, we'll kind of you can go ahead and do your own research and learn more about it. But that's kind of the goal to show you what's possible with generative AI. And from there 20 minutes we will be focusing specifically on charge GBT and the whole buzz around it. And we will be talking about prompt engineering specifically for newsroom use cases and how you can do that and we'll have a hands on activity. And then the last 20 minutes is just basically for us to kind of discuss it and a lot of questions and answers. So to start off, I've just created a quick video to show you just how this presentation is going to be working and what really covering empowering us entrepreneurs with generative AI. Today we'll explore how AI can enhance your newsroom operations, optimize your content and expand your reach. Discover AI tools like mid journey for image generation and chat GPT for content creation, harness the power of automation tools like Zapier to create engaging digital content don't venture into the realm of prompt engineering and produce high quality outputs for various newsroom use cases. have your questions ready for an interactive q&a? And a discussion at the end on using AI in the newsroom? Join us for this exciting workshop and build the future of news entrepreneurship kit. So that was a video, Jen talking about what we'll be talking about today. Did you notice anything about it? Do you think any elements you were generated using AI? And if so, can you tell me what

Speaker 3  5:30  
antico was all AI generated? I don't think there was a human being involved.

Nikita Roy  5:36  
So what what made you say that, so every aspect of it?

Speaker 3  5:40  
Well, I've kind of been looking at AI just a little bit. And from what, but there are programs that are so seamless that you wouldn't believe. So I didn't believe.

Nikita Roy  5:58  
Nice, yeah. And I see somebody said, yeah, and said it copied your wise. So you picked up on that there are tools. And just as you said, Mark, there are so many tools today, that kind of would create videos for us. And so I did have my voice cloned by a tool called 11 labs. So the way it kind of worked was, I had Chad TPT. I put in all the slides that I wrote, and I put it in it gave me the learning outcomes and what the outlines were going to be, I just took that into another tool called lumen five, in AI generated an entire script, and also created the entire video just within seconds, provided the relevant imagery, everything. So nothing has been even changed by me, except for just copy pasting. And then just to add to a little bit of fun, I went to 11 Labs, I gave a one minute sample of my voice, it created an entire AI clone of my voice. And I just overlaid that on top of the video. And voila, you have a completely AI generated video just within minutes of using these three tools. And so why did I do this? Well, it was kind of fun to just play around with it. But also it was just to give you an idea in terms of what is possible. Chad TPT has been in the news a lot. But tools like lumen five could really help you with like social media videos, repurposing your news articles to reach people in broader ways. So you could instantly create a multiple, like YouTube videos, we've been playing around with it, it's really great. Then 11 Labs, you want to create a podcast, an AI generated podcast to just repurpose again, your news to have it available to people who just want to listen to it. You can clone your voice and have it on 11 Labs. It's so it's just so much possibility with generative AI. So does it mean we can generate a podcast episode based on edited transcripts? And a minute of a voice example? How about the tones and motions etc? Yeah, so you can completely generate a podcast episode with 11 Labs, it might sound like it's a bit monotonous, I would say. But I had sent a sample of 11 labs to my parents, and I sent a same recording that I had recorded. And they did not they couldn't distinguish between which was AI and not, they just said you sounded monotonous. You didn't have emotion and that voice. But my own parents couldn't distinguish between the boys. So that was a bit scary for me. So moving on generative AI. So we have a couple of people in the room who are still unsure what it is. It's basically just a subset of AI that uses machine learning to just generate outputs, such as text, image, or music. And it does all of this by learning patterns from input data. So training data, that they have a bunch of training data, all of these generative AI tools are just having their models drawn on. And then based on that, the only thing that they do is predict, they predict what is going to be the next word, what's going to be the next pixel in the image. They don't do anything in terms of actually generating knowledge. All that they do is kind of mimic what has previously been done in their training data. And that's what they display. And so kind of moving on. I'm just giving you again, a brief overview in terms of all the other tools that are there, you have a bunch of like image generation tools that can be used. So I think a lot of you might have heard in the news mid journey dolly being image creator, Delhi and Bing image creator are kind of powered by open AI. And I put the both of them there in relation to my journey as well because I feel like Delhi and Bing image crater is something that people are able to quickly and very easily get onto and start prompting and seeing how it works. Whereas my journey is run runs on a discord bot. And so it's a bit of a learning curve to get into discord and figure out how to use my journey. But I find my journey to be really helpful. I have my newsroom robots podcast cover art over there as an example because we used new journey to create the cover art we just put on a prompt for the human hand, the robot hand using a pen and instantly we had exactly the kind of image that we were envisioning for our specific podcast with Put everything in Photoshop. And then there we had it, we had a podcast cover art ready to go. And so that's kind of just an example because I know as news entrepreneurs, you have a ton of articles to be published and every article needs a hero image. And sometimes when that's difficult to find tools like mid journey, being image creator, could be a great source of way to kind of like figure out how to use. So play around with it, it's a lot of fun. And there's a bunch of resources online, I forgot to put it over here. But there is something called I put in the chat later on, it's called Poll bot, it also gives you a mid journey prompt. So if prompting is an issue for specifically for image generation tools, you can tell it exactly what you want. And it will tell you how you should be prompting with an entire prompt of what you should get the AI model. And so just moving on to shad GPT. Now, the whole buzz about Cha GPT. But What specifically can you do with it in your newsroom? So one of the main things that a lot of newsrooms are currently working on is headline generation for a be testing, helping with your SEO metadata. Another thing is also about social media posts, you can automate creations from your news stories for social media posts tailored for each individual social media platform, you also can create your video and podcast scripts for it. Just as I was talking, again, it knows how a YouTube script should look like it knows how a Tiktok video should look like. So just in relation to that it has all of that training data, you just give it you a news article, and it knows how to tailor it for each platform. So instantly, you can repurpose all of your content. You can also summarize press materials. So you want to extract any key points from press releases. And you report you can ask questions with PDFs. So they just launched a plugins which is just this add an app that big can be integrated with CHARGE GBT. So you can have a plugin for helping you read PDFs and you can ask questions go back and forth, you don't have to read a whole long PDF chat. JpT will basically summarize things for you. You can also develop news quizzes. So these are all examples of things that I've been playing around with. We are currently experimenting with news quizzes in our newsroom. And it's been a lot of fun to kind of just repurpose content and use that for audience to help promote engagement and fun interactions over there can also help you with grant proposals. So as news entrepreneurs, you'll be writing a bunch of grant proposals trying to get that funding and it can help assist with your funding efforts. And newsletters is another way. We can just automate the crafting of all of your news and what needs to go in there. There is currently a newsroom, a local newsroom called ARL now that is experimenting with this and they have expanded create an entirely auto generated newsletter using chat TPT and some of the other tools that we'll be talking about soon. You can also extract codes so you have a long interview, you want to extract highly relevant codes and key takeaways. Chad GBT can do it all for you. And you can also have article summaries put in your long article and key takeaways that readers need to know No, instantly can be generated from chat GBT. And you can also translate your content. So chat, GBT has much better translation service than others, like Google Translate and stuff. So you can really use that to reach a broader audience. And people are using chat GPT right now to do all of these different use cases. So this is just an example to kind of broaden your mind in terms of like, what's possible.

Speaker 4  13:26  
Makita I see marks hand is the band. Maybe we can pause here to take any questions.

Speaker 3  13:31  
Sure. In terms of translation services, how accurate is GPT? Versus like, actually just paying a couple $1,000 To have a translation service? And then what are the best language are its most effective languages to translate to?

Nikita Roy  13:49  
So chatty, btw? I mean, I think a human is always going to be more effective in terms of understanding no answers. And what I would say that it does is it gives you a great first draft always. And it's helpful to kind of like, go ahead from there in terms of all of the languages, I don't know, at the top of my head, which languages exactly is there, but some of the main languages like that I've been playing around with, where like Hindi and stuff like it was doing a pretty decent job with that. So do you have I know, there's somebody using it for Spanish, as well for Spanish news. So it's being used currently in newsrooms?

Speaker 4  14:28  
There's a question in the chat and then we'll take you on and then we'll get back to it if that's okay. We'll have time for more questions at the end as well. But I have to read this out loud as I said, How would you respond to concerns that use of chat GPT will help train it further driving the destruction of the industry and all of our passion and livelihoods?

Nikita Roy  14:47  
Um, that's a good question. But I think if we don't use chat TPT right now we are definitely doomed. Because we have all of these like aI generated content mills that are spinning around I think the challenge for journalism right now is really getting ahead and being able to use all of these tools to be able to get our news to more people build that authentic, verifiable trust relationship of trust with our audience. And I definitely think we, we kind of need to keep on top to use these tools to reach more people. I see this way as a way to kind of broaden the work that we do. And it helps us I think this is something that really helps us as like news entrepreneurs, you're having a really small newsroom. And it's just another extra hand it can help you do so many things. That that's what for example, for the newsletter is ARL. Now one of the main things he was saying he did not have the time to and the resources to put another another journalist on to cover another city. But with these automated newsletters, they're able to produce news for that particular study, which was not being done previously. So I think it's just a way for us to reach more people. And it's, I think it's kind of like weather risk there.

Speaker 5  16:01  
Yeah. So is there a marked difference between the paid version and the free version for GBT? And would you recommend subscribing?

Nikita Roy  16:08  
Yes. Good question. So charge, GBT has two models, jtbd 3.5 and GPT. Four GPT. Four is way more advanced in terms of is able to really understand instructions better, I find that outputs are way better. There is a limit for the GBD four, you can only send 25 messages every four hours. So previously, there used to be not as much of a difference between 3.5 and four, like the output was generally great, always for GPD four. But now what they have done within the last week, they have made two other features available, which is called plugins and a web browsing plugins what I was speaking previously, plugins are just other apps like you can connect it to like an air table, you can connect it to Expedia, you want to like water your groceries, you can connect it to Instacart. And it would do that. So there are apps that are built to connect with chat GBT. And you also have a web browsing plugin. So keep in mind that GPT the model was trained with data up until November 2021. So if you asked it anything recent, it had no idea and it would give you the wrong information. So GPT with the web browsing, again, which is available only for paid subscribers, you can now go on the internet and find any information that you want. And that's kind of I'm showing you an example later on. It could browse the web could do everything. So I would say right now, it's really good to kind of it's $20 per month, try it out, test it out and see what you can do. I find it really relevant right now with all of the plugins and the web browsing plugin that can help you do a lot more work.

Speaker 4  17:39  
Let's move forward. And then we'll take there's a lot of questions for the app as well. Okay,

Nikita Roy  17:43  
perfect. So this was an example that I was talking about leveraging chat GBT. Now for your newsroom revenue operations. You need somebody to help you with sales. How about asking chat TPT, what to do. So what I did over here was I use chat, TPTs browsing plugin, to search the web and kind of generate results to find out. So I'm based in Cambridge, Massachusetts, so I used it as an example. So I would know exactly what businesses they were talking and verify if it was actually working. So I said, give me a list of 10 businesses, their industry sector, and a unique pitch for each one of them, so that I can reach out to them for my hyperlocal news site for placing ads on a digital news website. And it generated 10 businesses. And as you can see, like a central square florist, and exactly tells your ad good highlight seasonal offerings remind readers of the joy of giving flowers. And every single industry sector is kind of covered different industry sectors like food and beverage and exactly why and it's completely customized for what they are doing. So what I really liked over here is like this lunch, it's about differently atmosphere, the drink selection, that's what they kind of highlighted in their website, this one on kitchen, like what is the dishes that tend to serve your cuisine. So it's completely very customized. And you could just use this quickly to create and generate emails or any pitches that you need to produce in chat. TPT kind of helps you. So this is an example I was talking about, where it uses the web browsing plugin, as you saw, it went exactly and it's telling you where it's getting all of this information from as well. So that's kind of one thing I like. So in the past week, this was previously just allowed for beta users. So not everybody had access to it. But now that they have, like, allowed it for all paid subscribers. I think this is one of the key selling points for Chad TPT for right now. So again, I'm Jen going through all of this to kind of show you what's possible. The next thing is kind of like automating workflows using no code tools. So I was talking about somebody who created a completely auto generated newsletter. What they did was they used their air table, which is a database for creating all of which has a database for all of the news articles. And what you can do is connected with this tool called Zapier and Zapier would be like your best friend for automating workflows. It's a completely no code tool that just helps you connect different apps together. So what this will do is chat. CBT also has something called an API, which is kind of this bridge that you can connect with it through code. So Zapier would connect to GP TS API, which is kind of like chat GPT. And you could prompt that using an air table. So for example, if you have an air table database with a bunch of news articles, and you want to create a summary, you want another column to be there, to create a summary, what you could do is you could create a so called zap, which is an automation automated workflow, that every time you place an article over there, and as a new row in your air table, it would automatically go to GPT produce, it would trumpet, the whatever prompt you've given it. And we'll come back and just create another column right next to it with what its summary of that news article is. So now just imagine you have a bunch of news articles in one column, you have all of the summaries that are AI generated. Now, you can just take that all together, create another zap, so that it goes through MailChimp, or whatever email system that you have to then send out an auto generated newsletter, you can do the same thing for social media posts. So you put in what your article is in one row, and automatically, it would create a zap. So every time a new row is added, it would go and create another social media post based on your trump. So instead of you having to go to charity btw, and every single time place a prompt and do something like that, it will automatically keep on working. So the same thing is for airtable Google Drive, you could use it as a Slack integrated with your Slack channel. So you can just type in a question or put in a URL over there. And Zapier can go and talk to open AI, basically talk to a GPT app and do everything and just generate it for you. So this is just kind of an example of how you can use automated workflows using no code tools. Do we have any questions regarding that?

Speaker 6  22:07  
Hi, this is Kim. I'm curious to hear what would the actual GPT prompt be for this? I'm so new to this?

Nikita Roy  22:14  
Yes, good question. So that's what we are talking about. Next. Because prompting is important. That's the big thing. to kind of get these AI models to work, we need to start writing for the robots. So do lead me into my next slide, which is how to create an effective prompt. So one of the main things, let's take an example for like the social media posts, you need to start with a clear goal. So kind of define the situation and the expected outcome. So you want to tell it that you want social media posts, you're giving it a news news article, and you want a social media posts specifically specify for like Facebook, LinkedIn, Twitter where you want to go, then the next thing is kind of define the output criteria. If it's for headlines, you want to specify, like for our newsroom, we can't exceed 66 characters for a headline. And so that's something that we would put define an output criteria, we define it, that it should headlines should not exceed 66 characters. And so we give it a response to and you can also give it a style. So if you're writing an email or something, you can tell it to have a more conversational tone, or more professional tone. And you can ask it, what kind of like style it could have for the entire response. Another thing is a zoom, that chatty between knows nothing provide any useful details to help chart TPT and achieving your goals, all of the information. So that also means you can put in your entire news article in there and just give it details that could help it create it is not a knowledge generator, it only goes to whatever data it's only mimicking the writing, it's only mimicking how to produce content and predicting what should come next. So give it all of the knowledge that you want it to generate. Another thing is detail the structure. So guide chart, GBT on the format. So, as you saw I specifically said in my previous example, give it to me in a table, you can tell it to give it to you in a bullet list. You can also give it some examples of how you want it to generate for example, if you are you have given it a bunch of an entire interview, you can tell it to give me the name and you can give it an example named Nikita Roy and then this is how the code should be colon and enter the code it should be in a code whatever code should be taken it should be a quotation marks. So you can give it examples like that and it would just follow those examples. So again, detail what the structures are. Also give it an initial context. So something like providing a role for chat TBT helps them understand the context. So you can say you are a journalist, you are a teacher, and it will automatically then change the way and the tone that they are doing. And you can also in terms of like style over here. You can also say right and AP style and it kind of does It knows APA style it has they have been trained on APA news article. So they kind of understand what the APA style looks like. And that's something that they do as well. And the next thing is separators. So try to keep your instructions on the top, and then give its context. So when you're zoomed out TPT knows nothing, you always have to give it a context. So for example, if you're giving your news article, you have the instruction of generator headline. And then use symbols like a hashtag three hashtags, or three quotation marks, it's basically just to separate the instructions in the context and then give it the context of what the news article is. So that just helps the model, understand it better, and then elaborated requirements. So don't be afraid to kind of be specific, be descriptive about your requirements, what is it that you're actually looking for? So the more information you give, the better your prompts will be. Just think about how you would be giving instructions kind of to another colleague who's brand new at the job, what are you expecting from them, that's how I look at it. And then chain of thought prompting. So this is a type of prompting when you have a really complex task. So for example, if you're asking chat, TBD, right, like an entire article, for example, it's too much for you to do at one point. So what you could do is simplify that complex task, you'll start off by how would you do it, you would start off by first writing an outline of the article, then you would start off by writing an intro. And then for each paragraph, what is the main theme, and like, you can ask it step by step by step to generate every single thing. So starting with the outline intro every single paragraph a conclusion that you put together everything and you asked Chad TPT to edit it again. So one by one, you kind of like break down that complex task into more sequential parts. And that helps chart TBT to kind of produce a better way of doing this. And then finally, going back to our chart, TPT example, we kind of give it a specific role and context. So I asked her to be a salesperson selling ads for a hyperlocal newsroom in Cambridge, Massachusetts. So I specified the location, I specified what we were, and I wanted it, how I wanted it to act as so then the next thing was I asked it specifically to generate a list of small businesses in the area. So specifying what the output criteria and goal is. And the goal was that you can so that you can approach the end regarding placing ads on your digital news website. And then as you saw detail, the structure I said, told that format in a table, I want the names of at least 10 businesses, exactly what columns such as the industry sector, unique pitch for them to place ads on your website, and then the fault I elaborate on the requirements. So I also wanted like a unique selling point of our website and want it to be customized for their business. So you could also include how you could highlight the their business and the impact it could have. And that's why it had produced that prompt. So the first time I had not actually when I was prompting it, I had not put the elaborate on the requirements. And it had not given me that customized, unique pitch. So that is why I then put in that entire line about putting a unique selling point, I wanted to be customized for the business and highlight. And that's when it showed you the output that you saw, which was completely customized so you can play around with it and figure out how it works. And so before we go ahead, I'm Breanne, I just kind of want to see how people are doing with Chad TPT. So if you could just, these are just three quiz questions that we have to see before we go into a breakout. And you go into prompt engineering to check how you're finding everything. So I'm glad to see most people are having the correct answer. So the first one is Yes, both B and C, you give them an example of a desired headline format and specify the topic of the article, it can help improve the chat GPT output. And in the next one, summarize the article and a few sentences again, yeah, so when you're giving it a context, it's easier for it to have that separator in there. And if you give it be more specific about exactly the number of sentences you require, so as I said, define the output criteria specifically, that will help you produce an even better prompt. So these are all good prompts for you to start and see what it's giving. And then you can add on all of these steps to make it better. So don't think that once you create a prompt, and that's the output, it's more of a conversation that you have with it. And just keep on modifying things one by one and see until you like what you've created as an output. So for what you saw, for the opposite I created I did go back and forth with quite a bit. I had a prom that I really liked. And that's what I showed you at the end. So it's not usually the first time that you create a prompt and it's great as an output and then the final one is respond to the readers questions below. Do not discuss any unverified information how this prompt can be improved. As I was saying over here you elaborate your requirements. So be specific and descriptive about your requirements. So one thing that I missed out previously to mention was that if you don't want Chachi BTG do something you can specifically tell it not to do it, but then give it an other option of what it should do instead. So over here, stick to providing verified Facts. Avoid speculations or unverified information. And over here, you give it what the verified facts are. So it wouldn't kind of go ahead and hallucinate and understand something and pull out something else from its own training data. So you kind of give it an option of what it should do, instead of just saying don't do this. So that's one way in which you can elaborate requirements there. So okay, we are kind of tight on time. This is great, because I know that all of you kind of have a good start and have understood at least the basics of prompting during to get things going. So I'm going to quickly get into our breakout session. The goal really for this is I want to have chat TPT prompts for four unique newsroom scenarios that we can then share within the group. And it can be applicable to all of us. And at the end of this, if you can just finalize a prompt that you as a group are collectively satisfied with and prepare to share it with all of your attendees. And each one of you have a unique newsroom scenario. So we have four teams, the first team, you are given a news article about the AI upgrades that Microsoft is bringing to chat GBT and being so you have to write a prompt to create headlines for AV testing and write a summary for IT team to since we're at Craig Newmark school, you're looking to apply for a grant from the Craig Newmark philanthropies and you need to write a prompt that aligns with your organization's mission and answers the following question that they're asking. So we just provide a description of how the grant will be used to advance the mission of Craig Newmark philanthropies, and include a description of the project's timeline and communication plan, you can just generate like a rough outline of what a grant out letter would look like. Over here, in the third team, you are given a news article about the steps that the White House is taking to study AI risks. So over here, write a prompt to generate social media posts for Instagram, Twitter, and Facebook. So kind of see how you can play around with the tones for each and every different platform that we have there. And the 14th, you are given a press release about a glassblowing and live arts festival in Detroit, right, a prom that extracts the key details and helps you in generating an article. So these are the four different kinds of newsroom use case scenarios, feel free to kind of play around with the prompting. And as I said, you can all log in to chat GPT and try out different methods and see what's working and what's not. And I will pop into all of the breakout rooms as well and help you out.

Speaker 4  32:26  
Welcome back everyone. We want to leave plenty of room for questions. So if you want to maybe just share in the chat, what that experience was like for you, what you kind of took from it, we can see how it felt for everybody. And then Makita I don't know if you have anything you want to say about that activity, and then we can transition to the questions.

Nikita Roy  32:47  
And also if you can just put in the prompts that you think were the most effective for generating it in the chat that will also help everybody else, I think to kind of learn from that. And just one thing that I wanted to stress that I had noticed in a breakout room was Don't think too much with your first prompt, you can go back and forth quite a bit with these chatbots. And just get started. It's not about getting it right the first time. Somebody I forget who was your VA Stacy, you're saying that you treat it as an intern. And the first time is I just generate a headline. And then you go ahead and be like, Okay, now I want it to be 60 characters, and then you can just keep on building from there. So just think of it like you're telling an intern and step by step guiding it. So you don't have to have it perfect the first time. So yeah, that's just one comment that I had. And we can move into questions.

Speaker 4  33:34  
Hong Chow had a question earlier. And I asked her to hold on to it. So let's have her speak first, and then we'll take the next one.

Speaker 7  33:40  
Thank you. Very, very quick question, because I'm not skeptical about the tour itself. There's just I have this privacy privacy concern. I wouldn't basically use all your workflows, authorization that you show to process any confidential information. That's my assumption. I don't know if anything that I share with the tours with the GDP or any other AIS will also be included to feed the model or not. Like do I omit like, where they take it over once I share any raw material rooster? Thank you.

Nikita Roy  34:14  
Yeah, that's a very valid concern. And I'm glad you brought it up. So Chad GBT, I would not and a podcast that's releasing today, Ryan Serpico who is hosts, AI and automation engineer, he had a really great point. And he was like, don't put in anything that you wouldn't tell a stranger on the street. So use that as your guideline. If you're not going to tell a stranger on the street, it should not be going into chat GPT into these generative AI models. Chad GPT does record all of these histories. You have an option now to go and disable that. And they will delete all of these conversations and they would not be using it for your AI model. But that's Chad GPT. There are if you try and code directly with their GPT API that's not used for training their data. And if you there are some other tools that I have been looking at Similar to charge GPT, there's something called writer.com, I have been looking into their model because they are very transparent in terms of what exactly they trained on. So we should know that charge GPT doesn't exactly tell us what they have been trained on. But a tool like reddit.com actually tells us what exactly they were trained on. And they have privacy of front and center. They are HIPAA compliant GDPR, everything. And so that's one tool that I have been exploring right now, it's probably not at the level of charge CPT. And it's slightly more expensive. But if you're looking for an AI generative tool, that's something that I have seen is kind of better than Chad TBT, there is a lot of privacy concerns and risks. It is a business at the end of the day. And like any tool, you are giving information to it. So you have to be very for all of these GPT AI tools. But the way you see it as if you're doing something like social media posts, and something that is already out there on the internet, you're just giving that information to it and repurposing it and kind of helping you with producing content that you would have to take time to produce otherwise, and it's not information. So I would never suggest putting any kind of confidential information, any kind of personal information for you don't do that.

Speaker 8  36:09  
Thanks. Yeah. So as creatives, we all have to be worried about our work being lifted and used without our permission, and perhaps none more so within photographs, but words to so your feelings about copyright infringement issues with AI images, or lack of attribution, we're already seeing lawsuits being filed to protect creatives, including one that Nathan's mid journey, which you said you used in your, in your presentation. What are your feelings about that? Were you Did you look into the images that were created you out them? Did you verify that nobody's being slighted nobody's work was being stolen? So currently,

Nikita Roy  36:47  
I mean, there's a lot of debate going on about that. And the way I see it is right now for news entrepreneurs. It's just helping us create content, there is no regulation. And I think that's something that we have a lot of like, conversations that needs to be happening with this AI generation is happening. And it differs from place to place in terms of like how the courts are going to rule. So I'm just going to wait and see what the regulatory authorities are going to say. And currently, this was a tool that was kind of helping us generate podcast art. And so that's kind of like how we have gone about using it. Thank you, Ethan. Go ahead.

Speaker 9  37:24  
Yeah, so if it's okay, I don't so much have a question. But like a comment about that exercise, because I was kind of it was, it was actually really cool. And we kind of Donna was using Bard and Tim was using Chechi Beatty, and we kind of we use my project as like the baseline. And so, like we put, you know, I put basically took my proposed once I think value proposition proposition, right, yeah, value proposition from yesterday, right, which I'll put in the chat, and, and my name. And, you know, I've been a journalist for 20 years. So there's like, a lot of my content on the internet website and stuff. So so just put this prompt in with my name, or Tim put this prompt in, and maybe modify it a little bit. He can speak to that with my name. And it spit out like a perfect proposal, like, like a really good grant proposal that like actually really well describes like what I'm trying to do. And I was like, yeah, man, I wanna, I wanna who wants my grant proposal, cuz like, it took us like, 10 minutes. And I'm like, I'm gonna go apply for some grants now like that. That was wild. Like, that was a really cool size. So and if you guys wanted, I didn't even get through reading the whole thing. I'll read about half of it. And I was like, this is all like, nailed it. So but if you want I'll I'll put it in the rest one to share that because I thought that was really cool. And Tim, maybe he can chime in to speak to like, how he tweaked that that? Oh, yeah. Here he goes to prompt to just put it in there.

Speaker 5  38:53  
Yeah, I just chopped it into chat, just basically using the information you gave us and gave it a little bit of context. And it really, it really ran for there. I was shocked at how little information it needed to do the obligation.

Speaker 9  39:04  
Yeah, I mean, work. Let me see I put a copy and pasted what it spit into a Word doc. And it's 554 words total. But yeah, thank you for that exercise. It was really cool.

Speaker 5  39:15  
Yeah, the fact that it even gives you like the headers and the like date and like, all that stuff was was really impressive.

Nikita Roy  39:22  
Yeah. And like if you look at GPT, four, and now with like, the web browsing capabilities, and everything, things are really adding on to it. And again, when I use chart TPT, I use sometimes like, not our original like newsrooms name or anything, I don't want things to be associated. And so I I have completely like alias names. So that's one way you can protect your identity. Don't put it specifically to your newsroom if you want to protect your identity over there, but it gives you a general outline. It tells you how it should drive for somebody like me who was coming into the news on news industry, not really knowing I was writing grant proposals for the first time. I had to scour the internet for a bunch of ways and how to write a grant proposal. When charging MIDI came, it just gave me basically like an outline that I knew now how people are writing. And I could just jump on from there. So that's one way, you can be using chat TPT.

Jeremy Caplan  40:10  
Thank you, Nikki, this has been really eye opening. I know, there's some some people who have really valid and important questions and concerns and thoughts and have raised many of them in the chat. Some of them we haven't had a time to fully explore. And so I hate to cut off the conversation. But I want to respect everyone's time, including yours, Nikita and and so I want to suggest we kind of potentially if people are interested, we can gather around this topic again and explore some of these concerns, which are really valid and important concerns. And if we in the journal some space, don't raise them, right, others may not raise them for us. So it's really important that we do consider all of these concerns. In addition to considering all the benefits, like we've just been talking about, and all the ways it can be useful and helpful for us, we should also be really mindful of the ways in which it's going to present new challenges and new problems and new risks, all of which were the case in prior new technologies, right? In the social media era, for example, we didn't consider a lot of those concerns, until many would argue, you know, it was too late to really have an impact on the development of those platforms. So So I appreciate everyone, everyone's those who have skepticism. You know, I appreciate this skepticism. And, you know, it's something that I think we can we can keep digging into further. I don't mean to cut it off now. But I know we've designated this as our timeline. And so again, thank you, Nikita, for this great, great session. I love the examples. This is a really interesting exercise to explore. I want to encourage everyone to keep experimenting. One thing is even if you're skeptical, even if you don't, you know feel great about how these things work or what they do. I think it's really important for us to understand what they do so that we can be smart critics or smart skeptics and speak intelligently about you know, their capabilities and limitations and concerns. So encourage everyone to try regardless of how you feel ultimately about about the tools or how you use them. Thanks again. Take care. See everyone again.

Nikita Roy  41:51  
Well, yeah, thanks, everyone. Bye bye. Thanks to the Craig Newmark Graduate School of Journalism at the City University of New York for hosting the workshop. You can find more information about today's episode and the tools discussed in the show notes. If you like what you hear on the podcast, subscribe rate and review the show on Apple podcasts, Spotify, or wherever you get your podcast. This podcast was made possible thanks to Harvard innovation labs spark grant writing Nikita Roy and this is newsroom robots.

"
newsroom_robots,7,"Wed, 24 May 2023 23:34:44 GMT",Ryan Serpico: Building Hearst Newspapers’ First Generative AI Tool,https://www.newsroomrobots.com/episodes/ryan-serpico-building-hearst-newspapers-first-generative-ai-tool-6UfbWkPC,"<p>In today’s episode, Ryan Serpico joins host Nikita Roy to discuss how he built the first generative AI tool that is helping power local newsrooms across Hearst Newspapers. </p><p>Ryan is Hearst Newspapers first AI and Automation Engineer, where he takes advantage of the latest developments in generative AI to empower journalists in Hearst Newspapers' local newsrooms across the country. Prior to moving into this role, he spent three years at the San Antonio Express-News, first as a digital producer and then as a graphics reporter. He graduated from the University of Florida in 2018 with a bachelor's degree in journalism in 2018. You can follow him on mastodon (https://mastodon.social/@ryan_serpico) and on Twitter (https://twitter.com/ryan_serpico).</p><p>We also discuss Ryan’s transition from the editorial side of the newsroom to the technical side, how he views privacy concerns regarding generative AI and his advice for journalists looking to get more technical with AI. </p><p>Thoughts or questions? You can reach us <a href=""https://docs.google.com/forms/d/1NfOf6umHO-ESYDWZKCKfdp10fSsqnCrDMXjL7DLNehg/edit#response=ACYDBNhRTwLMoF5elD80B4zR28Isqaqus2lIKHR_RO-HU_g1Vzm6IInXuVUGHZfz9QPnKw0"">here.</a></p><br /><hr /><p style=""color: grey; font-size: 0.75em;""> Hosted on Acast. See <a href=""https://acast.com/privacy"" rel=""noopener noreferrer"" style=""color: grey;"" target=""_blank"">acast.com/privacy</a> for more information.</p>","Nikita Roy  0:02  
This is newsroom robots, the Podcast where we explore the intersection of artificial intelligence and the news industry. I'm Nikita Roy, a data scientist, media entrepreneur, and one of the many founders currently building your ventures at the Harvard innovation labs on the newsroom robots. I'm excited to bring you insightful conversations with industry experts about how AI is impacting the way we do journalism. Joining me today is Ryan Serpico Hearst newspapers, first AI and automation engineer, where he takes advantage of the latest developments and generative AI to empower journalists at Hearst newspapers, local newsrooms across the US. Prior to moving into this role. He was a graphics reporter at the San Antonio Express News. In today's episode, Ryan discusses how he built out the first generative AI tool that is being rolled out across local newsrooms at Horse newspapers.

Hi, Ryan, welcome to newsroom robots. You're our first AI engineer on the podcast. So I'm really excited to get a bit technical today on the show.

Ryan Serpico  1:19  
I'm really excited to be here. You know, like, I really do wish I had this podcast a year ago because I for the past week, I've been binging the episodes we've had out so far. And it's been real insightful, like every guest that you've come on out you've had come on here have been very, very insightful. Oh, that's

Nikita Roy  1:37  
okay. Thanks, Ryan. So I, I really want to start off with setting the context for our listeners. You are Hearst Newspapers, first AI and automation engineer. It's just been a month now since we are recording this interview since you've got that new position. And you were on the editorial side as a graphics reporter for the San Antonio Express. And you did your Bachelor's in journalism. So it's not that typical kind of tech journey that everyone has. And so I'd love to start off by hearing your story like, can you walk us through that career transition you've had and how you've ended up developing cutting edge AI solutions for forest?

Ryan Serpico  2:17  
Yeah, it really started last summer, like almost exactly a year ago. But it was early June, I was coming back from visiting my family back in Florida. And I decided to pop in my air pods into my ear and listen to this new episode of this podcast. That's other podcasts I listen to called plain English and hosted by Derek Thompson. And he was interviewing this technologist named Steven Johnson and they were discussing the current state of GPT. Three. And you know, this is like months and months and months before Chad GPT When this became more mainstream, but as I was on the plane, and like, I can't do anything else, because I had my phone on airplane mode, I was still my full attention was on this podcast. And like, they were explaining what you could do with JPA. Three, like you could have it explained the Big Bang, like ask it again, like explain the Big Bang as if I'm a second grader. And I was just like, floored I was blown away by all the all the uses all the use cases for it. And I decided, you know, once I'd land, I'd go to a coffee shop back here in San Antonio and like, sit down and like learn how to you know, prompt it. And when to open the eyes playground prompt today got a response back. I was like, Cool, okay. And then I thought to myself, Okay, how do I do this programmatically? And I was able to figure that out in like, 2030 minutes using Python. And then I was like, Okay, now how can I apply this to the San Antonio Express News because everything that GPD three is about or was about at the time was about text and the San Antonio, Express News is all product is text. So there had to be like, you know, applications here. And this was like a Saturday afternoon and I was looking at our homepage. And on our homepage, like a lot of other media outlets, we use Chartbeat. And we use headline testing to see what headlines could increase our click through rates for our stories. And on this particular Saturday, there were no headline tests being run. And you know, that's like a bummer. That's like a missed opportunity. But it's hard to blame digital producers, digital producers are the folks who run our home pages and do the headline testing, but they have a lot of gold going on. I was actually a digital producer for the first year and a half, two years that was at the sanitize rescues. They have a lot of stuff going on. Like they're not just managing the homepage. They're packaging stories. They're compiling newsletters, they're like working on their own stories. They have a lot going on. So I thought to myself, Okay, how can I use GPD three to you know, help out producers scale up their work and you know, I crudely just clicked into a story grabbed it was about like this new pizza shop opening up. I grabbed the a blob of text there. rode into GPD threes playground and said give me five alternative headlines for the story and it spat it out. And I was like, bingo, we have, we have a use case for, for media outlet. And then like that's kind of that was kind of like the beginnings of how I got here. And it's really framed, how I view the use, like the best uses of the GPD, three GPD, three book wives, and so on so forth. It's like a bicycle for the mind that enhances our abilities beyond what we could do, just like on our own. But I can talk a little bit more about that later on.

Nikita Roy  5:32  
Yeah, I want to delve more into that kind of like product. So you found the problem, you found that the problem was that digital produces have too much going on and deplete so you wanted to help them out with headline? And how are you kind of like how did you build out that product? And what stage is it currently at?

Ryan Serpico  5:50  
Currently, we are actually like I want to stress this, we are still in the training phase, like we've built it out, we've got like we sent it to our legal department. And we're currently in the training phase. And we hope to be done with that by the end of the month. But when it comes to like the build out of it, like it took a while because for 90% of my time building this tool, I was a graphics reporter at the Express News. So like, while I was trying to report stories affecting the San Antonio area, I was trying to like, you know, squeeze in a little time here a little time there on the weekends to build it out. But it honestly, it was frustrating at times, but it was kind of like a blessing in disguise because it allowed me to see like how other media outlets around the world were trying to use GPD three in it for me to see, it showed me how to not go about doing a building a tool like this. So you obviously I know on a previous podcast, one of your guests brought up the CNET fiasco where they published 70 Personal Finance articles that were like riddled with factors. And, you know, I was like, Okay, how can we like avoid that. And I should say that this bot that I've created, this tool lives operates entirely in in our Slack workspace. So I was like, How can we avoid what's what happened to CNET? And that informed me to like, go ahead and make sure that like, these are all public conversations, like it's not like chat GPT where it's a one a one to one conversation, it's anything you ask of our bot is going to be viewable by everybody else in that market. So and I like exactly go in more and more in depth in that into that later on when it comes to the rules. But just the all that time I had to, like learn from others mistakes definitely, definitely informed how I felt out my tool.

Nikita Roy  7:39  
And like, Yeah, let's delve into the tools specifically. So is it that the newsrooms can just put in an article right now into like Slack, and they could get a headline generated? And is that how you in visualizing and like how you've seen the impact of this project?

Ryan Serpico  7:54  
Yeah, so I, so the tool is called producer P, we don't need it. The name it's inspired by like a silly basketball nickname, but tool is called producer P. And the way it works is that if you're a digital producer, reporter and editor or whatever in a market, you can as long as you go through the training, I should say that like you're not allowed into any of these channels without a training, you go into the channel and you can either you can make use of like several different commands that I've created. for it. The most popular one I expect to be the anticipated that most folks to use is called the produce command. And you can go in there into this slack channel and post either a link to a story or paste the text of the story directly into the into the chat and do dash dash produce. And in about 10 seconds, it will generate three seo keywords, three SEO headlines, three SEO URLs, suggested push alert and 10 related links that I got from Google based off of the SEO keywords. And then we in these trainings, we're stressing to producers, reporters and editors and beyond, you know, bees are not an end all be all solutions. Like I part of the reason why producer P is in a Slack channel and not directly integrated with our CMS is that I wanted that added friction to this tool because I really am trying to encourage our reporters to like think critically, it's it's not like a calculator when you when it says two plus two equals four, you know, that equals four, I tried to stress to them that you are still smarter than a large language model. You're still smarter than generative AI. So we kind of like follow that sandwich framework where you have a story, you paste it into the chat, and then it gives you a menu of options to choose from and then it's on you. The onus is on you to go ahead and tweak those headlines tweak those URLs. What this really does is it just kind of gives you a way to see a story from five different angles at once. And then allows you to scale up your work so that you're not on your own. You don't suffer from the blank page syndrome or writer's block After whatever, it's really meant to just scale up your work now, like replace your own judgment, your own news judgment.

Nikita Roy  10:07  
Yeah. And so is that slack channel? Did you think that's public for everyone in that slack channel to kind of be able to see how people are using the tool and learn from that? Is that how it's operating?

Ryan Serpico  10:18  
Yeah, yeah, everybody, it's open to everybody, I should just go ahead and explain my three roles I kind of like based off of Isaac Asimov's Three rules of robotics. But Rule number one is a human must be in the loop at all times. Rule number two is you must only use these tools, create schools that summarize, remix, aggregate existing information. And then rule number three is you need to be radically transparent, not just to readers, but to each other in the newsroom, because one of the biggest takeaways from the CNET fiasco is that when staffers over there spoke to the verge, they said that they had no idea what was being posted or being written by their fellow co workers and what was being written by their AI. So I really wanted to tackle that head on by giving us this public venue like where everybody can see what everybody's doing, and everybody can police each other. And we're doing that, like I said, on a market by market basis.

Nikita Roy  11:14  
Yeah. And I want to delve into the training. So that's very interesting before anyone, any journalists can use this tool, you make them go through a training, what does that look like? And what does it consist of?

Ryan Serpico  11:25  
Yeah, so there's three things I want folks to get out of these trainings. Like I want them to learn how to use producer P technically, like how to go like access the channel and like the commands that are available to them and the best practices. And like, on the best practices from that I want them to, you know, understand how to use it effectively, I don't want them to come into it with like, unrealistic expectations, or I don't want them to come away from it being frustrated or confused by its output. So I walked them through the best practices of how to use it. But the most important thing is like how to use producer P responsively. And that kind of leads into the rest of the presentation. Like, honestly, only 20% of the presentation is like how do you like how to use producer p 80%. Of it is like how to understand generative AI at large. Because I'm so close with a lot of the reporters here and editors here in San Antonio. And it just seems like folks don't really understand how large language models work. They don't understand that it's really just autocomplete on steroids. The way I've been explaining it to folks in the presentation, and like, you know, just that when I'm at a bar with a with a co worker, is I'm honestly lifting this research paper that came out back in, I think 2020 by this one professor, I think I believe her name is Emily bender. And she came out with this research paper that described large language models as stochastic parrots. And you know, like when I explained like to my co workers like what that means I don't actually like include this the word stochastic because I feel like that's intimidating. So I just explained to them that like, I told them like, think of it less like the Terminator like I'm trying to shake it like this decades of Hollywood movies, like I'm trying to shake these cognitive biases out of them. And I tell them, like stopping them as the Terminator. Think of them as just like, like parents, because when you're in a room with a parent, because we all find ourselves in a room with a pair for at one point or another in our lives. When you're in a room with a parrot. And it says something in English, you don't think that the parrot actually understands what it's saying. The same thing is going on here with generative AI with large language models. All they're doing like with parents, like parents, they are just mimicking what they hear in their nearby environment with large language models. They're just parents with a computer in the brain that has like the entire internet, for the most part up until 2021 lodged in their brains, and they're just repeating what they've heard or seen on the internet based off of their training dataset. And all they're doing is picking the next most likely set of words that it I don't want, say think but it predicts will occur based off of that training data. So a lot of this training is just trying to show our reporters and editors how this works. And because of how it works, it informs like its limitations such as like it doesn't understand current events. So if you come to it thinking it's going to like if you go to a chat TPT if you leave producer P and its channels and you go directly to chat TBT a won't understand current events, if you plop in a URL in there, and it gives you like a summary of an article. It's just it's not actually reading the article. It's not connected to the internet, unless you use one of the cheapy plugins. But, ya know, it's just a lot of it is just trying to show our reporters and editors or our newsrooms, how this works in the limitations I try. I honestly try to be a Debbie Downer for our newsrooms, but then I wrap it up by explaining like saying like, Okay, well why are we using this? And I explained to them what I said earlier about our approach of like, this is a bicycle for the mind and we have these three rules that we're trying to use to mitigate the purpose. Agile risks. And my final slide just tells our newsrooms like don't undervalue your abilities don't argue don't undervalue your abilities don't over value the API's.

Nikita Roy  15:11  
Wow. And what's been the response been from the newsrooms using these tools? Well,

Ryan Serpico  15:16  
so we've only trained one newsroom so far. And it was like my home team here in San Antonio, Express News. But in the past week, it's been fairly positive. Like they've been loving it. And so far, they've been heating my warnings about like, don't use like its output, like literally, like use it as inspiration, using it as a starting point. It seems like they have taken that to heart and yeah, like, I've been blown away with their response so far. Yeah. And

Nikita Roy  15:43  
what kind of like challenges did you face when you were building out this product? Because now as I understand it, it's like, a GPT, three API written on top of like Python that creates an app for slack. And like, how did you go about building that out? And like, what challenges did you see when you were creating it,

Ryan Serpico  16:00  
creating it? Well, just like, it's kind of what I've been saying about how do you avoid like these, these risks of people to blindly copy and pasting its completions into our CMS or into our headline testing, honestly, was the biggest struggle or biggest concern for me and how to communicate like its limitations. I'm much more concerned about that than any of the technical issues that like, hit me during the development process.

Nikita Roy  16:28  
So I kind of like want to step back because you've developed everything in Python, you've been coding, but you did do a bachelor's in journalism. So like, Was this something you picked up? Like, how did you move to the technical side of the newsroom?

Ryan Serpico  16:41  
Yeah, well, I going back to my time at the University of Florida when I first entered the J school over there, I had fully planned on becoming a technology reporter in Silicon Valley. From a young age. I've always been fascinated with technology back in high school folks called me like Steve Jobs reincarnated because I carried around his biography, like that giant white book for my entire junior year of high school. So I've just always been fascinated with technology. And when I entered the Jade school, I was going down the staircase of Weimer Hall. And I came across this flyer that was advertising this course that was specifically designed for journalism students that taught them how to code and I thought to myself, hey, well, I mean, I guess I think it'd be like a good idea to learn how the sausage is made of how like software is made, because I thought it would inform my reporting. And then like, one thing led to another and I just want up writing more code than prose. I was at the fin and so ever when I was at the University of Florida, and then like, fast forward to 2020, I got a job as a digital reporter, or a digital producer, where like, my responsibilities were just to manage the homepage, and maybe put send out some social media posts by I was hired in March of 2020, like right at the get go of COVID. And I saw that our producers every night, we're taking our local COVID data and like downloading it, and like writing some functions on it to like, clean it up a little bit. And then like, uploading it, and like, like, it's like this whole process, and I was like, I'm thinking that COVID is gonna last a while, and I don't want to do this every day. So I went ahead, and like, this was like, my first or second week, I was like, I'm just gonna write a bot that does the whole shebang. For us, I'm just gonna, like, have it like pull the data, clean it up, and upload into a data wrapper graphic that automatically updates every night. And that kind of laid the create the framework for that led me to where I am today at the at the first step up. And that's what my whole job is about now is creating these tools that take advantage of the latest advancements in generative AI and automation technology to not replace as I have to constantly remind our newsrooms like not replace anyone but to like Empower producers and reporters and editors in our local newsrooms across the country. And like what

Nikita Roy  19:07  
resources really do kind of like look to, to kind of stay on top of this, like ever evolving AI world and just like help you develop technically.

Ryan Serpico  19:17  
Yeah, so I think it's funny how I keep up to date with the latest updates in generative AI. I use a 24 year old technology called RSS. I'm a huge fan of RSS. It's how like, I'm sure many of your listeners are receiving this podcast right now. And let's listen to it on Spotify. Yeah, no, I love RSS I use it for news but I also use it for AI you know, and I just subscribe to like anytime I come across an interesting blog or newsletter or forum that touches on generative AI I subscribe to it instantly and I just like keep it in my RSS reader and as they come in i i jump on it like some examples of my favorite examples is Simon Wilson's blog is a an open source developer that has done like re writing around like aggregating of like ai, ai news. I follow that AI snake oil newsletter that shows, you know, like how various outlets are not using generative AI appropriately. And I find that informs my thinking. And then there's this like, great website called emergent mind.com. And their whole thing is just generative AI news. It's kind of like a hacker news. If your listeners are familiar with it's kind of like Hacker News, but more specifically, just generative AI and I find that to be like a great snapshot every day of what everybody is talking about in the generative AI world.

Unknown Speaker  20:38  
Yeah. And

Nikita Roy  20:40  
I'm kind of interested more in like, what real potential applications do you see going forward for generative AI? Like you found that one solution? What are the ways do you think generative AI can impact the media industry?

Ryan Serpico  20:53  
I think the I've actually been using generative AI longer than for more than a year, like it goes back before June of last summer, at the beginning of 2022. I saw GitHub put out a blog post about this experimental tool called GitHub co pilot, and I download I was like, Okay, this is pretty neat. But like as time went on, I was like, Oh, my God, this is like, incredible. And

Nikita Roy  21:15  
could you just explain GitHub copilot for our listeners? Yeah, no.

Ryan Serpico  21:19  
So yeah, it's like, it's like chat GPT, but entirely for, like programming for coding. And like, it's more than just autocomplete. Like, oftentimes, when I show this to like, data reporter, or like a reporter who works in one of our newsrooms copilot, they're often like, oh, so this is just like, you know, like autocomplete. But then I show them that you can like actually, in a comment, like, like in a Python comment or a JavaScript comment, you can go ahead and say, like, I want a function that does this, and this and returns this. And it does it and it like references like the code that you already have in your, your Python file, JavaScript file or whatever. And, you know, I know Python, like before kopen. I like him. I've been like using Python ready Python for like three or four years. But what I found was they it just it felt so empowering and made me like the words of Simon woloson It like made me feel a little bit more ambitious, with the things that the sort of things that I can do. And I think that in that lies like a potential opportunity for a lot of local newsrooms across the country that aren't like, you know, Hearst newspaper, like they're an independent and independent paper are like a nonprofit, like it's like a small paper where there's only one person who knows how to code. And that like, that's like, we don't we, you know, lonely coders, it's rough. So what I think is great about co pilot is it almost lets you punch above your weight. And it could be like this equalizing force for these local newsrooms around the country. You know, like, as long as you know, like the bare minimum of coding, like, you could just if you want to scrub a scrub scrape government website, but you're not exactly sure how to, you could just like, go into co pilot or even chat GPT and give it like the HTML and you could ask it like, not just like, just blindly do it, you could have it explain to you how to go about doing it. And of course, if you want to make it easier, you could ask it to like, take on the persona of like Michael Scott from the office to like, explain it to you, and make reference to the office, I find that to be like a helpful way of doing. But, um, ya know, so it's like, it's I think that copilot and Chad GPP like, it's not just for blindly getting like responses back, I found it to be like a great educational tool, and a jump springboard for more research after the fact, I oftentimes have both my coding projects, and previously with my reporting projects, going to chat up at menus asked me to be to help me do a pre mortem for a project instead of a post mortem. So I could see like, all the potential hurdles that might lie ahead of me. So I can like be mindful of them, and address them as I go along. So ya know, I think for building out tools like producer P, it's like, excellent. And I think that for reporting, I think like data, like data reporting, I think it has a lot of potential there. Like, I always say to my coworkers, Python plus VS code, plus Jupyter Notebooks. Plus get out copilot is just like magical, because in a way, you can actually like interview your data using natural language, of course, like, you know, you need to like go ahead and like fact check it, but it just makes it like really, it's like wait faster to like interview your data, like to do data analysis in a Jupyter notebook with the help of GitHub co pilot to interview your data and get quick insights.

Nikita Roy  24:34  
Yeah, and I want to get into like the prompting aspect because that's super important when you're building this out even like get up copilot Chad GBT getting them to do exactly what you want to do. So do you have any like tips or insights in terms of like, how you have been approaching that?

Ryan Serpico  24:48  
Yeah, no, I mean, like, you can start out by saying, well, we can use an example I use the other day. It's not like you know, for reporting or anything one of my co workers who I believe he lives In Oakland, but he every week goes to this like trivia night. And at this trivia night, they weaken out in advance, they actually give out the topic of like, what the trivia is, it's going to be entirely about and he said, in a Slack message to me, he said that he was trying to get chat GPT to, you know, like, help them solve it because they scramble the topic, I should say they scrambled like that topic name. And he was trying to see if Chad TPT could go ahead and unscramble the words for him, and what wasn't working for him. So yes, if I could create a prompt, and I feel that there's just like some sort of rules of thumb, you know, when you're designing a prompt, like, the most important thing to me is to give it like plenty of examples, this is called cue shot prompting, because it just it gives something that gives Chuck GPT something to infer from rather than trying to do it blindly. And you could also it's also good to define like, exactly what your what output you're looking for. Because if you just ask it to like unscramble these words, it's going to try to like explain everything, like explain why it's doing what it's doing. But it's like good to inform it, like I only want you to like give me the topic, nothing else and directing it to not repeat. Like if there's only one letter if there's only one letter E and it only produce just one letter, or just one E and B in the output. So giving it examples to work from tantamount giving it like the expected output that you want to see out of it is important. Give me a context giving it constraints, just like those are like those are the rules of thumb, I think for when it comes to giving a good prompt is also you know, chain of reasoning prompt where you can like write out, like, give an example of like a type of answer you want to get out of it. But just like your your train of thought. So like if you're giving it a math problem, like explicitly giving an example of like your reasoning to so that it follows you your reasoning in its answer. That's a good another good. Another good example.

Nikita Roy  26:56  
Yeah. And I kind of want to get your insights in terms of like for journalists who maybe like you have a bit of experience with coding or are looking to wanting to learn coding, what kind of languages or tools do you recommend that they kind of focus on right now, so that they can upskill themselves?

Ryan Serpico  27:15  
So I'm like a Python head. I don't like any other language, like I've always just been like, I'm probably biased here. Just say like, you know, Python is, I think, the most friendly language out there. And there's so it's the one that was popular. Yeah, no, this isn't a controversial statement. It's like always, like at the top, like five I think StackOverflow surveys each year. So that and then also just like, honestly, spending a lot of time with copilot like download copilot I think it's free for a certain set of a certain set of time. If you're a student, you know, don't tell your professors but it's free, copilot. So just like getting in there and like, like, it's always been hard for me honestly, to explain to my co workers like the benefit, because again, they all just think that it's like just copilot or autocomplete on steroids. But like, you really need to like experiment and noodle with it on your own to see what you can do with it. Like just install it and just start a project like you normally would. And then just start writing comments in English and natural language to start learning how to use and I promise in time, you'll you'll see the magic that lies within. Yeah.

Nikita Roy  28:25  
And so I just want to like kind of like wrap things up and see how are you envisioning kind of the future of the newsroom looking like, from more of a technical side and developing like you, you're the first AI engineer, how do you see newsrooms evolving.

Ryan Serpico  28:41  
So when it comes from comes newsrooms, like I'm trying to ingrain like I've said throughout this, this podcast, just like educating our reporters on like, how to use it effectively. And I try to like tell them, I tried to assuage their fears that like, you know, AI is not going to take your job, but I remind them that like they shouldn't be worried of that about that they should be worried about like a reporter who knows how to use AI replacing them. So I think just it's it's vitally important to like learn how to use it, like using it as like a thought that thinking aid, as I said earlier about using it for pre mortems. But also using as like a jumping off point when it comes to like when you're starting out a story like asking it, you know, what, like, what type of people should I like, talk to like, what sort of like sort of sources should I be seeking out for the story. And then also, like, once you've written the story, like giving it like your write up, and asking it for clarity. So just like, I think for reporters, like traditional reporters, like it could be very useful tool for their writing, not replacing them not replacing the writing, but just like helping them improve their own writing. It's like chat. TPT is almost like an editor that never sleeps and never gets tired. are you bothering them? So

Nikita Roy  29:51  
I just had one last question in terms of like, using all of these GPT technologies, how how are you looking at the privacy risk, and have you been concerned And then looking into that and kind of educating your journalists about it.

Ryan Serpico  30:03  
Ya know, like, we've had long discussions at Hearst newspaper about, like what we should and shouldn't like, throw into these large language models like anything that any stories that are unpublished, you should like shouldn't post like post the plug into produce a PR tool or any of these other tools, especially if it has any sensitive information contained within it. We've seen like instances from I think, just last month with open AI, they had this like, issue where people were seeing like other like conversations from other people of hearing in their in their timeline, or not their timeline in the in the TPT interface. So it's, you know, just trying to tell inform reporters when they're using this, like, be careful, don't like, Don't be stupid, don't like Don't Don't Don't, don't share anything with it that you wouldn't share with like a person on the street.

Nikita Roy  30:53  
Okay. And last words about kind of, like, how has your journey been so far, one month in I feel like it's your 30 day report into your job as an AI engineer, What's kept you so excited and keeping up with the whole AI journey at Hearst?

Ryan Serpico  31:09  
I think just like the impact that I'm already having, like, honestly, for the first month it's been there's been a lot of focus on automation, not like just like the standard automation aspect of my of my job title by the generative AI tool and the potential that holds in there like older within scaling up not replacing, but scaling up all our work to help us punch above our way in our newsrooms.

Nikita Roy  31:31  
That's exciting. So thank you so much, Ryan, for coming on the podcast. This has been so insightful. I'm so excited to see you develop more innovative solutions for Hearst Newspapers and really power that local journalism that you guys do. So thank you for taking the time and being here.

Ryan Serpico  31:48  
Yeah, thank you for having me.

Nikita Roy  31:51  
That was Ryan Serpico host newspapers, first AI and automation engineer. Subscribe to us on robots on Apple podcasts, Spotify, or wherever you get your podcasts. This episode was made possible. Thanks to the hobbit innovation labs spark grant. I'm Nikita Roy and this is newsroom robots.

"
newsroom_robots,6,"Wed, 17 May 2023 15:35:55 GMT",Bill Adair: AI-Generated Misinformation & The Future of Fact-Checking,https://www.newsroomrobots.com/episodes/bill-adair-ai-generated-misinformation-future-of-automated-fact-checking-generative-ai-x__1tB7I,"<p>Pulitzer Prize-winning journalist Bill Adair, the creator of PolitiFact and the co-founder of the International Fact-Checking Network joins host Nikita Roy to discuss the current state of misinformation in the age of generative AI and the role of journalism in combating it.</p><p>Bill is a Knight Professor of Journalism and Public Policy at Duke University, where he researches new ways to expand fact-checking and combat misinformation. He is currently working on a book about lying in politics. </p><p>We discuss the potential threats and opportunities that generative AI brings to the industry, the cutting-edge work at the Duke Reporters Lab using generative AI, and the future of automated fact-checking. </p><p>Tune in to hear Bill's optimistic outlook on leveraging AI to safeguard our information ecosystem.</p><p>Thoughts or questions? You can reach us <a href=""https://docs.google.com/forms/d/1NfOf6umHO-ESYDWZKCKfdp10fSsqnCrDMXjL7DLNehg/edit#response=ACYDBNhRTwLMoF5elD80B4zR28Isqaqus2lIKHR_RO-HU_g1Vzm6IInXuVUGHZfz9QPnKw0"">here.</a></p><br /><hr /><p style=""color: grey; font-size: 0.75em;""> Hosted on Acast. See <a href=""https://acast.com/privacy"" rel=""noopener noreferrer"" style=""color: grey;"" target=""_blank"">acast.com/privacy</a> for more information.</p>","Nikita Roy  0:02  
This is Newsroom Robots, the podcast where we explore the intersection of artificial intelligence and the news industry. I'm Nikita Roy, data scientist, media entrepreneur, and one of the many founders currently building their ventures at the Harvard Innovation Labs. On the newsroom robots, I'm excited to bring you insightful conversations with industry experts about how AI is impacting the way we do journalism. Joining me today is Pulitzer Prize winning journalist Bill Adair, the creator of Politifact, and the co founder of The International fact checking network bill is a knight Professor of Journalism and Public Policy at Duke University, where he researches new ways to expand fact checking and combat misinformation. He's currently working on a book about lying in politics. In today's episode, Bill explores the transformative impact of generative AI, on fact checking and his work at the Duke reporter's lab using generative AI.

Welcome to News from robots Bill, I'm really excited to have you on the show today.

Bill Adair  1:12  
Thanks for having me.

Nikita Roy  1:13  
So I've been looking forward to our conversation today to get a lot of answers from your wealth of experience, because we've been exploring how generative AI presents a lot of opportunities for journalism. But this is growing sense of unease and a lot of concern in the industry right now about its ability to rapidly create and spread misinformation and disinformation. We've already witnessed examples of this, like with Chad GPT, just hallucinating making up fake Guardian articles that sound just like their journalist would write it. Then you're seeing AI generated images go viral like that of Trump and handcuffs or something like Pope and Berlin's Yaga. And the information ecosystem has already been under pressure from a lot of these bad actors, polarization and just a constant stream of misinformation. And now with generative AI, I want to get your views on the whole generative AI and entire mis and disinfo landscape. How do you see it impacting our entire information ecosystem?

Bill Adair  2:22  
You bet? Well, it's an exciting time. And it's also as with anything new, it creates lots of uncertainty and the uncertainty breeds fear. And so people see this and they immediately start worrying. And, you know, we think about 2001 A Space Odyssey and you know, the astronaut outside the spaceship saying, you know, how Open the pod bay doors and how doesn't open them. And that's sort of our vision of AI run amok. So I think it's natural that we're afraid that when technology becomes as smart or smarter than than us that we begin to worry.

Nikita Roy  3:01  
And I want to get your thoughts on the situation that we're in right now with the pressure that's on our information ecosystem. Just in March, the Duke reporter is lab put out a review that showed that many politicians claims in the US, especially at the local level go unchecked. And now we have this added challenge of AI generated images, chatbots hallucinating and fabricating information and just the potential for a constant creation of misinformation. How are we as the news industry now going to be able to keep up with that speed of misinformation that's going to be generated? Yeah, well,

Bill Adair  3:43  
let's let's take those things separately, because they're very distinct things. So I think everyone is aware that the news business is in a period of great turmoil, the legacy news organizations have been contracting in painful ways. And newspapers in particular, have shrunk in dramatic and quite difficult ways. And that has reduced the number of reporters that are covering local government that are covering state government, and they're just fewer boots on the ground that are holding politicians accountable. So that's, that's a problem in my world, in political fact, checking that manifests itself in that politicians are able to say things without getting checked, and that's very disappointing. I started PolitiFact in 2007. And in the 16 years since then, there are fewer fact checkers probably and in various areas, because news organizations, particularly newspapers just don't have the resources to put into fact checking. So that's a problem. We put out the report that you just referenced here. In our Duke University reporters lab that showed dramatically how little state and local politicians are fact checked, and that's very scary. So for example, a governor only about half the governors in the United States got fat checked, the percentages are much lower for US senators, dramatically lower for US representatives, and just a sliver of mayors and state legislators get fat check. So, you know, think of it like what are their odds of getting a speeding ticket for racing down the highway, tiny, you know, there's just, they can lie with impunity, because they know they're not going to get factcheck. So that's really worrisome to me and to a lot of people. But here we are this moment of new technology, that creates great promise, but also some scary things. And so generative AI creates some opportunities to remedy the situation. And so I'm not one of these people who's like, Oh, my God, you know, Chet gbta is like hallucinating. I'm not so worried about that. And I think that those sorts of things can be fixed.

Nikita Roy  6:13  
And what would you say would be the fixes, really, because as the technology just gets better and better, how are we going to be able to keep up with that speed of misinformation that's going to be generated?

Bill Adair  6:26  
Sure, I think it's important. But there's been a lot of huffing and puffing about generative AI and its mistakes here in this first incarnation. And I would liken this to the people who sit and they're like, Ah, this stuff will never work. This would be like the people who had Kitty Hawk, in 1903, watch the Wright Brothers plane and said, Ah, that plane, planes will never fly, that plane could only go underneath feet. And you know, that's silly. What we're seeing here is the absolute first generation of this technology, both in generating words and images. And so it's gonna get better, it's gonna get much better, and it's already gotten better. And so we shouldn't scoff at it, we also shouldn't be afraid about it, we just need to look at ways to make it better. And, and so I'm amazed that so many of my colleagues have made such a big deal of you know, because, you know, it's, it's terrible. It's got this wrong, and it got that wrong. Well, of course, you know, and, you know, the Wright Brothers crashed the first planes that they flew, that's how we advance human effort, you know, is by trial and error. And so that's what's going on here, both with the images and with words, so what can make it better? So one of the problems, of course, with generative text is that we don't know where it's getting its information. And so clearly, we have to make sure that these large language models begin to point to dependable sources and reference them. And that doesn't exist under the current, the current structure of large language models. And so we need to redesign them so that they show their work so that they show their sources so that we know oh, well, this information came from Politifact, or factcheck.org, or the Washington Post fact checker. And, you know, the problem with them is they have these giant brains. That's basically the web. And we don't know what you know, the internet, and we don't know where it got its knowledge. And, you know, it's essentially just a guessing machine. That's like guessing what the next word should be what the next pixel should be. And so the creators need to make that better. They will, you know, I have no doubt and the latest versions are better than the previous versions. So it's getting better.

Nikita Roy  9:03  
Yeah, and generative AI, just the same way as it's helping automate processes and journalism. It's also helping automate the production of misinformation in the same way. And we are just grappling with a future of a widespread creation and dissemination of this type of content, which is going to increasingly overload our information ecosystem. So how do you envision newsrooms and fact checking organizations evolving to tackle this kind of surge in missing disinfo that might arise from all of these advancements?

Bill Adair  9:39  
So Well, the problem with individual newsrooms is they don't have the resources to do much of this. So they need help. And so what we're hoping to do is help them help them leverage their small resources to combat misinformation. And I think one way we can do that, for example, in the in American politics, it's common that politicians have talking points. So a politician in Virginia will repeat the same line. That's been said by a politician in Florida. Now, there may not be a fact checker in Virginia to check the new instance. But there might have been one in Florida who did it. And with large networks of fact checkers, like we have today, you can easily match those claims. So the politician in Florida says something say about immigration. And then the politician in Virginia essentially repeats it. So that creates an opportunity to use AI to match those claims. And then use generative AI to generate a new fact check on the the new claim by the politician in Virginia. Now, that's good. But it's risky. Because as we know, you know, generative AI can make mistakes, it can make assumptions that are wrong. We've all seen examples of that. So we have a concept that we call half baked pizza. And this is like if you go to a supermarket, and you want to have a good pizza, but you don't want to go through all the hassle of making it, you get a pizza that's half baked, take it home, you tear the wrapper off, you stick it in the oven. So our concept is essentially the same with a fact check. Generative AI presents the journalist with a half baked pizza, a fact check that takes the original content from what happened in Florida, adapts it to the new claim by the politician in Virginia, and presents the half baked pizza to the editor who says yep, yep, yeah, the ingredients are fine. Let's put it in the oven. And so that factcheck then gets published and distributed to the audience in Virginia, or the editor can say, No, we need to move some pepperonis around, let's, you know, let's put some more onions on it. And, okay, now it's ready. Now we'll put it in the oven. And so this is the human in the loop concept, to use a technology term, to make sure that the content is accurate, you're still benefiting from the savings of human effort from technology. But with a human in the loop, you're ensuring the quality of it, and that you're not putting out journalism that's inaccurate. So I think that's one way we can fill a gap in local journalism, benefit from work that's been done by a human fact checker in another area, who has checked essentially the same claim.

Nikita Roy  12:49  
Yeah, and I want to learn more of the kind of work that's been done at Eucalyptus lab. I mean, the development of the squash tool was a significant leap forward and automated fact checking. So could you walk us through the functionality of squash and how it automated fact checking, and what's the future of it?

Bill Adair  13:09  
So squash was essentially the first generation of automated fact checking. And the idea was the dream that a lot of people had. And this goes back to when I started PolitiFact in 2007, of having instant fact checking. So a politician makes a claim or campaign commercial comes on, and people have an immediate need for information, you know, is that true that you're the politician say something? And they want to know, is that true? So we pioneered and it's pretty amazing to see a demo of it. A technology we call squash, as in squash the falsehood that recognizes when a politician says something, we use voice to text to convert the claim to text, we then match it against a giant database that has all the fact checks that have been published by the main fact checkers in the United States. And then when there's a match, we pop up on the screen, this is a video tool, a summary of the fact check. It's amazing, you know that you're cruising along watching us speech or debate. And the fact check pops up on the screen. It's truly it puts a chill up your spine, except that it's got some UX problems, some user experience problems, because there isn't time to read what's on the screen. So as cool as this is, it hasn't been an effective tool. We actually haven't released it to the public. Because we haven't solved this problem of like, how do we summarize it on the screen, so that it really is useful to people and political speech is so dynamic, it moves so fast, that even though it's instant, having this summary pop up, that by the time When people digest it, the politician has said two or three additional things. And the person looks up and is like, Oh, what, wait, what? What did he say? And so there isn't, there isn't time to digest it and, and then kind of resume listening to the speech. So we've thought about pausing the speech, letting people actually interact with the speech in a video way. So you would actually take control of the speech yourself like you like it's a DVR. So anyway, we're very excited about it. But now I think the action is going to be in generative AI not in this kind of pop up factchecking we ran into in squash was exciting, we did some really groundbreaking things. But ultimately, that UX problem is really hard to conquer. Another one that we found is that there just are not enough fact checks to draw from. So if it's a presidential campaign, there's tons of fact checks. But any other campaign, US senate gov house, for all the reasons I explained earlier that, you know, there's just not that many fact checks because journalists have to crank out fact checks. And that takes some time. So squash would not work on a Senate race would not work on a governor's race even. So we've been that's another drawback in all that, anyway, I think the same way we look back at the Wright Brothers, we'll look back at squash and we'll say yeah, you know, the Duke reporters lab, flew the plane 108 feet. And it was cool. But we haven't built the 747 yet.

Nikita Roy  16:40  
So what is your current focus at the Duke reporters lab in terms of shaping the future of fact checking? What areas are you primarily concentrating on at the moment?

Bill Adair  16:52  
So generative AI, and in two ways, the one that I talked about in terms of cloning fact checks in making half baked pizza, and then the other side is how the bad guys are going to use it? Because we don't know how they're going to use it, but we know they will. And so how will the forces of evil, use generative AI to target their misinformation in devious ways, you know, it makes it possible to micro target lies at scale. I mean, in frightening ways, you know, used to be, you would have one website that would have all the false stuff on it. And so that was this pink slime that my colleagues here at Duke have studied, and that you would have just, you know, these garbage websites, and there would be like one for an area. Well, now you have the potential that these messages whether through a website, or through targeted email, or WhatsApp messages, can be targeted directly to people based on their, how they their behavior online, how they what they click on their cookies, whatever. So it's frightening, in some ways, that it will be easier than ever for the forces of evil to spread misinformation that really targets people in their vulnerabilities. And so that's an area where we're going to be doing research in the next couple of years.

Nikita Roy  18:25  
And as you were saying, there's so much of data that platforms are able to collect and people. And now with this introduction of generative AI coming into the mix, we are in the situation where a lot of bad actors can automate misinformation and prey upon vulnerable populations. How do you see newsrooms? And what's the role that journalism is going to play in helping people deal with this surge of bad actors?

Bill Adair  18:51  
So I think newsrooms roles will, I think they'll continue to do a lot of the same things they've been doing the work of tracking down who the the people are behind, misinformation, is still going to be a human enterprise. I don't think that generative AI is going to be able to figure out who the bad guys are behind the devious forms of generative AI. So I think that's still going to be a task for the best investigative reporters. I also think political fact checking will still require human fact checkers to create the core fact checks, sort of the individual unit fact checks that can then be drawn from for other for other uses. You go back to when I created PolitiFact in 2007. I envisioned even back then, and this is I shouldn't take all the credit for this. This was also very much a function of my collaborator, Matt Wait, who's now at the University of Nebraska, that we Created Politifact, not just as journalism, but as data. And so each factcheck is an entry in a database, this politician made that claim and got that rating, you know, half true or false or pants on fire. And so that structure of our journalism was quite innovative in 2007, it's actually still in HIV in 2023. And so that unit of journalism, I think, will still matter, and will still be needed to power, a lot of things in this new age of AI. So that's another thing that newsrooms will do, I think newsrooms will still have to write that original fact check. It will then be cloned. You know, for me, this conjures the image of those robots in Star Wars Episode one or two, whichever it was those guys that have the guns and, you know, get blown away. But this is I think you need, you need a kind of a root piece of journalism that will be created by a human.

Nikita Roy  21:11  
And so far, what would you say has really been that milestone in automated fact checking? What's the state we are in right now? And where are we headed?

Bill Adair  21:23  
So I think one key has been the adoption of a schema called claim review. So this is a standard that most of the fact checkers in the world, particularly most of the big ones use to tag their fact checks. So they can be more readily identified by Google and other search engines. And that makes automated fact checking possible in lots of ways. Because the various kinds of automation, whether it's an app like squash, or just a bot on Twitter, or anything that someone might invent, can draw from a database of claim review entries to find the root fact checks. And so So I think that has advanced the plot a lot. And I'm really proud of that we helped develop it here at Duke help develop claim review along with Google. And Google has been very generous, I think with that hasn't, you know, hasn't considered it proprietary, the, it's an open standard with schema data work. And so I think that makes automated factchecking a lot more available. I do think the big biggest challenge in automated fact checking, and in really all journalism continues to be the partisan divide. In the United States, there's just such a trust problem that really breaks along partisan lines, because for decades, people on the right have been hearing that they can't trust the news media. And so that creates a real serious issue. I think when journalists that are truly unbiased, or at least as unbiased as you could hope for do good fact checking journalism, it's rejected by people on the right, simply because it's coming from journalists. And and that, I think, is a serious, serious problem that we haven't figured out an answer to.

Nikita Roy  23:27  
Also, since you are a professor at Duke, now, I want to quickly touch upon journalism schools in the age of generative AI, and get your thoughts on, what do you think are the key skills and knowledge that journalism students need to be knowing in order to be well prepared for a future with AI?

Bill Adair  23:48  
What's funny, you know, I teach, I teach a variety of different kinds of courses. I still think like, the most important course is news writing and reporting. Like, you know, I think students like to learn how to how to write, and how to go out and interview people and how to write different kinds of stories. And so I don't know that we need to change how we teach a lot, the basic skills of journalism, reporting, going out and talking to people hearing their stories, and then writing them in a compelling way. Whether it's a narrative or a fact, check. I think that's still the basic thing that is needed. And so I don't know that journalism, education has to change an awful lot. I mean, I think we still want to arm them with things like to understand things in the digital world, like search engine optimization, and social media. And but the most important thing to me is, can you do interviews and can you write?

Nikita Roy  24:48  
Yeah, are you able to bring in that added value of what it means to have a human in the loop with AI? That's something that's going to be important now, and I just want to wrap things up by hearing your thoughts on how do you see the future of fact checking, evolving, we've been making a lot of strides towards automated fact checking. And now with AI, where are we headed?

Bill Adair  25:12  
So I'm optimistic, I really do think AI presents lots of opportunities to scale fact checking in new ways, and reverse some of these market forces that have been so difficult for journalists. And I do think it's early enough that we, the journalists can learn how to use these new technologies and artists them. So I'm hopeful, I mean, I can see a world in which we still have a good force of human journalists that are doing the important work of political factchecking. And that it's being amplified by an impressive group of bots that, take that work in, clone it and use it in places that it never would have been published before. So I'm pretty optimistic about it. I also think we'll have moments of awakening where we'll realize what the forces of evil are doing with this technology. But I think we'll we'll be able to respond to that, you know, there was a moment, we shouldn't forget this a moment, maybe 10 years ago, when we thought we would never conquer spam, the terrible junk email that we used to get all the time, that would just clog our email inbox. And now, if you think about your inbox, there's a lot of stuff in there, but it's because you subscribe to it, you know, it's not so much spam, because spam filters gotten really good. And to a large extent, we have won the war against spam. And that's because Google and Microsoft and others put some good engineers on that problem. And they figured out how to identify spam. And, you know, and they weeded it out of the system. And so I think, likewise, it'll take us a little bit of time, but we'll identify the people who are using generative AI to create bad stuff. And there'll be moments where we're like, Oh, we got fooled by this or that. And you know, that may be the Pope and a puffy white jacket, or that may be a bad photo of Trump being arrested by a cop with six fingers. But I think that there will be, but we'll figure it out. And that's what we do. And I think people will will eventually be better informed because of this moment.

Nikita Roy  27:42  
That's a really hopeful future, you're painting for us. And that all the concern that's been in the industry. So this has been a great conversation. And you think that even though generative AI and all of this has the potential for a lot of harm, we would be more equipped to kind of like deal with it and the resources that this would bring about? Yeah, I mean,

Bill Adair  28:03  
what's the alternative, you know, like, just give up and die, you know, like, I mean, I think a lot of my colleagues like to worry about stuff and get depressed. And, you know, instead, I'm about, let's figure out what's wrong and fix it. And let's take this new technology and harness it and use it to fight the bad guys. So I'm up for that.

Nikita Roy  28:25  
Well, it's reassuring to hear that we are working towards using this technology now to fight the bad guys. And this has been really great and optimistic discussion about the future with generative AI, though you've kind of put to rest a lot of this concerns I brought up in the Big Bang. So it's great to have you on the show. And thank you so much for doing this.

Bill Adair  28:52  
You bet. Happy to do.

Nikita Roy  28:54  
That was Pulitzer Prize winning journalist Bill Adair, the creator of Politifact, co founder of The International fact checking network, and the night Professor of Journalism and Public Policy at Duke University. Subscribe to newsroom robots on Apple podcasts, Spotify, or wherever you get your podcast. This episode was made possible thanks for the spot ground from The Hobbit innovation labs. I'm Nikita Roy and this is newsroom robots.

"
newsroom_robots,5,"Wed, 10 May 2023 14:00:21 GMT",Tim O’Rourke: How Hearst Newspapers DevHub Builds Tools to Empower Their Local Newsrooms,https://www.newsroomrobots.com/episodes/how-hearst-newspapers-devhub-builds-tools-to-empower-their-local-newsrooms-hxGMIIhS,"<p>In this episode, Tim O'Rourke, the Vice President for Content Strategy at Hearst Newspapers, shares his experience leading the group's <a href=""https://www.sfchronicle.com/projects/about-the-devhub-hearst-newspapers/"" target=""_blank"">DevHub</a> editorial engineering and content strategy team that partners with HNP's local newsrooms on innovative projects and growth strategies. Hearst Newspapers produces 24 daily and 52 weekly publications across the United States. </p><p>Previously, Tim was the director of product and strategy for The San Francisco Chronicle. He supervised the newsroom's product, website+app, multimedia, and audio staff; directed data-driven coverage; and oversaw the development of interactive projects and journalistic tools for Hearst Newspapers. His former roles include The Chronicle's managing editor, digital; assistant managing editor, and the executive producer of SFChronicle.com. He came to The Chronicle as the senior news editor, responsible for the print front page and news operations. He also served as the night-breaking news editor and the department head for the copy and wire desks. He developed the yearlong Chronicle Covers front-page archive project and wrote the occasional craft beer story for the Food+Wine department.</p><p>Before joining The Chronicle in 2013, O'Rourke worked as an editor and writer at the San Jose Mercury News, Contra Costa Times, Santa Barbara News-Press, Hartford Courant, and Diablo Magazine.</p><p>Join us as Tim delves into how Hearst is building their AI strategy in the age of generative AI, looking at the impact of AI-driven chatbots, the opportunities and hurdles in creating AI-powered tools, and Hearst's foray into VR and news gamification.</p><p><br /> </p><br /><hr /><p style=""color: grey; font-size: 0.75em;""> Hosted on Acast. See <a href=""https://acast.com/privacy"" rel=""noopener noreferrer"" style=""color: grey;"" target=""_blank"">acast.com/privacy</a> for more information.</p>","Nikita Roy  0:02  
This is newsroom robots, the Podcast where we explore the intersection of artificial intelligence and the news industry. I'm Nikita Roy, a data scientist, media entrepreneur, and one of the many founders currently building their ventures at the Harvard innovation labs on the newsroom robots. I'm excited to bring you insightful conversations with industry experts about how AI is impacting the way we do journalism. I'm excited to have Tim on work as our guest. Tim is the vice president of Content Strategy at Horse newspapers. He leads the group's dev hub editorial engineering and content strategy team that partners with local newsrooms across the brand on innovative projects and growth strategies. Previously, Jim was the director of product and strategy for the San Francisco Chronicle, where he supervised the newsrooms product staff director data driven coverage and oversaw the development of interactive projects and journalist tools for Hearst Newspapers. In our conversation today, we discuss team's journey in establishing the dev hub team, we look at his team's collaborative process with newsrooms to develop tools striking a balance between caution and innovation, and discuss what generative AI could mean to the future of local journalism.

Hi, Tim, welcome to newsroom robots. I'm really excited today to learn more about the work you're doing at Hearst and how you're approaching AI. Great to be here. Great to meet you. So Tim, I've been keeping an eye on the exciting work you and the DevHub team at Hearst Newspapers have been doing. And you've really built this cross disciplinary team that's making a significant impact on local journalism across the various publications under the host brand. So to kick off today's conversation, I'd love to hear more about your personal journey in establishing and leading that DevHub. Team. And could you tell us more about how your team collaborates with the different publications to develop innovative news tools?

Tim O'Rourke  2:13  
Yeah, so it's been a long road, a really fulfilling one. And I think our whole deal is we're local, we're proud of it. You know, we focus on local we we know our lane is and we really want to just serve our readers in our local communities. I was in the San Francisco Chronicle newsroom for nearly a decade and did a bunch of different jobs. There were one point I was the managing editor for digital and one of my teams was a small band of really, really smart, awesome developers. And they were doing such amazing work that people started taking notice of what they were doing. And I kind of just helped clear a path for them so that they could perform. And, you know, the the work in SF was really successful. And Hearst, to its credit is continuously invested in dev and data journalism. And so they allowed us to grow. And part of that was can we expand and build reader tools, projects, templates, newsroom tools for the other Hearst newspaper markets in Houston, San Antonio, Connecticut, New York and other places. So that was about 2020. Right when the pandemic was taking hold, and we, you know, we kind of we left the SF chronicle newsroom, because everybody was leaving everywhere, right, and we were going back back home, and that kind of put everybody on the same plane. And we were able to figure out how to work with these other newsrooms where we were located. And over the course of the past couple years, we've gone from being an embedded San Francisco Chronicle team that served other a&p, Hearst markets to one that is officially part of the HMP Hurst, a central team, that mandate is to serve every market, including San Francisco. So we've been able to grow the team each year through investments from Hearst, and the results have really been successful. And we we keep bringing in really sharp people to do awesome work in a lot of different areas. And the whole thing is built on collaboration with our, with our local leaders in markets,

Nikita Roy  4:01  
and how does your entire DevOps team really integrate with the rest of the content strategy for the Publications at Hearst to help them power the journalism that they do?

Tim O'Rourke  4:13  
Yeah, so I'll give a quick kind of structure framework without getting too in the weeds here. But you know, what half of the DevOps is editorial engineering, visual storytelling, you know, development, interactivity, you know, interactive experiences, data driven journalism, that side of the game. And then the other is audience development and more content strategy, newsroom transformation, you know, tactical applications for local journalism. So those are two totally different approaches, the dev hub team, the traditional dev up that does the engineering and, and visual storytelling. You know, they work in collaboration with different folks in each of the markets. And you know, sometimes it's partner projects where we're all coming together and we're, you know, building stuff you know, piece by piece together, say with graphics journalists, or for photographers or producers or editors. And then sometimes we're creating, you know, templates or tools that the newsrooms then use to create their own projects. So we keep up a catalogue of about 30 different templates that are interactive in nature. And, and, you know, it could be, you know, interactive map based pages, or it could be, you know, visual essay with, you know, screen filling images are all kinds of different stuff. And we maintain those, we improve upon them. And we work with the markets as they publish projects through that framework. And we also work with them on on one off projects. On the audience development. And content strategy side, it's more working with the editors in chief working with the managing editor is figuring out what strategies are working best in some markets, maybe it's different, maybe it's the same, we don't try to cookie cutter it or top down it, and really figuring out what's the best solution to help grow local journalism in each of our markets. And the markets are much different. And I think a big learning for us over the past few years has been to embrace that and say, you know, what works in San Francisco might only work in San Francisco, but also to be on the lookout for, for what things do travel across the different markets.

Nikita Roy  6:03  
And I'm trying to understand more on like the process in which you're able to come up with these tools. Is that a lot of direction coming from the newsrooms to the editorial engineering teams? Or is it part of the larger strategy that the dev hub team is working on to empower all of the local journalists to do their work and enhance it with the kind of automation tools that they're building?

Tim O'Rourke  6:26  
Yeah, so we, we stress collaboration, so that everybody's sick of hearing the word collaboration, but it's so true, I mean, if you know, we can build the greatest thing in the world. And if the newsrooms not bought in, that will work. And you know, we're also not a service desk. So we really preach that we want ideas to flow both ways. And some of the best ideas we've ever had came straight from the newsroom, maybe from a reporter, maybe from an editor, photographer, producer, graphics, journalist, whoever, and then my team, also they develop their own projects, and then they work with the local markets to make sure that they're being localized properly. And, you know, it's really how can we do the highest quality journalism and most efficient, smart way possible, and try not to get hung up on whose ideas who's and who's the ultimate owner, because the bottom line is the ultimate owners, the readers, and we want to build things that the readers, you know, really appreciate and interact with and keep coming back to our our websites for

Nikita Roy  7:18  
so you're stressing upon the word collaboration. And I'm really interested to know more about kind of how you're getting buy in from newsrooms, and so many different people, especially with a lot of evolution going on with the technology right now. How are you able to kind of help them understand the importance of it and get them to change the way that they've been approaching the way they do journalism?

Tim O'Rourke  7:43  
Yeah, well, again, I think we number one, we came from a local newsroom. So we know that most of the time the ideas coming from them are the ones that are going to work the best. So, you know, we learned from them just like they might learn from us. I think it's definitely harder. Being a distributed hybrid team, you know, we're in different offices, we have people in in Texas, we have, you know, I'm in San Francisco, I go into the San Francisco newsroom. Still, there's people in the Hearst Tower in New York City. And it I think we just have to over communicate, and we meet with the markets multiple times, every week, we have people who are just dedicated to project managing to work with the managing editors and the producers to make sure that the work is being done the right way. And everybody's looped in properly. You know, each market is different, there's different, you know, ideas, different players, different types of topics that really resonate in the different markets. So we really, you know, we make a purpose to really talk to everybody as much as possible to do projects that we know will work within the individual markets. So we're not spinning our wheels, you know, just because maybe it was a good idea one time, and really to listen, you know, we again, the if we're not listening to what the markets need, what topics they want to cover the things that they want to do, that anything that we do, it's just wasted time, right? We need, we need the engagement, it's up to the local markets to make the decisions on how they're going to promote things, what they're going to focus on what the best topics are in the news right now. And we have to do that dance with them. And that's what we've been most successful is when we need them.

Nikita Roy  9:13  
Yeah. And I was seeing a number of remarkable projects that the teams built out like the Texas Bill tracker that really exemplifies accountability journalism to help readers track bills throughout the legislative process. And then various data driven projects like the California Air Quality map and neighborhood walkability map and all of these reader tools that just harnesses data, and presents them to readers in a very accessible way. So I kind of want to hear more about how you are building out these projects and getting them from A to Z from development and into the readers hands.

Tim O'Rourke  9:51  
So yeah, we do such a wide variety of projects. It's hard to speak to it all like even at a high level because it's like you know the difference between something That's, that's a photo driven, you know, best kind of local photojournalism in the world is happening in San Francisco and the process that a project that puts that at the front, you know that there's a green mat and like a deep Data Dive using d3 That, you know, puts forward these really was being interactive graphics that tell a really complex story is simply like it just two different tracks. But I would say that, you know, focusing on visual journalism, right, and it's not, because that's the end all be all of all journalism, it's just a table leg of what we're trying to do. But there's a lot of room there for innovation, a lot of room for interactivity. So we look at those types of stories, what are the stories that could really benefit the reader, you know, whether on the desktop screen or on their phone, or wherever, you know, a visual component, or visual storytelling could really help them understand what's going on in their community. So we kind of start there. And you know, sometimes we work with the data teams in the markets. And so that's going to have be a certain kind of project. And it's going to be obviously data as your primary source, very data forward, very data visualization heavy, you know, oftentimes through d3 framework and interactive graphics, or static graphics that tell complex story, simply. And sometimes it's a it's a Reader tool that's driven by data, but isn't about a moment in time analysis, it's about how can we provide data to our readers in real time at a local level that the search engines or national competitors aren't going to be able to do? So that's that stuff, like you said, the air quality tracker, you know, where we were the first publication to publish the California COVID Tracker, at the beginning of the pandemic, we started the fire tracker, which now you can get on Google and everywhere else. And you know, those were about how can we, we don't want to turn it into a, you know, a 40 inch story with the photos, I mean, we want to put a tool out there that takes data that it's hard for readers to get out online picking and searching. And we want to put it right in front of them in the easiest way that they can understand so that they can make decisions that you know, could be just to make their day a little bit easier. Or it could be a decision that helps save lives. And again, that's one track, right. And sometimes it's a very, you know, a very high touch project. It's 25,000 words, and but it could really benefit from a visualization or an interactive component and the dev up or the local design, graphics, and visual teams will get in there. And they'll develop something that that is really additive to the project.

Nikita Roy  12:22  
So I want to shift focus into delving into the whole buzz of generative AI and this entire experimental phase that everyone is in right now. I want to learn more about how you're thinking about AI strategy with generative AI coming into the mix. And what role do you see it playing in the future of local journalism?

Tim O'Rourke  12:45  
Yeah, I mean, it's such a big topic, as you know, better than I do. You know, for us, it's, it's really a balance and preach balance. And the leadership here preaches balance. And, you know, again, my lane is really just editorial, and you know, where editorial meets development and content strategy. And I think, in that lane, you know, we're really saying how can we balance caution and innovation, right, because our brands have these reputations, and everything's built on our our ethics and the way that we've done our journalism for decades and decades and decades. And, you know, we don't want to, you know, shoot that away because of Russian and experiment out to market. That said, I mean, it's so exciting. And there's a such opportunity there that we are embracing it, and we don't have the biggest team, we're, again, we're in local news. And so we need to make some smart bets. So we're really at the beginning of this, again, because it's such a broad topic, we're really focusing on what are the ways that we can harness this operationally to improve our journalism, you know, and it's, that's really right now, for at least the editorial side, again, lots of folks across the company, lots of folks across the division are working on this. It's not just sitting only on my team by any stretch for my team and what we oversee with the newsrooms, it's really about how can we use this game changing technology? I mean, transformational whatever that it is, you want to throw on it, right? How can we harness that in some way to improve our journalism at the local level?

Nikita Roy  14:08  
And what are like the top key concerns that you're having and assessing right now with generative AI before like pushing that into production?

Tim O'Rourke  14:18  
I think, you know, from our perspective, editorially, it would just be, we don't want to pretend that this is a replacement for journalists, we don't want to pretend that, you know, we can just quickly throw something up there that replaces the stories that were painstakingly reporting. You know, we don't want to we want human eyes on anything that goes under our brand. Now, there's other applications where that's not necessary, right, but for creating, you know, high touch local, quote, unquote, artisanal journalism, like we want a human involved at every step and we still see tons of opportunity with that rule in place.

Nikita Roy  14:56  
And talking about editorial I really want to touch upon the consumer And in the industry right now with the rise of chatbots as the means of delivering content, and particularly with like aI driven search chatbots potentially impacting traffic that we get from search engines. And just given the number of publications under the Hearst brand, I'd like to hear your thoughts on this matter, like how concerned are you about the potential effects of such traffic? And how are you thinking about approaching any potential decline while these AI power technologies are being embraced?

Tim O'Rourke  15:31  
Yeah, I mean, it's a great question. And I mean, I think the the threats already here, and it's something that's going to affect anyone who's bidding on, you know, search traffic for, for audience growth. And I don't think it eradicate the need to write really smart content that has the best kind of search tactics in it, because that often means that you're putting your best foot forward across all the platforms, really, you know, our main focus is doing, again, high quality, like local journalism for, you know, subscriber sites, not just for subscribers, but it's the goal that we have is we want to build our subscriber base so that we can continue to fund the newsroom continue to grow the newsroom and continue to do high quality local journalism. So and that's in that framing, search is super important. Our subscribers are obviously on search, they find us through search, even if they're they have a subscription that allows them to come to us in any way they want. So we still want to have the right tactics in place where our stuff is coming to the top. But at the same time, if you're a local publication, where a lot of your strategy is built on utility from search readers looking for specific key words, like, you know, that's in danger now, and it's time to look for other ways for growth, right? It doesn't mean you abandon search. It doesn't mean you abandon utility content, there's still a huge appetite for that. And there always will be and again, locals that advantage here too, I believe. So you keep doing the work that you believe it. But if the whole strategy is like how many cheap clicks, I can strangle out of search keywords, then you're probably in the wrong side of the business anyway, right now.

Nikita Roy  16:59  
Yeah, exactly. And talking about AI strategy, what are like the key questions you're thinking about in terms of assessing the opportunities, along with the challenges of building out AI tools right now to help power content throughout the publication?

Tim O'Rourke  17:17  
Yeah, I think more early on now, we're ahead of some places. But you know, obviously, the work that's already being done across the world right now is staggering how quickly everyone's pivoting. But for us, it's how can we help one slice of this deck? Again, we're talking about something that could possibly rival mobile phones or the internet, right. So, you know, how could one slice of this tech help us improve local journalism? I mean, that's looking really kind of at a small speck of what's possible overall. And for that, we want to, you know, our whole approach is, you know, again, bouncing, caution and innovation. So first step is how can we create tools for our journalists to make their jobs easier, so that they can continue to do the best local journalism and their bark markets, bar? None. And that's where we're putting our effort to begin with, while still trying to experiment and look for ways where we can do more reader facing stuff, more abstract stuff. So one approach would be, how can we harness the improvements in generative AI to create newsroom tools that our reporters or producers or editors can use every day to save them 510 15 minutes a day. And then if you take that you take a step back the savings that that will get your organization and the overall improvement in the high quality high touch journalism, you know, could be staggering over the course of time, right? I think there's also a huge opportunity for local news organizations, we're pretty lucky we have a lot of really awesome editorial engineers, graphics developers and others who use coding to present local journalism in new, exciting and innovative ways. But not everybody has those options not always been invested in the way we have by Hearst. So the opportunity for this tech to help local newsrooms build things through code or hasten, you know, the time it takes to build something, if you only have a couple of devs on your entire staff. I mean, you could have massive impact, you know, the just in the quality of the storytelling really, really quickly. Right? So we're really excited about that opportunity as well.

Nikita Roy  19:14  
Yeah. And you're also exploring other opportunities with like we are and gamification, I was seeing that on the dev hubs website. And so I kind of just wanted to touch upon those topics. How were you seeing those kind of models as well evolve with the content strategy for a local journalism.

Tim O'Rourke  19:31  
So for the dev hub, one of our main mandates is just to help, you know, spearhead innovation across our group, because when you're doing, you know, best in class, daily news coverage, it's hard to take the time to try something new and experimental and possibly something where you will fall flat on your face. And you know, that happens. And we've, of course, fallen on our face a few times. Right. But you got to try and, you know, I think we're really excited that Hurst has given us the opportunity to to take some some big swings, even if it's a little risky. So that's kind of in our, in our DNA really. And that's why, you know, we had graphics reporter in San Antonio, not even on the DevOps, but just working for the San Antonio Express News. And on his, in his side time, he developed a internal AI driven, you know, news audience tool that we're now going to take across the group, right? He did that on his own, because he felt like he was empowered to innovate and to take risks and to try something that he was interested in that he thought could help other journalists across our network. When it comes to VR 3d, we got a couple of projects in development right now. And we have to balance, you know, helping the newsrooms cover big breaking news in their markets, we have to balance the maintaining and improving the templates that that our newsrooms use, but we also need to make time and for innovation, so we always have a couple of projects that are kind of pushing us forward, you know, and, again, if you're, if you're a big national pub with a huge staff of people who code or interactive journalist or whatever you want to call them, you know, you've always got these things churn and churn and churn. And for us, we really got to try to take the right bets, try to bet on some tech that will really push us forward in the way that we do journalism, the way that we do our storytelling. And, for us, we see tons of opportunity with 3d and letting that kind of take us into like more of a VR experiential thing as the year goes on. And with gamification, you know, obviously, like quizzes is like a real kind of like base entry point. But what's the next step of that, you know, we've had some experimentation in the markets recently, where it's kind of like a choose your own adventure type interactive experience. And it's not that that's that in and of itself is going to, you know, define our journalism, but it is something that that helps readers see that we're always innovating. We're always trying to, you know, present stories in new and exciting ways. And, you know, when you come down to the local level, you know, the, if we're doing if we're not doing that, then then who is right, so we really make like to try to keep pushing that both on my team, and then, you know, the markets themselves are pushing themselves and doing a really great job as well,

Nikita Roy  21:55  
with all of these different experimentations going on and projects at the DevOps team. I really want to hear more about your personal journey in terms of like leading the team, and what challenges have you kind of had to overcome with building out these projects? And now with AI coming into the realm as well? How are you going to be looking at those obstacles in your newsroom?

Tim O'Rourke  22:18  
Yeah, that's great question. And I think, number one, it's never boring, right? Like Aaron, journalism, local tourism, national journalism, wherever, every day is different. It's never boring. It's why I got into this. That's why I'm still here, you know, and it's what makes it exciting. It also can make it tough, right? Because just when you think you're getting something figured out, then boom, you know, something like GPT, three comes out in November, and everything changes, right? You think you've got election, you know, infrastructure figured out and boom, something changes in, you know, a national pub does something and you're like, wow, how do we not think of that? So then you got a pivot for the next election, you know, something changes boom, in the, you know, news happens in the market, and the projects you're working on, are not the most important thing anymore, because news app and well, real life happened and it's time to adjust. So that's always our thing is how do you keep these kinds of bigger things going? How do you keep innovation going? When our first priority across the board for everybody in this organization is to provide the best news coverage bar, not in our in our local markets, right? For me personally, it's, it's more with all the ideas and all the possibilities out there, how do I just keep making things happen. And luckily, I got a brilliant team that, you know, can juggle and innovate and do really high in journalism, you know, without having to reinvent the wheel every time and being surrounded by that many people makes my job, pretty easy. But again, it's it's a juggling act. And that's part of the fun, but it's also the biggest challenge.

Nikita Roy  23:42  
And kind of drawing upon your entire experience thus far, I really want to learn more about some key insights if you've gained and recommendations you'd have for other newsrooms, that are right now trying to establish all of these AI tools and harness upon these technologies. What kind of lessons have you learned, that you think would be valuable for other newsrooms? Who are looking at AI right now?

Tim O'Rourke  24:06  
Yeah, I think first of all, I just break it down to local because, you know, I think the if you've got a pretty big staff, like a national club or whatnot, I'm sure they already have complete teams dedicated to this, not to mention the reporting going on in the sides to really inform everybody. For us. You know, it's the advice I would say is like, just let some people start to nerd out on this stuff. Again, the thing, the tool that's the farthest along that we're developing, we got a few things coming out soon. But the this tool that we're going to be rolling out across all of our newsrooms, it started with one graphics reporter in San Antonio because he was frustrated with some of the kind of repetitive tasks that he had to do in his job. And he was smart and he he developed the beginnings of a tool that then had been fleshed out as the tech is improved. And now it's going to be something that saves everybody across our entire newsroom network time every day. His boss at the time, could have gotten The way that said no, we need you to do your exact job every you know, instead she said look like yeah, definitely do that on the side still create the stuff we needed to create. But she was smart enough that a good enough manager to say this is cool. Keep going. You know. And I think that's hard to do in the news business and harder to do and local news environment where we're all overworked, everybody's overtaxed and there's not enough resources, you know, anywhere, right? And being able to have the foresight to say, we got to experiment, we got to try this out, we got to let this guy go. That's the biggest thing. And then too, I think you know, what I'm seeing here. Again, Hearst is pretty unique. They've funded these types of innovation teams for years and years, and we've got a really nice runway, and it's allows us to do things and not everybody can do. But we've got, you know, they immediately kind of said, look, let's bring that guy on the depths of so his impact can be can have a bigger impact across the network. And there's also people and other teams, right. Like, it's not just limited to like one team squirreled away on the side that's in charge of innovation, like we got our thing going on the DevOps, but then product, the product team is looking at, you know, AI in a totally different way. But and really exciting stuff happening over there. And, you know, marketing is looking at how it can help them improve their business and the finance team. And you know, everybody's kind of like, how does this apply to us? And everybody's kind of got that experimental innovation mindset to where they're looking through their lens about the best way that this tech can can help them do their jobs. And, you know, nobody's saying no, no, everything has to go through one, two person team or one person, one leader, you know, we want to have organizational wide rules, of course, right. But we don't want to limit the ability for people to figure this thing out.

Nikita Roy  26:44  
So Tim, just to wrap things up, I really want to understand more about what are you most excited about AI, and the future of local journalism, and how you kind of envision the future of the news industry evolving, especially for local journalism. With the rise of generative AI?

Tim O'Rourke  27:02  
I think first off, possibilities are endless. And I couldn't even imagine saying, oh, three years from now, like, who knows, right, that it's gonna be so transformational, that couldn't even predict. But I do think local, we have some advantages, as long as we stick to our guns and really focus on doing the highest quality local journalism in the market. And, you know, we say that ad nauseam, but we we mean it, and that's where we've seen success over the over the years. But I think there's gonna be an advantage for local in the short term, I think there's an advantage when it comes to creating the data driven tools and, you know, reader facing and newsroom facing that we've been able to develop, because you can't just take those out of the box. And then again, we throw around this like artisanal term that our product lead uses, and I love it, but there will be an opportunity for that kind of work, the high touch, really beautifully written narrative journalism, really striking photojournalism, you know, the really sharp data driven approaches and analyses to local issues, those won't be replicated to least in the in the short term, right. And so we want to keep pushing on those and putting those as our best foot forward. And then also, at least right now, there is an ability to really continue to own live local news coverage that, you know, has been our kind of a number one priority for years and years, and we want to continue to focus on on that and our newsroom. So. So those are all places where I think we we got opportunity where it's going again, I think, if we can democratize interactivity, coding experiential journalism, through this technology, then that can, you know, not just here, HMP in hers, but you know, across local journalism that can create enormous opportunities, and much better journalism overall. And I'm excited to see where that goes. The ability to really enhance an efficient size people's time, right? Like, if we can, we're not able to cover every board meeting, we're not able to cover every city council meeting that we should, you know, and in some places, some news deserts, none of its being covered. What if this technology can allow, you know, our readers, our communities to have better information, better insights into what's going on around him in the halls of power? And as decisions are being made, and money's being spent? I mean, that's, that's really exciting to think about. And I also think that, you know, if we just keep our ethics and ideals in line and understand that our strength is in our reputations and the approach that we have to news, then that will win out in the end. Yeah,

Nikita Roy  29:25  
exactly. Really focusing on that quality journalism. And that's kind of like what I'm taking away that the power of transformation that's possible for local journalism in the age of AI is exciting. It's a very exciting future that you're painting for us there, Tim, and thank you so much for being on the newsroom robots podcast. This has been such an exciting conversation to hear all about what horse newspapers is up to.

Tim O'Rourke  29:50  
It's great to meet you and thanks for having me.

Nikita Roy  29:54  
That was Tim O'Rourke, the Vice President of Content Strategy at Hearst Newspapers. If you'd like Do you hear on the podcast? Please subscribe rate and review the show on Apple podcasts, Spotify, or wherever you get your podcast. This podcast was made possible thanks to a spa grant from the Harvard innovation labs. I'm Nikita Roy, and thank you for listening to newsroom robots.

"
newsroom_robots,4,"Wed, 03 May 2023 07:30:00 GMT",Charlie Beckett: Fostering AI Literacy in Newsrooms and Navigating the Risks of Generative AI,https://www.newsroomrobots.com/episodes/charlie-beckett-fostering-ai-literacy-in-newsrooms-and-navigating-the-risks-of-generative-ai-3WfY5pb2,"<p>In this episode, we explore the crucial considerations when developing an AI strategy and the potential risks of generative AI in the newsroom with Charlie Beckett, Director of the JournalismAI project at Polis – the international journalism think tank at the London School of Economics and Political Science(LSE). He is also a professor at LSE’s Department of Media and Communications. He was previously the director of LSE's Truth, Trust, and Technology Commission, which reported on the misinformation crisis in 2018. </p><p>Charlie is the author of SuperMedia: Saving Journalism So It Can Save The World (Blackwell, 2008) and WikiLeaks: News In The Networked Era (Polity, 2012).</p><p>Before LSE, Charlie was an award-winning journalist at LWT, BBC, and ITN, beginning his career at the South London Press and later a program editor at Channel 4 News.</p><p>JournalismAI, a project of Polis supported by the Google News Initiative, is a global initiative committed to helping news organizations use artificial intelligence responsibly. </p><p>By fostering innovation and capacity-building, JournalismAI aims to make the potential of AI more accessible and to address inequalities in the global news media related to AI. Through various programs, JournalismAI unites journalists and media professionals to discuss and explore AI, encouraging debates on AI's editorial, ethical, and financial implications on journalism.</p><p>Join us as Charlie provides his valuable insights on the significance of AI literacy for journalists, the crucial questions to consider when developing an AI strategy for news organizations, the risks and potential limitations of generative AI, and the influence of AI-powered chatbots on search engine traffic.</p><p>Be a part of the conversation on AI in journalism! Send us your questions <a href=""https://docs.google.com/forms/d/1NfOf6umHO-ESYDWZKCKfdp10fSsqnCrDMXjL7DLNehg/edit#response=ACYDBNhRTwLMoF5elD80B4zR28Isqaqus2lIKHR_RO-HU_g1Vzm6IInXuVUGHZfz9QPnKw0"">here.</a></p><p>Here’s a list of helpful resources concerning today’s episode:</p><ol><li><a href=""https://www.lse.ac.uk/media-and-communications/polis/JournalismAI/Case-studies"">JournalismAI Case Studies</a></li><li><a href=""https://www.lse.ac.uk/media-and-communications/polis/JournalismAI/Starter-Pack"">JournalismAI Starter Pack </a></li><li><a href=""https://www.journalismaidiscovery.com/"">JournalismAI Discovery Course</a> (Applications currently open)</li><li><a href=""https://drive.google.com/file/d/1utmAMCmd4rfJHrUfLLfSJ-clpFTjyef1/view"">JournalismAI Survey Report</a> (2019)</li><li><a href=""https://airtable.com/shrQeIsvzGoTbdp7b/tblvwDhL4X23V1pTp/viwN8zctay9H2N0ir?blocks=hide"">Partnership on AI's Database of AI Tools for Local Newsroom </a></li></ol><br /><hr /><p style=""color: grey; font-size: 0.75em;""> Hosted on Acast. See <a href=""https://acast.com/privacy"" rel=""noopener noreferrer"" style=""color: grey;"" target=""_blank"">acast.com/privacy</a> for more information.</p>","Nikita Roy  0:02  
This is newsroom robots, the Podcast where we explore the intersection of artificial intelligence and the news industry. I'm Nikita Roy, a data scientist, media entrepreneur, and one of the many founders currently building their ventures at the Harvard innovation labs on the newsroom robots. I'm excited to bring you insightful conversations with industry experts about how AI is impacting the way we do journalism.

My guest today is Charlie Beckett. He's the Founding Director of Policy and International Journalism think tank at the London School of Economics, where he's also a professor in the Department of media and communications. Currently, he's leading the policy journalism and AI project. He was also the director of LSCs should trust technology Commission, which reported on the misinformation crisis in 2018. Before LSC, Charley was an award winning journalist at LWT BBC in ITN beginning his career at the South London press, and later, a program editor at Channel Four News. In today's episode, we discuss Charlie's experience researching AI in journalism over the past five years, and how he's observed the adoption and evolution of AI in the field. We also discuss the importance of AI literacy for everyone in the newsroom, and how journalists can stay ahead in this ever evolving world of AI.

Hi, Charlie, welcome to newsroom robots. I'm really excited to have you on the podcast today.

charlie beckett  1:35  
It's very nice to be here. Thank you,

Nikita Roy  1:37  
Charlie, I must start off by saying that I've been a huge fan of the work being done at journalism AI, is really helping advance AI literacy in the news industry, with I remember the journalism AI fellowship that came out last year that brought together newsrooms across the world to innovate products. And earlier this year, I was a huge fan of the journalism AI discovery email course that was launched. And it's really been clear that there's an increasing interest in this space with all of the buzz that has been coming about recently. But you've been in this space, researching the use of AI in journalism for over five years now, and really been able to witness a truly fascinating period of growth and innovation. And so I want to start things off by getting your insights and start off by getting your perspectives on how the adoption and evolution of AI in journalism has changed over the years.

charlie beckett  2:35  
Yes, it's a really good question. It's been a fascinating period. For me, I'm quite a an old professor. But before that, before, I've been working at the LSE for 15 years, I was a journalist for 25 years. And in my whole working life, I've seen endless technological change in the news media. And of course, that's accelerated in the last 15 years that I've been running this international journalism Think Tank polis, which has been interested in all sorts of different things. But the key interest is, has been media change. And the you know, we've seen these waves of media change recently, you know, about 20 odd years ago, we all went online, because somebody invented the internet in the world wide web. And then we had social media coming along more recently, but that's become part of the fabric of our world. And in a way I see these collection of technologies, you know, art that we put under the umbrella of artificial intelligence as the next kind of wave. Some of them have been around for quite some time. If you think that it's machine learning it's data. Well, that's not new. What is new, I think, is these programs where the technology can do the tasks, like a human, you know, is taking over much human journalistic labor. And when we started this project five years ago, when we started it with a global survey, because we're totally International, we wanted to see what was going on? And the answer was some really interesting stuff, but very little. And there was huge kind of disparities between different media organizations, and of course, different countries, because this was new technology, and it was only just starting to have an impact in journalism. So it's been very exciting. As you say, we've built all sorts of programs and projects and resources and activities that we can talk about perhaps, and then bang this year to have my god suddenly, you know, everyone's been very enthusiastic. I've been, you know, fascinated, but then today, it's been a kind of firework show of publicity has no the last since perhaps November, because of what we call generative AI. You know, all that chat GDP, my journey, Dally, all that stuff, which in many ways has been a spectacular PR boost for AI in all fields, not a journalism course. But I think the key to it has been everyone can now try it. We can all go on to track GDP slamming a prompt and see what happens. So I think that's been the game

You changing effects of this last phase? Yeah. And as you were saying, AI has become more accessible. But also at the same time, I'm curious to get your thoughts on how important is it for everyone in the newsroom to be aI literate, or at least knowledgeable about AI and its applications? Because predominantly in the newsrooms, I feel like it's been the product and tech teams and executives thinking about AI strategy. But now should all journalists be like, need to be familiar with AI tools and think about how they can incorporate this into their work? Yeah, I mean, just look at what happened in the past. You know, I do remember journalists telling me when the internet came along, well, I'm not gonna bother with it. And I remember when, when the social media came along, people said, well, it's nothing to do with me, you know, and the lesson was, well, it will be partly because you are going to be using it. Secondly, because your news organization is going to be using it. And thirdly, because the world that you're going to be reporting on, is increasingly going to be driven by these technologies, and by those tech companies. So whether you're reporting on sport, health, security, it pays to know something about these technologies. And that's very much the way we saw it, you can see right, that it you don't leave this to the it, people don't leave this to the product development team, you need to inform the process, especially you know, if you have take pride in your journalism, then this is for you, partly because it could make your journalism better. But you want to make sure that the other things you appreciate about your news organization are enhanced, not diminished by these technologies. And when I'm talking to other journalists, right now, about AI, one of the biggest concerns that they're having is, it's all advancing too quickly, like, how do you keep up with what's happening in the industry and AI and all these tools that are coming about and how to use them? It's just all happening too fast? And that's what I'm hearing? So like, how do we keep up, kind of keep on top of all of this and stay ahead and kind of differentiate from what is just a hype? Round? You think I feel I mean, you know, we're not very big Institute, we're a handful of people. And the secret is, firstly, I would say don't panic, you do not need to know everything about everything to do with AI, I think you need to put your toe in the water, I think you need to get some very basic knowledge just to start with. And I would say yes, don't rush in partly because this technology is changing. So quickly. So many products are coming along, so many advances in it, that there's no harm in taking a breath, being a bit cautious of being a bit discriminating about, you know, how you're going to get involved. I mean, you know, the way we structured our resources at the journalism AI project is, we've deliberately made it so that you can come in at a very low level, which is where I started, I haven't gotten much higher, actually. But you can come in to a very low level, and just, you know, what the hell is machine learning, you know, just give me a one hour introductory course, we can do that for you for free. Or we've got this journalism, AI starter pack, where you can go in at one level, or you may have a particular interest is investigative journalism, is it that you're interested in revenue raising, for example. And you can go into different levels and with different interests, and explore and getting connected to all sorts of resources. And this is the key thing. I think networking and collaboration is always good. But especially around this, you know, you mentioned we're doing these fellowships, they're kind of teams of people from different news organizations exploring experimenting with AI and journalism. And they really benefit, there are so many shortcuts you can get by asking somebody else by benefiting from somebody else's experience. And again, that's why on our website, there's tons and tons of reports, guidelines, you know, prototypes from other people who have played around with this stuff, and are continuing to do so. So you can learn from that, too. You don't have to reinvent the wheel every time. So I know, it's daunting, but you know, I think we should concentrate. But it depends on your role, doesn't it? But any journalist can find something to try out to experiment that a kind of low, low level, just to start to get a feel for it in the same way we did. You know, and the whole digital thing came along. You know, we've got used to editing online, for example. And you know, it was great. It was so much better than you know, I remember editing with film and video, and weird stuff like that. And you've got so much better once you learned these these new skills. So I think that is the way to see it don't get hooked up about is it sentient? Or is it a robot, you know, and I'm very cross that you'll be using the robot word in your podcast, but that those things are so many

sleeping, is it going to take your job it might do. If your job is creating really boring, repetitive journalism, then it probably will take your job actually. But generally speaking, we've seen that it's used much more to augment and support the journalist doesn't mean it's gonna be easy. You're gonna have to learn new skills, probably, you might end up having to do more different tasks. You know, you're hoping that that will enable you to focus on the stuff that you are good at as a human journalist.

Nikita Roy  10:31  
I kind of want to delve more into your work over at LSE. And the journalism AI fellowship program. Like I really liked how it was structured with, like one person from a tutorial and one person from tech working together in teams. And do you see that as kind of a model for building AI driven products in the newsroom? Because I'm also like thinking about smaller news publishers who might mainly be focusing on editorial your tech is outsourced. You're just having plugins and a completely off the shelf CMS? How would small news publishers look at implementing AI in their newsroom when they don't really have the resources like bigger publishers to go out and build tech specific to their newsrooms?

charlie beckett  11:17  
Exactly. And I should say that all the sort of programs we created have been kind of organically, they've listened organically. We started off with a survey report, people said, oh, we need some basic courses. So we built those. Then people said, Hang on board about just like you said, What about small newsrooms? We're in a small newsroom. How can you help us with that? So we said, Okay, we're going to build this free online course, directly aimed it's called the AI Academy for small newsrooms. And again, we've been working with incredibly fascinating smaller newsrooms around the world. And they're really interesting, because they're so creative, and often very savvy, around tech, they just don't have the scale. They don't have an r&d department, or a product development team, who can look after all these things. So we're trying to find ways forward for them. And as you say, we got the collaborative fellowship. And again, that arose, not spontaneously but organically. He said one year, three years ago, he said, Does anybody want to collaborate with some other people looking at AI related issues in journalism, and a bunch of people said, Yeah, I want to do this, I want to look at bias correction, or I want to look at automating archive. And we put people together purely by their interests. And that meant you did have millions of people within a news organization. In the editorial reporter who wants to use AI to do an investigation with a data scientist, perhaps who's really fascinated, trying to search through documents, and you put them together, you also put people together from different news organizations in different countries and even different continents. So last year, we had the Guardian newspaper, which is obviously a global international quality news organization, working with a very small and Mexican investigative data investigative journalism organization, tiny on Greenwood. And they both had very complementary skills. And they had a great conversation, and they came up some really interesting ideas. So, you know, that has been absolutely key. I think one of the fascinating things again, I didn't expect that it was an unexpected consequence of this program was the way that it's changing career paths. And the way that it's changing attitudes to production, if you like, an innovation, in the past, journalism has always been very insular, very competitive, independent, isolated, often for very good reasons. But I think the computer science, data science, techy people, they come from a more of an open source collaborative, you know, hackathon type culture, where you try and share great ideas to save time. And it's been a wonderful blend there. And really fascinating looking at some of the careers we did a series on our blog of looking at women in journalism AI, and you think, yeah, we've been attacked, not traditionally easy, but something around journalism and AI, there are some absolutely brilliant people who have not to be men who have created really, really interesting career paths. And yeah, we try and be a space, you know, we try and be a space where people can come perhaps, kind of out of their newsroom. They don't literally come to us in London, all that we do is done remotely and online. You know, it'd be impossible to do such a global project physically, in one space. And again, that's kind of facilitated the collaboration. And we bring in mentors, you know, we do we have partners at universities like Northwestern in the states who work with us. We have other people in the industry, you know, technologists and academics and experts who helped by being tutors and mentors to all these projects. And again, it's it's just a fantastic way to get insights and to accelerate your learning. And then there's that feedback loop because, of course, all this stuff The people are creating and learning feeds back into this network of how many about more than 6000 people at the moment? For example, subscribe to our newsletter. So, and they are incredible when we did you mentioned the discovery email course we launched this January, we had an initial application that was something like over 1000 people from over 100 countries in Africa. Okay, right. This technology in global, you know, we often talked about global we often just mean, America, Europe, and perhaps South Africa or Japan. But yeah, this is really spread.

Nikita Roy  15:35  
Yeah. 100 countries that's AI is everywhere across. It's a global phenomenon.

charlie beckett  15:41  
Yeah, not evenly distributed, as they say, but, but it is, it is everywhere. And we don't have a particular bias. But for example, I have a colleague working in Bangalore, Lakshmi, civet, us who is based in Bangalore. So we're quite strong in India, which you probably fully aware is a hugely important tech play this huge, important journalism place pipe, because you know, they have a government, which doesn't particularly like independent journalism. So we're hoping that AI helps to empower independent journalism,

Nikita Roy  16:11  
then how do you see that connection really happening? Like, how is AI going to be empowering that independent journalism?

charlie beckett  16:18  
Well, simply because we know the pressures on journalism at the moment, in a way, you've got nothing to do with tech. At one level, it's about the business model problem. It's about political constraint, you know, authoritarian regimes around the world, we can see press freedom diminishing everywhere. And that's not that's not good. And then there's a lot of pressure from, you know, corporate pressure, people, and of course, you know, misinformation, and disinformation, and so on. So, in most of the rest of the world, it's not easy being a journalist. So anything we can do with the technology to empower them is useful. I mean, if you think of a huge organization like Bloomberg, this technology is absolutely central to their business. And it makes their production fantastically efficient. But then think about a small organization perhaps has got 1020 people. Now, if this technology can somehow save the labor of one or two people, or suddenly they get 20%, more effective. And that could be the difference between them disappearing, or and then finding the kind of services that are going to sustain them. So we don't, and we we take an ethical stance towards the technology, we're very concerned about the risks that it brings. And we're also very ethically concerned about the idea of good journalism, but we don't we don't dictate what people do with this. And it can be so diverse. It could be to boost it to reduce your subscription, churn something very nitty and gritty, but essential, because if you don't get that revenue, you can't do your journalism. Or it might be something much more ambitious. Like we had one looking last year, looking at trying to automate the claims that politicians make a kind of fact checking, sophisticated fact checking, could you use it to automate that? So there's an incredible range of things you can do.

Nikita Roy  18:08  
And I was looking at a research survey that journalism aI had published back in 2019, where you looked at how newsrooms were using AI, and surveyed how many newsrooms had an AI strategy, which, at that time, it was about a third of the newsrooms surveyed had one. And I think if you survey them today, it's going to be way higher, hopefully. But I've kind of enlightening AI to social media. And as you were saying about the social media with where every newsroom needs to have an AI strategy going in now, or be looking at it at least. So I'm kind of wondering what a successful AI strategy entails? Like, what are the main components that newsroom executives should be paying attention to when they're thinking about the future of their newsrooms with AI in it?

charlie beckett  18:59  
Well, I think every strategy depends on what your goals are. So that's the first thing to say is that there isn't a template that you can just drop on any organization. And that's the way forward that's the route map. Is it different for AI, to, for example, having a strategy about anything you know about your product about your audience, or perhaps about partners, tech and tech and social media? In some ways, it's not, you've got choices, just so with social media, you can have a very detailed set of guidelines and tactics around training and the use of social media. Or you might say, No, we're not going to use it. Our strategy is not to use social media. I mean, NPR just pulled out of Twitter. But if you aren't going to do it, I think what, what difficult about it and I make no bones about this is it's complex. And even small organizations that can have a strategy or strategy doesn't have to tell you a year to make it and I have 20 people on that committee doing it. You just have to think carefully before you act and you try to plan ahead. And I think that's important for these technologies for a number of reasons. But mainly because as I keep saying, it will impact on all the different parts, or it can impact on all the different parts of your news organizations process, it can impact on the news gathering on the news creation, on the news distribution on the revenue gathering, all those different parts can be affected. So if, for example, you know, you decide to automate personalized newsletters, well, you ought to be talking to the marketing department about that as well, because that's one of the services where you're seeking to gain revenue. So you're to be making sure the marketing department talk with the tech department, but also they've told the editorial department, because they're going to be filling those newsletters. So it's quite a holistic process. So we basically say, Look, you know, we've got loads of material online, where we set out kind of simple strategy steps. And the first one is kind of generic, really, which is, get to know that technology first. Don't just blunder in waving wads of dollars, people who come knocking on your door promising, you know, gifts and silver bullets and things. Get yourself acquainted. Think about other people in your organization who need to take responsibility and be involved in this process. However tangentially think about whether you've got people with the skills, who can, you know, have a role in this, and then approach it by thinking, well, what are the problems we're trying to solve? Or what are the opportunities that we're trying to target with these technologies? Am I just chasing this bright, shiny thing? Because I heard a competitor's got it, or I saw it on the news. And it really looks groovy? Or is there actually a role for this in our news organization. And then it's the usual things about making sure that you best to start small, always review what you've been doing, and make sure you've got the humans in the loop, and then review the results further down the line. And generally, you know, these there will be for individual journalists, there'll be kind of plug in and play stuff, you already do it, it probably use transcription services or translation services. For example, as a journalist, you may have personalized your search, so that you're monitoring sources, for example. So the individual I think, the individual journalists, I think that is going to be something they can adopt today, you know, you can start using these things, you probably are using these things already. But the more systemic processes in a newsroom, they need to be more strategically thought out. And, you know, going to the ethical piece, you do need to say, Well, look, this make a choice here. Are we going to use this to create you know, clickbait? Or are we going to use it to try and enhance the quality of what we're doing? And in that sense, it's the same old managerial decisions you always have had, you know, how's it going to affect the quality of our product? What is our product? What's our place in the marketplace itself? And how will this technology fit in, and you can learn so much from as I say, from what other people are doing, there's a very good organization called partnership in AI, that has produced a whole kind of table on their website where you can go and see which organizations have used which tools for which functions. And you know how well they've done really helpful, granular, practical advice. And so there's loads of resources to help you on this journey.

Nikita Roy  23:34  
On that no one kind of curious about how should we be thinking about the risks of using AI when developing the strategies? Like how would you advise someone to kind of strike a balance between adopting AI but still being mindful of its risks and potential limitations?

charlie beckett  23:52  
I think there are kind of three types of risk really. One is the big one, which is around AI in general. And this applies to any industry that decides to use this technology, especially the generative AI, which is it raises all sorts of big questions about discrimination bias within the programs themselves. Are they reliable? Are they you know, are they going to perpetuate injustices, for example, or other floors? We know about, you know, the the racial bias or facial recognition, for example, when it's used in security. So there's that big stuff on that applies to journalism as well. And that's inherent in the technology. And all technologies have some kind of inherent bias and potential risks. Then there's the ones that apply to journalism particularly, which is things like inaccuracy, possible defamation, you know, we've seen with the chat GDP it says crazy things about people because it's so desperately trying to come up with an answer. So we can see there's some very specific risks there are for journalism itself, and then they're the kind of journalism isn't it. industry risks. So for example, risks around transparency, you know, do you understand the technology you're using? What about the relationship you have with the tech companies? Are you confident about issues around IP around copyright, around the datasets that are being used. So those are the more kind of, like strategic structural problems that the industry has to face, especially in relation to the tech companies themselves. So there's loads of risk, and some of them are kind of unprecedented, you know, like this idea of large language models. I think that that, in a sense, is an incremental change in terms of technological breakthrough. But in terms of cumulative effect, and implications that could be, you know, really interesting in Syria. So I think there are definite risks, which is, you know, all the news from other newsrooms I talked to, are looking hard at this, they're experimenting with this, but only the more foolhardy ones are allowing it to create content, for example, in an unfettered way, it's very much a transitional phase. And every month, there's a new iteration is an era of chat GDP, for example. So in that sense, it pays, get across it, get knowledgeable about it, but don't dismiss it just because you managed to make it say something cranky, well, well done, you've probably got it to do something, it's not designed to do very good. Don't use it like that, then great. But don't just give up on it. Because I see 1000 potential uses. And I see even more 1000s of companies, some of them slightly, most of the words said they're a snake oil and involved with some of this, or at least something illusory about some of the products being offered. But I think that will improve. And I'm already hearing about really interesting applications, either built in house, by news organizations, or you know, built by, for example, intermediary startups and so on. And of course, you know, the big tech giants themselves.

Nikita Roy  27:05  
Yeah, I'm talking about tech giants. I want to talk about search engine, specifically, we've kind of had this beneficial relationship with them. So far, at least, where we would have traffic being driven towards publisher websites. But now with like Microsoft banks, chatbot, Google bar, we're kind of seeing chatbots becoming like, the new thing. And it's becoming the future, where like, I was talking to a journalist yesterday, and we were kind of nerding out about how search engines could impact publishers and how they're going to take away traffic from publishers. And he was like, you know, what it instead of going to wire cutter and finding out what would be the best office chairs, I just typed that on Bing. And we actually did that. And it just popped up with the top five best chairs, according to wire cutter and took us directly there it sort of question right then in there. Yeah, it did link how to wire cutter. And like it told me exactly what the wire cutter staff had said about it. These are the features that they really like. And we didn't really feel like we need to go on to wire cutter at that moment, especially for someone who was casually browsing, you got the basic information for us to start out the search right then and there from beings answer. So that really got me thinking and curious to know about how are you seeing? And like, how are newsrooms going to be preparing for that search engine traffic, even though I must say Microsoft and Google have repeatedly said that they are focusing on driving traffic to publishers through those chatbots? But like, how should we be thinking about this?

charlie beckett  28:38  
Yeah, nothing. It's an incredibly crunchy situation. And in a sense, we've been here before, she said, Facebook, push news organizations up their algorithm, then it decided, oh, I don't, we're not interested in news anymore. So suddenly, all those businesses who had built their business on Facebook video, suddenly had their legs kicked away from underneath them, with pretty little warning, to be honest, similar issues, as you know, around Google, you know, and whether they end with the Google snippets, for example, was that taking away, you know, customer attention that could have gone back to the website. So I think there is a huge amount of negotiation to be had here. I think the downside for news is something that we've already been aware of, which is you can't copyright news, in the sense of if a bomb goes off or a president's elected, just because you're reporting on it, doesn't mean you own it. So in that sense, especially with structured news, where it's been atomized into this data that can then be put on to Chapter up, and you can say, well, who got elected, who won the presidential election being there or come up with all the facts because the facts themselves, you can't copyright them as such. That I think is going to meet huge pressure on news organizations that do that kind of routine commodity journalism. I think it means that those organizations that have gone for paywalls, and subscriptions and memberships and so on, are going to benefit more because at least theoretically, they're able to put some moat around their content, although that's the technical issue. We're not sure. And I think it means if you look at wire cutters, great example, that he could do product reviews purely by, you know, Google reviews couldn't in this one's got five stars, this one's got three. So the great thing about why customers, it doesn't just do that, it's got really expert people who really pay attention to a product. And they think of it from a human point of view. Yes, that's got loads of groovy applications, but I found it really difficult to use. So there is human judgment, human analysis and their experience of looking at products over time. Now you can use algorithms, you can train them to try and copy that degree, but much better to get to habit, you know, from wire cutter. That's why wire cutter is so such a popular product for New York Times. So in that sense, if you can protect that human value, then you will still survive. But you're quite right, the way this works in practice is going to be interesting. And I think in that sense, there's gonna have to be a combination of the kind of European regulatory approach, which is much more about content, and how the public benefits from a media environment. And the American approach, which is more around antitrust, more around having a competitive free market. And I think in this, there's a kind of a mixture going on. I mean, one media executive, I spoke to New York recently, from a very big media organization, said, well, funnily enough, he said, and he was speculating, this wasn't their policy, you speculoos they will, if there's lots of different chat GDPs, and they're all competing for authority and attention, then perhaps you can do a deal with him, you can say, okay, you can use our database. If you pay us a lot of money, for example, you can license us, or you can do us a deal where you will make sure that you billing back in return, we'll give you more reliable, better data, so that you don't come up with these hallucinations and nonsense. So, you know, we've seen in the last few years how it's a dogfight. And in some places like Australia, you know, the publishers have managed to screw some money out of the tech companies in the short term, but longer term, it is a power struggle.

Nikita Roy  32:27  
Yeah. And just as you're saying, it seems like it's really the quality of content that we produce, it's going to be more important than ever. But this has also got me thinking about like, in terms of like, the business model of publishers with the current stage of AI, like, is there going to be an impact on the way we think about generating revenue as well? Like, are we going to be, I don't know, like producing chat, GPD, plugins and chatbots. Because I feel like also the nature of how people are going to get information is changing, they would expect to just type a question and have that answer straight away, right there. And just as I said, like, according to wire cutter, what are the best office chairs, and it straightaway tells me what the best office chairs are, according to them, instead of having to go through and read an entire article, and then it shows up, you know, are people gonna be like expecting to get the answer right then and there? And how do you see business models kind of beginning to evolve as a result?

charlie beckett  33:19  
Well, I think partly, it's going to accelerate or perpetuate certain trends that are already happening. One of them is the sort of bifurcation news organizations getting bigger, and they're getting smaller. So we're getting consolidation at the top. The New York Times is the classic example. But it's happening in most marketplaces, because they've got the scale to provide enough products and services to justify a big subscription. And they can keep up with the tech as well and benefit from the scale and different affordances of the technology, the same time that you're getting a kind of blossoming of a much smaller news organization, some of them hyperlocal, some of the niche, some of them not so small, you know, 5070 100 people, and some of their tiny could be single people who are creating news products, news organizations, new services. So I think this AI will kind of accelerate that, that bifurcation. And it will also, I think, impact on another big trend that we've seen over the last 1015 years, which is news organizations are doing less and they're doing more. And what I mean by that is they are not trying to cover the all the water fronts. You know, they're not trying to record every single country in the world and every single topic they are trying to do move it to the better ones, especially they're trying to do deeper digs, better coverage, more context, more analysis, also more human stuff about particular issues, that particular stories, and they could be ones that are more attractive to their audience, or it could be just that that's their specialism. And I think there's partly a reflection at the same time you have to do everything for everybody. And in this sense, the AI can help you because none of us are the same person all the time. You know, sometimes you are interested in, you know, technology sometimes you're interested in whatever cookery sometimes I'm interested in football, something I'm sometimes I'm interested in ancient history. Now, you know, is difficult to please me all the time, sometimes I'm interested in the morning, for example, in short bits of news that just tell me what's going on briefing me, briefed me briefed me, give me some headlines that were, and then in the evening, give me something reflective and thoughtful and chewy and analytical, perhaps a podcast say. So, you know, news organizations can use the tech to try and understand that variability that they have to have. And I also think they can use the tech to do that deepening on the verticals, you can use the tech to surface background information context, different sources, different angles, different perspectives on a particular topic that enables you to do better, the better journalism rather than that old idea of, you know, when I was at the BBC, for example, we would say, we've got to cover this, that you've got to cover everything, we've got to mark this, we wouldn't do much about it. But we felt we had to because the BBC was and is still a kind of universal broadcaster. And that's pretty unusual. And most news organizations are no longer that. So these are the interesting trends. And it's all about structured news, it's all about the idea that within the newsroom. And this is a kind of an invisible change. The public could see when news organizations went online, well, they've got a website, they could see when when you went onto social media, oh, my favorite newspapers on Twitter, or Instagram, that's nice. You know, that's changing things, they won't see a lot of this stuff, because it will be about reformatting and repackaging. And information flows that will be within the news process. And some of it will be automated, you know, there'll be getting content that was not seen by human hand, it was not created by human hand, others, it may have been edited by it. And so you know, we're gonna get this is the, you know, the kind of Internet of Things, you know, we were already getting our news on so many different platforms, and from so many different devices, I think that's going to increase. And again, the AI facilitates that through synthetic media. So you won't notice it as a consumer necessarily. You may notice it occasionally. You know, if you're, who's the channel that decided to use a Kuwait News, they've decided to use the virtual news reader, while you use, you can spot that you can see that I'm not sure that's the best use of the technology. But generally speaking, it's going to be under under the hood.

Nikita Roy  37:48  
Yeah. And since you've kind of been a part of this AI conversation for the past five years, I kind of want to wrap things up by getting your insights into how do you see the evolution of the news industry? And what do you see the newsroom of the future would look like with AI playing an increasing role in it?

charlie beckett  38:09  
Yeah, I did write a book back in 2008, which was sort of, hey, this is the way journalism is going to change. And it went out of date within a couple of years, because the change happens so rapidly. Luckily, most of the solutions were quite accurate. You know, they were very accurate, but they just happened so quickly. So that's one lesson I've learned, which is that any predictions you make will probably happen quicker. I mean, I'm literally having a conversation yesterday with a news organization, quite a serious one in the UK, that's come up with a really clever way of using potential using some of these new generative AI. And it sort of gave me the impression you're going to have this. And I suppose I'm going to fall prey to your robot metaphor here. But you're going to have this kind of super wired journalist who's got all these incredible things to assist them, all these plugins that are helping to make them do their work faster and more effectively. And at the same time, they're going to be plugged into a newsroom, or news organization, which is also intensely networked with a lot of the boring decision making taken over by systems connecting people even more closely to the consumer to the audience. And, you know, that's the key thing, the key challenge for journalism. At the moment, it's not necessarily what you do with AI. The key challenge is, the public lives in a world of an overabundance of information, and an overabundance of bad information. And they have a lack of time, and often a lack of resource or literacy to be able to access what they want it the biggest challenge for journalism right now is to optimize the connection between the cities Then, and good journalism sounds really simple. But we're creating an enormous amount of fantastic journalism. And it's not connecting well. So that is my, that's my wish. It's not my prediction. I think times are tough and things are going to change. And frankly, I do not know where we're going to be. It's five years since we started this program. And you know, I could write a blog, perhaps I want to, I'm too much of a coward about where I think we're going to be in five years time. But it's been a roller coaster ride. And I just hope that the great thing about this is that we care, podcasts like yours, show that people are paying attention within the industry and outside of the industry, people realize that this matters, and that we should, you know, think responsibly and make others act responsibly, too.

Nikita Roy  40:51  
Well, great insights there, Charlie, we need to act responsibly with AI in a very crucial and experimental phase with AI in the newsrooms, and well, I feel like I can keep this conversation going for a really long time and keep talking to you. Because there's just been some incredible insights here about using AI and journalism. But just before you wrap up, I want to let our listeners know how they can learn more about journalism, AI and the work that you're doing there. Well, we

charlie beckett  41:18  
are completely open, we're completely free. I should say actually, just full disclosure, we are that this particular project is sponsored by a course, the Google News initiative. So it's a tech guy sponsoring us, but we're completely independent with with the LSE. But we've got this huge network, you can sign up for our newsletter, you can apply for any of these courses, you know, got the email course we've got the online courses, we've got the Academy for Snorks more newsrooms, you've got the fellowship for people who are a bit more expert, if you like. And we're always happy to talk. I've got a team based in Europe, based in India and myself. based in the UK, we've got partners around the world, we've got friends around the world. So please just join us whether you're a student, whether you're a researcher, whether you're a journalist, whether you're a technologist, or whether you're just interested in civilian, we would love to hear from you.

Nikita Roy  42:10  
Well, thank you so much, Charlie. There's a lot of support journalism AI and thank you so much for what you're doing to help us here in the newsrooms, and thank you for taking the time to come on the show.

charlie beckett  42:22  
Thank you so much. It's been a lovely conversation. Thanks.

Nikita Roy  42:26  
That was Charlie Beckett, the Polish journalism and AI project director at the London School of Economics. To learn more about our guests and work at journalism AI, visit us from robots.com If you liked this if you're on the podcast, please subscribe rate and review the show on Apple podcast Spotify, or wherever you get your podcast. I'm Nikita Roy, and thank you for listening to newsroom robots.

"
newsroom_robots,3,"Wed, 26 Apr 2023 12:25:00 GMT",Damon Kiesow: Approaching AI in Journalism with a Human-Centered Design Mindset,https://www.newsroomrobots.com/episodes/damon-kiesow-the-need-to-approach-ai-with-a-human-centered-design-mindset-qz7ItSk9,"<p>How can journalists adopt a human-centered design mindset when building AI-driven products, and what skills will the next generation of journalists need to succeed in an AI-powered newsroom? </p><p>Today we’re joined by Damon Kiesow, a digital media pioneer specializing in aligning community information needs and business strategies to support sustainable local journalism. </p><p>Damon shares his expertise as a professor at the Missouri School of Journalism, author of the first textbook in News Product Management, and co-founder of the International News Product Alliance. He is also the co-founder of the summer pop-up newsroom, the Missouri Information Corps, and the creator of an audience and product-focused diversity internship program in partnership with the Institute of Nonprofit News.</p><p>Before joining Mizzou, Damon served as director of Product for McClatchy, where he created the company’s first Product Design and User Experience Research teams. Over at The Boston Globe, as a senior product manager, he helped guide the publication’s mobile strategy. In Nashua, New Hampshire, he served as the managing editor/online at The Telegraph, where he helped the Newsroom pursue a digital-first local news strategy — launching the newspaper’s first mobile app and video journalism efforts.</p><p>In this episode, we get Damon’s views on how newsrooms can approach AI, delve into the importance of a human-centered design mindset when incorporating AI into newsrooms, and discuss the essential skills journalism students must develop to succeed in this evolving landscape. </p><p>Be a part of the conversation on AI in journalism! Send us your questions <a href=""https://docs.google.com/forms/d/1NfOf6umHO-ESYDWZKCKfdp10fSsqnCrDMXjL7DLNehg/edit#response=ACYDBNhRTwLMoF5elD80B4zR28Isqaqus2lIKHR_RO-HU_g1Vzm6IInXuVUGHZfz9QPnKw0"">here.</a></p><br /><hr /><p style=""color: grey; font-size: 0.75em;""> Hosted on Acast. See <a href=""https://acast.com/privacy"" rel=""noopener noreferrer"" style=""color: grey;"" target=""_blank"">acast.com/privacy</a> for more information.</p>","Nikita Roy  0:02  
This is newsroom robots, the Podcast where we explore the intersection of artificial intelligence and the news industry. I'm Nikita Roy, a data scientist, media entrepreneur, and one of the many founders currently building their ventures at the Harvard innovation labs. On the newsroom robots. I'm excited to bring you insightful conversations with industry experts about how AI is impacting the way we do journalism.

Our guest today is Damon caso, a digital media pioneer who has witnessed the transformation of the news industry firsthand, and now helps shape the next generation of journalists as the night share in digital editing and producing at the Mystery School of Journalism. He's also the co founder of the news product Alliance previously has been with McClatchy as the director of product where he created the company's first product design and user experience research teams. Over at the Boston Globe he guided the mobile strategy of the publication, and he founded the mobile media blog for pointer. In this episode, we hear Damien's views on how newsrooms can adapt the AI revolution, the importance of a human centered design mindset when building AI driven products and touch upon the crucial skills required for the next generation of journalists.

Hi, Damon, thank you so much for joining us on The Newsroom robots podcast.

Damon Kiesow  1:29  
Great to be here. Great name. Thanks.

Nikita Roy  1:31  
So Damon, we've started off the year 2023. With Ai no longer just being a buzzword or a novelty, it's everywhere. And for us as part of the news industry. We appear to be at a really pivotal point where these technologies are starting to impact the real world. And I want to get your take as a digital media pioneer. What has been your perspective on how AI will transform journalism?

Damon Kiesow  1:57  
It's a great question. And honestly, this comes up every time there's a new technology that's sort of launched into the world that obviously has some sort of relevance or interests for journalism or the business of journalism. Francesco Marconi, who has a used to work at the Wall Street Journal has an AI a startup describes, like the phases of AI in three steps. I'm not sure if the his label is exactly right. But like automation was where we started that sort of simple tasks, and then that support or enablement of like maybe routine tasks still, but like writing like Grammarly, I use as a, as a writing tool or spellcheck like that support. And we're now in the generative phase of like AI. And I think that's where, obviously a lot of the buzz has come from recently. But that's also where a lot of the riskier aspects of the technology are sort of quickly coming to bear or more apparently, which is why we're here talking about it. Right.

Nikita Roy  2:52  
Yeah. And how have you been thinking about like generative AI and the entire buzz surrounding that? How can journalists now leverage that and and use production?

Damon Kiesow  3:02  
Yeah, carefully. would be my my first buzzword on that, you know, CNET started doing AI generated stories before people were really aware of what generative AI was popularly speaking. And they published 77 stories that were sort of filled with errors, because they weren't apparently clear on the ethics or sort of the the mechanics of how that worked. Just this week, Bings chatbot, sort of gotten to a, I call it a tiff with Google's chat bot, because someone had Hacker News, posted a joke. And that got picked up as a fake news story. And then Bing was saying that Google's chat bot had been shut down, right. So there's always like, very emergent things going on. And some are risks of misinformation. Some are just really entertaining, right? There's questions around like News Corp is expecting open AI to pay royalties. If you're training the language model on Wall Street Journal stories, for instance, like, this doesn't just touch one piece of the industry it touches like almost every aspect or segment because I mean, we're in digital media, right? So everything is digital is prone to intervention or improvement, or disruption, right? By technologies like this. You know, the problem is, we in the news media are in the business of like, creating, understanding, right, creating, we're in the knowledge creation business. And these AI models don't actually generate knowledge, they generate mimicry, and repetition. In the generative models, they they create mimicry of past knowledge, assuming that the models were trained on accurate data, and assuming that the models are able to make sense of the sort of the chaos, that is human communication, right. So right now, if you ask it to cite a fact, it's going to give you the fact and then make up the citation. Right. It just isn't quite there yet in terms of actual knowledge creation, right? It's like the new Turing test is, can we train a computer to jump to conclusions as well as a human being can write, like, fantastic. But you know, heuristics are a huge time saver for the human brain, because it's expensive thinking is expensive, right? But the problem with heuristics is, is they they let us impose, like all sorts of cognitive biases on our decision making, right, like including stereotyping, right, which leads to racism and other sorts of really unfortunate side effects. So those are like the bad side, or the risky ethical side of things for us. On the positive side, there's all sorts of tools, we're already using these in newsrooms, and we have been, right analyzing data, looking for trends, summarizing meeting transcripts, or summarizing interview transcripts like this, suggesting headlines, it'd be useful for a B testing, like all these sorts of things where you have a smaller controlled set of data or signals to look at. And in sort of that bucket, you can ask it to give you alternatives based on past well understood or routinize sort of processes, or inputs, right, I think it's really good for that customer service that Washington Post has been using for smaller models that is for like election stories, or just as plugging in numbers into a pre written template. Like all those are fantastic uses of technology, going to it and thinking it's actually a knowledge creator and can tell you really accurate things from an almost universal set of data sources is not it's not where we are,

Nikita Roy  6:38  
yeah. And circling back to the disruption caused by technology, you've been a part of the news media industry, you know, the disruption caused by the transformation that the digital media era and I want to take a step back into your career, you've worked on helping newsrooms in a weight then build these digital products over up the Boston Globe and McClatchy previously. And we are in a similar moment in time where the media industry again has to evolve. And I'd love to hear more about your journey. When building news products for newsroom with this kind of digital first mindset. What lesson did you really take away at that time during the digital revolution that could be applied to newsrooms once again, who have to evolve to keep up with the AI revolution?

Damon Kiesow  7:23  
Yeah, I mean, that's been that's been a journey, physical and sort of learning journey. Certainly. I think originally, early on my career before I was really involved in the product management side, the business side of the profession. I was really I think chasing technology. Right, I started after I left newsrooms proper I, I was at Poynter Institute in Florida for a year studying mobile and social technology, and really interested in what those what that could do for for journalism, and study in writing about in teaching about it. It was really during that period that I started realizing you're thinking about the fact that the technology changes constantly, like every couple of years, there's something new interesting. But journalism isn't really in the business of chasing technology or shouldn't be, it's really in the business of serving readers or serving communities. And I mean, that's why I went back to school to get a master's in human factors and information design, which is very much a human centered design, research focus, because I really wanted to go to step back from the tech and say, how do we serve communities? How do we serve people better? And then what are the tools we use to do that with? And certainly mobile is one social is one. But coming from the human perspective, we ask about what are the needs of the community first, and then we look at the portfolio of tools we have, of which AI is now one and say, What can we do with this tech to improve our communities to improve our business, right to make things more efficient, or better to add value, social and economic value? Because we're a business in some way. And it really comes down to in all those cases, like Rule number one is do no harm, right? Like democratic growth. Yes, good idea. How do we make sure we're doing the right thing and not just doing the easy thing, because we've been sold, if I can go back to social, we've been sold that doing Facebook video, it'd be a fantastic thing to make money, because of the metrics were being distorted by someone who had a lot of self interest and distorting the metrics, right? It's those sort of hype cycles and you're listening. You're if your primary source of authority on something being a good or bad idea is the business that's created the product, right and you're making your business decisions based on that interest, and not in the interest of community, you're gonna go down a lot of blind alleys or over a lot of cliffs. Such a general sort of a very general perspective. Obviously, there's a lot of nuance underneath that

Nikita Roy  9:54  
and getting into your expertise about human design centered thinking. I'd like to delve into your thoughts on how can we as journalist take that mindset and approach AI when creating products now for the newsroom that involve AI?

Damon Kiesow  10:10  
Yeah, I think it goes back again to the sort of the three layers of the three levels of sophistication of how we use the tools, like on the on the more internally focused uses, like automating alerts, digging into data, those types of uses, supplementing sort of routine activities in the newsroom that aren't directly creating the journalism, but maybe supporting like administrative work or research and news gathering. Like there's not a lot, I don't think there's a lot of risks there, especially if you're not using the generative models, but using just a learning model, that you're training, maybe on your own data you're using for very specific uses. That's fantastic. I think when you get to the currents are emerging aspects of it. Right. The challenge there is like these, that's a black box, I put it this way. All those models work is a black box, we don't know, sort of what language models what source those language models are trained on. Like, have they been designed or developed ethically? Basically, is the question I think newsrooms need to be asking, like, how do we know? And think about like, ethically sourced diamonds and ethically sourced coffee, right is the thing we talk about. Now, we didn't use to, like, I worry about my iPhone being ethically sourced, and it's not right. Certainly, the current AI, we don't feel necessarily it's been ethically sourced. But we don't know because those aren't typically public models. So I worry more about the centralized the big models that Google or open AI or those level of organizations are launching. And I might worry less about, I don't know, can we call them artisanal sort of AI models that could be trained locally, for smaller uses, but more targeted, and sort of more ethical trainings and deployments and control over, right, because we don't want to be launching a news product into the wild, that we think is just reporting the facts, but it's got biases, somehow deeply embedded in it, because the the learning model included like five years of 4chan, right, we don't know that. And so how do we avoid that problem is sort of the Do No Harm thing that comes first.

Nikita Roy  12:25  
And to understand more, what do you think would be the ideal approach for a news product manager right now, to who's looking into all of these AI models that are coming out? And also having to incorporate it in an innovative at the same time within the newsroom? What should they keep in mind?

Damon Kiesow  12:44  
Yeah, so definitely newsrooms or news organizations are not do not typically need to be early adopters of a new tech, that's different than saying they shouldn't be early experimenters with the tech. Right? They absolutely should be early experimenters with a tech. And I think it comes down to what are the needs in the newsrooms, they need to understand the technology, they need to understand not just currently what it can do, what it's likely to be able to do in the next three 510 years, in order to align sort of what's that tool set was that portfolio of capabilities it's going to be able to do, and how do those sorts of different because there's a lot of different channels of capabilities coming out? How do those different channels align with the needs that we have in the organization, or aligned with the needs that we've identified in the community that we can somehow solve in a way that does align with our business needs, our ethical needs our community needs, right? And so and we are we're seeing experiments, we should be experimenting? Absolutely. We should be testing, things that like are happening, meeting transcripts, AV testing, some of the things I mentioned a minute ago, but we need to be doing it with with a complete awareness of there's a difference between testing something for a back office use like in a production, or a news gathering and those kind of tasks, which are low risk in terms of ethical dilemmas or community harm risks, versus testing projects, or products, which are community facing, and are producing output or content in ways that we don't understand the underlying mechanics, like CNET, publishing stories, and not realizing that AI among other things is really good at making things up, right. So I would put those into different buckets sort of back of house in front of house. Experiment as much as you want in the back experiment as much as you want in the front. But don't necessarily be releasing breaking news stories, for instance, where you let AI run the show without strict human oversight and intervention, as an example,

Nikita Roy  14:57  
and for those in the newsroom right now. that are hesitant about AI. It's adoption the same way it probably was. The digital media industry was transforming. What would you say that people need to keep in mind right now?

Damon Kiesow  15:12  
Yeah, I mean, there's no such thing as a bad technology. I mean, you know, I hate to put it that way, because it's a bit of a cliche, but there's no bad technology, there's poor uses of technology. There's technologies that are imposed sort of artificially on society because of the lack of oversight and regulation and understanding, right? We had elected members of Congress yesterday asking if Tik Tok needed to connect to Wi Fi. That's not a real great recipe for intelligent discussion, and sort of CO construction of technology, with society, if that's like one of the bodies responsible for regulating sort of how this emerges more broadly. So I think we need to be smarter than that. And just saying, Yeah, journalists can be suspicious of innovation. Often they're suspicious because it comes as a buzzword, as opposed to a solution for an actual need. And I think we just need to talk about, yeah, there's hype, there's plenty of hype around AI right now, around the generative models, AI is not going anywhere, right, it's been a thing for a long time, it's improving to the point where now it's reaching sort of that, as public uses in business and other in society, we just need to identify what those really productive uses are now. And there are already plenty of them. And then we need to keep an eye on the more cutting edge or bleeding edge examples and figure out how, when and where can we bring those into the culture of journalism, right to make them, make them work for us, as opposed to make them work for the profit making entity that's, you know, pushing those out and piping them off? To some extent?

Nikita Roy  16:59  
Yeah. And I want to step into the next part of your current journey. Right now, as a professor at the nursery school of journalism, you're building the next generation of journalists? What do you think journalism schools right now need to do to prepare their students for a future in which AI is playing an increasingly important role? And they know how to deal with it?

Damon Kiesow  17:21  
Yeah, they should be they should be playing with it. They should be reading. I mean, among other things, playing with the publicly available models and tools, to understand that interaction to understand the, the sense of it and the quality of the results you get based on different questions, you can ask what it's good at what it's bad at currently, it's learning as we are, it's learning how to do its job as we're learning what its job can be, so to speak, right? So you've got to be you got to be playing with it, experiment with it doing tests, you've also got to be we've also got to be teaching journalists. And I think we do to some extent or another, like critical thinking, right? For instance, what is it good at? What is it bad at? How does it work? What are the motivations and incentives of the other organizations developing the work, you know, we need to, we need to be teaching journalists, current and future, like to avoid shiny object syndrome, where we do fall for the trap of it's new, it's interesting, it's fun, let's throw it on the webpage and see what happens. We're not really in the see what happens business. Right? We're in the careful, cautious, ethical sort of innovation in production of, again, of news and understanding that sometimes gets understood as journalism is an innovative and I think journalism has historically been very innovative. We've been among the first industries to adopt all manner of technologies from carrier pigeons to telegraph to VideoTex, which failed, but turned into the web, so to speak, right? We've been very innovative, what we haven't been real good at, in some of those cases, especially in the digital age is turning that innovation into a product or platform that's also good from a business perspective for us. So we need to sort of to loop back to your question, because I diverted there a little bit. You know, we need to be teaching systems thinking to understand how this new thing fits into the larger ecosystem. Right? We need to be teaching product thinking, to understand, right? From my perspective, that technology is not deterministic, or it shouldn't be. Technology is open for negotiation. So we should be looking at this opening salvo of negotiation go, what do we like about it? What don't we like? How could it work? What are the risks? How do we then take our understanding of sort of that SWOT analysis of it and like apply that to news in a way that maintains our ethical concerns or community He needs, how do we make things more efficient? So we as journalists can spend more time doing the work of, you know, reporting, and being out in the community, so to speak. Like all those things. That's, that's a, that's a bunch of words to say, you know, news, product thinking and news product management, and having more technologists who come in with a, an education in social sciences, not just technology, right, in newsrooms, and we're doing that you're certainly seeing that at a number of schools sort of teaching that balance between sort of STEM and humanities, if you want to phrase it in that way to say, that's a great fun, new thing. AI is a great fun, new thing. How could your best work with it?

Nikita Roy  20:39  
Yeah, and now with this hype of AI, the hype of AI is taking over the role of journalists, we also have journalism students coming out into an industry that has been experiencing a lot of layoffs and a very uncertain future. I wouldn't know from your perspective, what are the key skills and knowledge that you think that the next generation of journalists need to have to prepare themselves for a career where they are going to work around with AI?

Damon Kiesow  21:05  
Yeah, journalism students coming out. It's actually funny, they've come up now in a world where a lot of the technology just in the past 15 years that we've seen as earth shattering, or maybe I've seen is earth shattering at the time, because I'm old, you know, mobile phones, and even just high speed broadband, like all this kind of stuff, constantly connected, right? They accept that as table stakes, like that's not a new thing. So they've definitely definitely have a different understanding of it. What I worry is that, because these really revolutionary and disruptive technologies have been part of their DNA almost since birth, they now might not necessarily see those as negotiations, they see those as that's how the world is. I think they really, they need to be more skeptical. Journalists are always skeptical, like that's their business is to be skeptical. I want them to be more skeptical of new things, but not cynical about it. And I think that gets back to your earlier question of why do journalists sometimes reject innovation? I think they become cynical because they've seen cycles of innovation that haven't really, quote unquote, helped journalism, which isn't entirely fair, but that's how it's perceived. I want them to be more skeptical and ask more questions. But I also want them to have the skills not just of reporting, right, and editing and writing, but of like, deeply understanding how technology works, how it develops, how it's shaped and formed. I mean, this is, again, critical thinking systems thinking, having a human centered approach or a community centered approach, not just the technology technology for us as a tool, but having that human centered approach to thinking about audience needs first, and then looking at turning around and looking back in the office and going, Okay, what tools do we have to solve those, and it's going to be a little bit of AI, it's going to be mobile, it's going to be social, right? Like all those solutions. There's obviously a lot of more cut and dried skills underneath that. And I don't say everyone should be a coder, for instance. But having an understanding of how to do some coding, even in Python, something like that, I think really opens your eyes to how technology works in ways that it doesn't, if you you're just looking at the box, you have to open up the box, appear inside, poke around, get a sense of it. But if you want to put the box back on the shelf, that's fine. As long as you walk away with sort of a little bit more understanding of this is part of society. Now this is part of the world now. We can't just treat it like it's non negotiable, or we don't have to understand it, especially in the business of news, we have to understand it and figure out how to turn it in or take advantage of it for news.

Nikita Roy  23:49  
Yeah. And we're in the stage of poking around with AI. And so I want to conclude I always ask our guests at the end about their final thoughts and looking into the future. How do you see the future of the newsrooms being with all of these newsroom robots and automation becoming a part of reality?

Damon Kiesow  24:07  
Yeah, yeah, there's two answers there. One is AI is going to be used to eliminate jobs. Because the profit motive, especially of the large media organizations is going to be to use this as an efficiency to cut costs. It shouldn't be used that way, and it's not appropriate for that use. But since the age of the Luddites, right, that's been what's happened is, we use new technology to increase productivity and reduce staff. What it really should be used for and it will be used for many places is to make the work of creating good journalism and keeping an eye on the community and understanding data, those types of things. That's what it's perfect for. It's just another type of computational skill that started with doing data journalism on mainframe computers. And, you know, of course, my highlight is Excel sheets. That's That's as far as I can go with that. But like it's, it's a tool, and we just need to figure out that what the right fit for the tool is, in the many, many use cases journalism has for computers and technology and artificial intelligence is, I don't think we'll talk about AI as a separate thing, and five or six years in terms of how it's embedded. Just like I don't talk about spellcheck as a tool separate from my word processor. Right? They'll always be an emergent characteristic of AI, the words doing something new. But there's also going to be this briefcase of sort of settled technology that's improving, but isn't disruptive, and we're just going to use on a daily basis. Now thinking twice about sort of how it works or why it's a value.

Nikita Roy  25:48  
Okay, great. And just before we wrap up, I want to throw it back to you about how listeners can learn more about the work that you're doing. And the current news product management textbook that's you worked on.

Damon Kiesow  25:59  
Yeah, so I'm currently boycotting Twitter. So I point people at my Twitter account it's that's sad, but life moves on. I'm currently on Mastodon, you can find me there. If you want to follow me on Mastodon, you can search on on my name. And you'll hopefully find me just finished writing like literally put the last word in the document yesterday on a textbook on news Product Management. Hopefully we'll be out in the late fall, maybe November, December, still waiting to get a final date on that. That's been a couple of years of writing and thinking about news product management, the history of the ethics, the mission, how it aligns with New Journalism, as opposed to how product management and news aligns with sort of the different practices and the different motivations that you have in high tech and Silicon Valley specifically. So there's a there's a big distinction, I think, between the two, the news product alliance is been formed to think about and talk about in Teach sort of that news product making newsrooms. So that's really what I spent the past two years working on. And so what I'm teaching here at Mizzou is sort of that news product management and a capstone class I teach.

Nikita Roy  27:10  
Fantastic and so excited to read the book when it comes out later this year. And once again, thank you so much for joining us today. It's been a real pleasure to have you on the show.

Damon Kiesow  27:21  
Thank you. Fantastic.

Nikita Roy  27:24  
That was Damon kieso, the NYCHA and digital editing and producing at the Mystery School of Journalism, and the co founder of the news product Alliance. Subscribe to newsroom robots wherever you get your podcasts and send us questions you'd like to ask our guests at newsroom robots.com. This podcast was made possible thanks to the Harvard innovation labs background. I'm Nikita Roy and thank you for listening to news robots.

"
newsroom_robots,2,"Wed, 19 Apr 2023 09:35:00 GMT",Joe Amditis: Harnessing the Power of ChatGPT for Local Newsrooms,https://www.newsroomrobots.com/episodes/joe-amditis-harnessing-the-power-of-chatgpt-for-local-newsrooms-0Hql3ET3,"<p>In this episode, we explore the potential of ChatGPT for local newsrooms with Joe Amditis, author of Beginner's Prompt Handbook: ChatGPT for Local News Publishers. Joe is the Assistant Director of Products and Events at the Center for Cooperative Media at Montclair State University, an Adjunct Professor at the School of Communication and Media, and the producer and host of the <a href=""https://whatthefuckjusthappenedtoday.com/podcasts/"">WTF Just Happened Today podcast</a>. </p><p>Joe, a veteran of the NJ Army National Guard, was deployed to Iraq in 2008 and his unit was activated to help with Hurricane Irene relief efforts in 2011. He earned a BA in political science and criminal justice from Rutgers in 2013 and an MA in engaged journalism from the Newmark Graduate School of Journalism at CUNY in 2016. He was co-founder and director of operations of Muckgers, an award-winning, student-focused investigative news outlet, until 2014.</p><p>Joe has also coordinated several collaborative reporting projects, including <a href=""http://usdemocracyday.org/"">Democracy Day</a>, a nationwide reporting collaborative involving 300+ newsrooms across the United States.</p><p>We explore the exciting world of ChatGPT and its potential to revolutionize local journalism, discussing the transformative power of generative AI, ethical considerations, prompt engineering, and the future of local newsrooms in the age of AI. </p><p>Joe can be reached at amditisj@montclair.edu and on Twitter at <a href=""http://twitter.com/jsamditis"">@jsamditis</a>.</p><p>Here’s a list of helpful resources concerning today’s episode:</p><ol><li><a href=""https://jamditis.notion.site/Beginner-s-prompt-handbook-ChatGPT-for-local-news-publishers-15d1f07d5b194265a41fdd42955679b4"">Beginner's Prompt Handbook: ChatGPT for Local News Publishers (Center for Cooperative Media)</a> - Discover Joe's comprehensive guide to using ChatGPT in local newsrooms.</li><li><a href=""https://centerforcooperativemedia.org/resources/useful-links-websites/"">Giant List of Useful Tools and Websites (Center for Cooperative Media)</a> - A treasure trove of tools and resources for newsroom operations.</li><li><a href=""https://docs.google.com/document/u/1/d/1dy-bxKTrU-kujpC8LU9bPPJuu5jraGg8fVa37WBd0vQ/copy"">Template: ChatGPT Usage and Newsroom Ethics Policy (Center for Cooperative Media) </a>- This template facilitates transparency in newsrooms' ethics policies regarding the use and disclosure of generative AI.</li><li><a href=""https://trustingnews.org/newsletter/"">Trusting News Newsletter (Trusting News) </a>- Stay informed about building trust in journalism with this insightful newsletter.</li><li><a href=""https://www.lse.ac.uk/media-and-communications/polis/JournalismAI/Starter-Pack"">Journalism AI Starter Pack (LSE)</a> - Get started with AI in journalism with this comprehensive resource from the London School of Economics.</li></ol><p>Be a part of the conversation on AI in journalism! Send us your questions <a href=""https://docs.google.com/forms/d/1NfOf6umHO-ESYDWZKCKfdp10fSsqnCrDMXjL7DLNehg/edit#response=ACYDBNhRTwLMoF5elD80B4zR28Isqaqus2lIKHR_RO-HU_g1Vzm6IInXuVUGHZfz9QPnKw0"">here</a></p><br /><hr /><p style=""color: grey; font-size: 0.75em;""> Hosted on Acast. See <a href=""https://acast.com/privacy"" rel=""noopener noreferrer"" style=""color: grey;"" target=""_blank"">acast.com/privacy</a> for more information.</p>","Nikita Roy  0:02  
This is newsroom robots, the Podcast where we explore the intersection of artificial intelligence and the news industry. I'm Nikita Roy, a data scientist, media entrepreneur, and one of the many founders currently building their ventures at the Harvard innovation labs on the newsroom robots. I'm excited to bring you insightful conversations with industry experts about how AI is impacting the way we do journalism.

Today's episode focuses on the challenges and opportunities of ChatGPT and how local newsrooms can harness this technology to serve their communities better. Joining me is Joe Amditis, Assistant Director of products and events at the Center for cooperative media and an adjunct professor at the School of Communication and Media at Montclair State University. Joe has coordinated several collaborative reporting projects, notably democracy Day, which brought together over 300 newsrooms across the United States. He recently released the beginners prompt handbook church, GBT for local news publishers. He's also a veteran of the New Jersey Army National Guard Show. Welcome to the newsroom robots podcast. Hi, thanks for having me. We're excited to have you here. You've been quite busy at the Center for cooperative media hosting workshops all about ChatGPT for local newsrooms. So I'm really excited to have you on the show today and really delve into this topic of ChatGPT and what it means for the future of journalism. So just to kick things off, I'd like to take a step back and lay the foundation for our listeners, and in layman's terms get an understanding of what generative AI is. And so can you give us a brief overview of how it works and what its relation is to ChatGPT? 

Joe Amditis  1:45  
Yeah, so most of your listeners are probably familiar with some form of generative AI or even the early attempts at it. If you remember smarter child, I mean, the old going all the way back to like ame and AOL Instant Messenger, they've been trying to do chatbots. And really, it sort of came from this desire to push the limits of what is possible with computing and create sort of like, you know, human like experiences and engagement and stuff. And so what it really is what generative AI essentially is, at least in the term, if we're talking about like text based generative AI, which is the most popular one everybody's talking about. Now, we won't get into like mid journey and stable diffusion and stuff. But it's just a computer with a very fast and smart computer that is able to look at a massive dataset of text and read it posts and internet articles and news articles and everything from this big data set that it has. And based on all that information, it is able to pretty accurately being the operable word there in certain contexts, predict what is the most likely next word. So based on everything that's come before it, and based on what you've said to it, it is able to very effectively and efficiently predict or guess what the next word is. And I say guess because and I alluded earlier to the whole accuracy aspect is the big concern, or the big scary part, I think, for part of it at least, is that sometimes it just makes stuff up wholecloth. It'll just, it'll make up academic sources and references. It'll make up stuff. But one of the first things most people do with this thing is to see if you're in your edited state upset. So ask you, you can ask it who you are. Maybe if you work at an organization or company who you know, tell me about the Center for cooperative media. And the majority of the information that it has mostly is correct. But if you know a subject intimately Well, it's easy for you to spot where it's just what it's called hallucinating where it's just using that predictive aspect of its behavior to try to fill in the gaps. And oftentimes, the danger with that is that it sounds so convincing, that if you don't know or have intimate knowledge or familiarity with a topic, then it's very easy for you to get fooled. Frank, so I can't remember his name. There's a great book called on bullshit which talks about the difference between lying and bullshitting. And I would argue that this this type of technology is just the best and most brilliant bullshit artists out there. But that being said, some things are and what what I focus on a lot in the eBook, and then trainings and workshops I've done is, we actually have a lot of bullshit in our daily lives, a lot of our jobs are filled with bullshit, at least bullshit paperwork. And that's where I think AI can come in a generative AI like chat GPT can come in really handy, because the amount of forming emails outreach, cold outreach, copy, and all this stuff that is essentially the same bullshit over and over again, with minor tweaks based on the situation or context in which then that can save you a lot of time upfront. And that time that you save those little bits over time can multiply and actually be a big help to, especially publishers and organizations with, you know, less than five full time staff. Yeah, and you've been delving into generative AI and before even the launch of chat GPT you said in one of your workshops, and so I'm kind of kind of curious to hear more about your voice and experience once Chad TPT came out. What's been one of the key insights you've got from that journey, any standout moments or challenges you faced while working with it? Well, I found out about it from tick tock like maybe 130 In the morning one night when I should have been sleeping and I was scrollwent in my bed and I saw somebody say, oh, you know, this new thing came out. And it's crazy. And I immediately, you know, switched over, I knew I recognized open AI because I had already been playing around with their GPT three, their playground and everything. And I have no formal training background or experience in any of the computer science stuff that underlies all this technology. So please take everything I say today with a grain of inexperience and salt. But I'm coming at it from somebody who is an enthusiast who is curious, who likes to play with these kinds of tools, instead of doing the actual work that I'm supposed to be doing at the office. And sometimes like this, it just ends up you know, working out nicely. And it turns out that that was something that was useful. But I mean, I stayed up for two and a half hours after that on my phone, just asking this, this thing, questions. And again, this was like, literally hours after it had originally been released in research preview. And I had just finished reading a book by Brandon Sanderson called the Lost metal, which came out maybe a couple days beforehand. And it was like answering questions about the book. So it was very, it was very wild to me. And I didn't even realize at the time that it only was supposed to update up until 2021. And so as they put increasing, you know, limits and restrictions, and people did increasingly nefarious things with it and tried to get it to trip up and tell it, you had to make a bomb and stuff like that it became more and more restricted. But in the early days, it was wild, it was the first couple of days, it was just anything you wanted, back and forth. And I was having like, I mean, I've used it to play d&d with myself, and create entire character sheets and scenarios and walk me through encounters and stuff. I've used it to generate tables to you know, haven't come up with SEO keywords, verse certain subjects. But one of the things that really strikes me about it and the capabilities of it, and I'm still working on figuring out how to do this myself is to be able to feed it, the data from my own organization. So all of our annual reports, our partner interactions cleaned up, and anyone anonymized, obviously, or at least, you know, made so that it's not sensitive, I don't want to put sensitive data into it. There's a whole reasons why. And I'm not fully comfortable with doing that yet. But to be able to use it as a sort of living institutional memory with perfect recall, and the ability to make narrative connections and identify themes and shortcomings and everything. Once you have it built on a large enough data set as a custom set of information and data. Like I said, like our documentation and production, and publications over the last decade, the possibilities are endless. And it becomes a sort of imagine if you could hyper Google, everything you've ever done at your organization. And not only that, you could ask it to identify patterns, themes and narratives that have emerged in your work that you may not even have realized or known existed. And then once you get deeper and deeper into this, and you start realizing that the real power, just like any tool is not the tool itself, but it's the people who are using it. And you start to understand that the questions that you ask this thing matter so much more even than its ability to spit out text, that's when the real fun starts. And with the latest release of GPT four, which is you know, light years better in terms of logical reasoning and process and being able to really produce I mean, I'm using it now to to write my own front end interface for GPT, four and a little chat bot with no coding experience. I mean, my dad's a software engineer. And so I know how to talk to those kinds of people kind of my dad would probably argue with that. But I don't know JavaScript. I don't know Python, I don't know how to do this, I've tried a million times to teach myself that. And I was able to stand up a front end interface connecting to the API and open AI in a matter of hours with the GPT, four update, and the code works. And it can diagnose your code, and it can comment out all of your code. So not only are you able to build things and have it build with you as a sort of copilot as it's called, but it can help you lay the breadcrumbs for others to you know, follow up and make your work repeatable, as well. So I mean, I could go on for hours about it. But there are so many capabilities that it would be silly for me to try to list them all in the course of one podcast. Let's just suffice it to say that much. Yeah. And so let's shift our focus and focus directly on local newsrooms and the power that Chad gpz has and how they can harness it. And how do you see Chad TPT being an integral tool that they could use to for the operations and reporting processes. I've worked with local news organizations, local publishers, local journalists, entrepreneurial journalists for the last decade, and I used to be one myself, and most if not all, of these folks are working on a shoestring budget with a very small team. Most of them are wearing as the common you know, saying goes like a million different hats. A lot of them especially in like the 2012 to 2015 16 timeframe, were journalists that were either laid off or let go by major newsroom or chain newsrooms, and went from reporting or editing or designing their entire life to thinking, you know, I'm gonna start something on my own. I'm going to do the news, the way I think it should be done, I have all this experience. And I'd like to bring that to my community, whether it's a local community or an identity based community or a cultural community, and I'm going to do that and then they quickly realize that their journalism experience per se, their writing and editing and all that kind of stuff is useful, but it is nowhere near close to the whole picture and the

often the only avenue of redress or approach for them is to hire and or listen to a bunch of consultants, hopefully rely on organizations if they exist in their area, like the Center for cooperative media, which is grant funded and set up specifically to serve and support the needs of those exact kinds of needs of small publishers. But ultimately, it's just to have to schedule a meeting or go to an event or a workshop every time you want to learn about something new, or spend hours trying to figure out what to even Google to know what you need to know, that you don't already know about a particular topic is tough. And with something like GPT, and the other, you know, all the other GPT based apps and services that are out there, you can start further back. And it takes I'm hoping, and this is sort of the way I would approach it, if I were somebody in their position, that you would never have to worry about hiring a consultant ever again, except, you know, if you're lonely and you wanted to talk to somebody, because all of a lot of the least the upfront work, the structural work, the understanding, even understanding the terminology and knowing what to ask for, I mean, how many people who didn't go to business school or some kind of, you know, higher education know what a SWOT analysis is, for instance, right? I didn't even know about it until a couple years ago, because I did political science as my major I did not do business. When you learn a new word, when something with a tool like this, that word now becomes fully accessible to you. And you can implement those and you can have a generate examples of those kinds of stuff. But at a smaller, more granule, granular level, and going back to the mountain of bullshit that you have to do on a daily basis when you run a business, or when you work in one, having that be right at your fingertips. And even being able to ask a question, and have it generate documents for you while you're working on other things, then you come back to it, and you check. And it's just the time saving and the knowledge acquisition and the accumulation of components of it alone are worth it. In my opinion. I mean, the thing is free first of all, but if we're talking about like paying, you know, a couple, maybe 10 or $20 a month, incredibly worth it. But then when you get into the you know the weeds of this, and you start to build a sort of process for how to integrate this into your workflow. You combine it with things like Zapier, which is an easy no code automation tool, where you can based on triggers and responses, you can generate social media copy additional, you know, alternate headlines, have it help you clean up transcripts, and maybe even extract relevant or useful quotes. I mean, formatting text alone, I mean, the amount of terribly formatted abysmally formatted emails and communications that I see on a daily basis is enough to make this thing worth it because it can create bulleted lists, it can create tables, it can print things in different formats, it's pretty damn good at language translation, in a lot of cases, not perfect, but you can tell it to specialize or customize the translation for particular colloquial dialects. I mean, you can translate something in general Latin American Spanish, or you can have it translate in Cuban Spanish or Puerto Rican Spanish. And so far, the testing that I've done in work with our live translators, you know, our human translators, it's not unreadable, and it's better than Google Translate. But of course, I mean, there's there's specialized tools like deep L that are out there for that kind of task. But just this like leap in the ability, and the accessibility of this technology is where the biggest value bump is going to be, it is now at max, in most cases, like $20 a month to get the GPT pro account. And I would argue you don't even really need that. So the ability to just access this and play around with it and understand how you can incorporate it based on your needs and your organization's needs is has never been lowered, the barrier to entry has never been lower. And it really just comes down to do you have the imagination and creativity to figure out ways to implement this. And if you don't come talk to me, I'll I'll shoot, you know, back and forth with you. And we'll figure out how you might be able to use it.

Nikita Roy  13:40  
Yeah, and it's very exciting to see the use cases of Chad GPT. But now we've also reached a point where we need to know how to write for the robots, so that they diversity output that we want, which basically is AI, prompt engineering. And Joe, you're just the person to talk to you've put together a whole handbook about bigness, prom engineering for TPT, and how local newsrooms can use it. So what guidelines should we be keeping in mind for writing for Chachi? BTW?

Joe Amditis  14:09  
Yeah, so thank you. First of all, it was very kind, I don't think prompt engineering is going to be around as like a thing for too much longer. I think the most relevant example I can give is, I don't know if you remember when Google first was becoming popular and search engine and Boolean search came out. And I would argue, a lot of people still don't know how to Google things. I reminded of that almost every day. But essentially, you know, people had to learn how to talk to Google and how to ask for things in the right way in order to get the right results, which then eventually bled into how do you publish things so that Google's scrapers will see it. And that's where SEO came from this idea of search engine optimization, and it comes from both ends. So on the one end, the users have to get a grasp on how to how to search for things. And even beyond that, the number of searches will you know grows exponentially as the network effect takes you know, goes into effect and more and more people use it. And so you Is to have to use have to show people you can't just google how do I do this, I'm trying to do this because you need to use keywords, you need to say, legal template MOU, Local News, New Jersey laws, like you know, and you had to use all these specific phraseology and terms that you use. Whereas now it's sort of flipped again. And now they do want you to ask to ask in full sentences, because it's based on natural language processing, which is just a fancy way of saying it speaks like a human being does, and it can understand those things. And it's still a black box at some level in terms of what you'd have to write in order to get certain responses. And part of the one of the the sort of like warnings or downsides of this is that we don't really know, or at least, I don't even think the open AI folks fully know why it takes back certain responses based on certain prompts. But it's safe to say that there are certain patterns and certain tricks and tips that you can use. And I talked about them in the book, the most popular one that everybody knows at this point, or at least everybody who is paying attention, this knows this sort of act as prompt where you tell the bot to pretend that it's a marketing professional. And from what I understand, really all this is doing is it's just giving a general area of the large database of information that is in that bot, it's giving you a general area of where it should be focusing on for its responses. So when you say make me this, right, it'll make it'll do its best. And it's it really doesn't have any starting point. But if you say act as a marketing professional, or as a nonprofit management expert, all of a sudden now that it weights or preferences, information related to nonprofit management, or for marketing, upfront, it's sort of front loads that type of information. And it uses that context, to give you the responses that are more targeted and more tailored for that particular situation. And so it's sort of like a dance, you're going back and forth. And again, this thing has been out for less than like three months or something was like November 30, is when the big GPT, three chatbot was unveiled. So this is going to change and it's already changing even with for just coming out, it's going to change. But for now, everybody's still trying to sort of figure out the best way to go back and forth with these things. And really, the best way is to just play around, it's you know, if you have the free account, you just have unlimited prompts, it's not like, there's a limit on this not charging you or costing you money, I would just mess around and see what it's good at, see what it's not good at, see if you can trick it. And honestly, that's where I've learned the most is I tried to see if I can trip it up, see if I can confuse it and try to understand how it responds to increasingly confusing or convoluted requests. And then through that sort of emergent picture, you start to get an idea of what it's best at and what it's sort of like shaky at

Nikita Roy  17:29  
Joe, can we just like mess around with it a bit and see how you would dry prompts to chat TBT?

Joe Amditis  17:34  
Sure, let's mess around a little bit. So if I were a local newsroom, and I wanted to, you know, I want to make stuff for it. Where I have a client, let's say I have a client, that there's an advertising client, I've wanted them to pay me we ran their ads, I wanted to pay them. And they haven't paid me and I don't want to hire a lawyer yet. But I want to let them know that I'm serious. And I want to use language that sounds really scary legal language that will, you know, convince them that I'm serious. But I don't even know where to start. I don't have the money for a console. So I say I just speak to it like a normal person. I have an advertising client for my local news publication. The will and they haven't paid me for the ads. We ran for them for four months between January 2022. And April 2022. Please write a scary legal sounding email to the CEO of the shitty ad ads Incorporated. Letting them know that if we don't receive payment, for within the next two weeks, we will be forced to escalate the issue. Okay, so I've given it context here. I tell it what I want. This is what I wanted to do. This is some additional context about who it's going to. This is what the newsletter should have. This is the type of tone the scary sounding scary legal sounding email, right. And I'm just going to hit it. Let's see what it does. This is again, this the 3.5 model, your CEO of shitty ads Incorporated.

Nikita Roy  19:17  
Yeah, this sounds pretty convincing. It says I'm writing to you today regarding our outstanding debt of payments for advertisements that were run in the willow between January 2022 and April 2022. Despite numerous attempts to contact your company and resolve this matter, we have yet to receive payment for the services rendered. And it's styled pre scary as well, saying as you're undoubtedly aware, failure to pay for services rendered as a serious matter can result in legal consequences, and with therefore demanding that payment be made in full within the next two weeks. And If payment is not received within this timeframe, you'll have no choice but to escalate the matter. This could result in legal proceedings and additional fields and expenses incurred by a company and it's like a whole four paragraphs here.

Joe Amditis  19:57  
This sounds legit and this sounds like it was written by Anna Attorney and it's giving me all the information I need. So I'm going to read this very carefully. Before I send anything like this, I'm going to make sure that at all times, and at every level, I have robust and careful human oversight. But let's just say, let's say we want to want to make this a little scarier. Now, the thing that makes these things so powerful is its ability to remember up to a certain point in the context of the conversation. So a lot of chat bots in the past, what what happened is you send a message, it sends you a response. And then your next message is as if it was coming from a brand new person, it has no memory of the conversation and what the fact that this does have that to a certain extent, means you can do things like add a paragraph, that's that states that we've reached out to them several times over the course over the last three weeks, and have not received an adequate response. So I'm not giving it any information that I want it to continue to refer to our original conversation, but it knows that so when I click this, it's going to rewrite, it's going to add that it's going to give me the paragraph here, and then I can say, like, combine them into, let's just say, combine them. So now it's combining this paragraph, and it's inserting it in here where it makes sense. Boom, over the past three weeks, all this. So right away, this is like this is super useful, because it is it's giving me the language and the tone and the type of writing that I wouldn't even, I wouldn't even know where to begin on something like this. Now I can even say Create a list of 10 possible avenues of redress that we could pursue, if they don't respond. And let's see what it does. So now it's just giving me advice on what I can do, if they don't respond. And you just go, you can go further and further and deeper and deeper with this. And you can even go back up and edit your previous responses, which starts with sort of new sub thread or a new branch of the conversation tree that allow you to let's say they haven't paid, it's not CEO of shitty ads is the CEO of ads Unlimited, right. And now when I hit submit, it starts over, but it saves that conversation. And you can make infinite adjustments and tweaks like this, allowing you to quickly generate very similar but customized emails for different clients, or different people who are ripping you off. And then as you can see, our original conversation history is still there. So I'll stop there, so that we're not just looking at my screen this entire time. But that's basically where we're at in terms of the quickness, and the usefulness of something like this. And you can see, and you can hopefully you can imagine a myriad other uses and possibilities for something like this. We didn't even get into its ability to help you code or to create spreadsheets and analyze data. It's 3.5 kind of sucked at math. That's the only thing in true journalist fashion, it sucks at math. So you're you feel right at home there most of my most of the journalists listeners.

Nikita Roy  22:53  
And I think using it for the journalism world, we have a standard of ethics and practices that we need to absolutely adhere to. And so it's important for us to touch upon the challenges and opportunities that come with TPT. And from an ethical standpoint, what considerations should local newsrooms be aware of when employing Chad GBT for their operations and using it in scenarios like this?

Joe Amditis  23:17  
Well, number one, you should just assume that everything it gives you is bullshit. Everything that it sends back to you is either wrong or missing or incorrect or just slightly off. And if you go have you approach it with that mindset, because the reality is, most of it is fine. But if you approach it with that mindset from the beginning, you won't let your guard down, you'll stay vigilant and you won't get caught with your pants down when you publish something that is blatantly false or embarrassingly incorrect, or just betrays like a deep ignorance of a subject that is very common, right. And this happens isn't the same thing. When you get content or you know, stories in journalism submitted from freelancers or from somebody who you don't sit behind at work, you always want to edit because anything you put out into the world that has your name, or your company name on it, you're going to want to have to stand by you're gonna wanna be able to stand by it. So the rules haven't really changed too much there. The thing where we start to get murky is attribution and disclosure, which is where I think already journalists do a terrible job or you know, capital J journalism does a terrible job of letting the community into the process and not just letting them watch but letting them participate. And that's a whole nother conversation we can have but the same basic principles apply. Let people in have that give them a window at the very least into how this works, show them and tell them and make it clear to them that you you know what kind of tools or assistive technologies or generative technologies went into the production of your journalism and of your work. And again, just reiterating this goes for all aspects of journalism, not just the stuff you do with AI, but particularly because of the the sort of public moral panic around this kind of stuff at the moment. Like with anything transparency, trust, honesty, disclosure are your are your friends, the London School of Economics is doing a lot of really interesting work when it comes to the use of of AI in their new This room there, I think they're even doing a community journalism journalism AI community workshop coming up soon. And I just got off the phone with one of the folks from that organization today. They have all kinds of resources that they're building out in terms of, you know, an ethical approach to using this type of technology. How do you do disclosures? Trusting news is another organization that's really focusing on this and doing some great work. And they always have around transparency and authenticity and honesty, and openness in journalism. And even folks like Wired Magazine have a very clear disclosure policy on their website and in their articles, where they say not only how they used AI tools and generative AI in their production, but they say what they're willing to use AI tools for, and what they're not willing to use them for, and then what they're still considering it on the fence about. So for instance, they will not be using any AI generated images for their articles. But they might be they are open to using AI to help generate social copy and suggest alternate headlines for articles. So it really varies based on the relationship that you have with your audience and the relationship that you have to your own journalism and how comfortable you feel opening up the doors and letting people see that process. And I would argue that in most cases, it's going to be a benefit because you build trust by letting people know what you're doing and be like, they might have better ideas on how to use it than you do this. So why not let them in and become part of the process and you can build together and that way, the question of is this going to build trust or not is out the window? Because of course it will because they were part of it along the way. This is quite

Nikita Roy  26:26  
an exciting discussion. And I want to wrap things up with understanding how you see sort of like the future of the local newsrooms evolving, especially with the rise of generative AI and the power that Chad GPD holds. What thoughts do you have in terms of like, how this is going to evolve and the implications that might have for newsrooms,

Joe Amditis  26:45  
we're gonna see a lot more nonsense. You know, three years of a pandemic, and majority of people I talked to still don't know how to share their screen on Zoom. So I think we're a long way off from mass adoption, what we are going to see is a lot of people who were previously unable to access this kinds of tools and maybe would have thrived in using them and excelled. Now, they're gonna be able to do that. So your Grifters, your scam artists, I mean, you combine chat GPT with 11, labs, voice cloning, and the amount of grandmas and grandpas who are going to get their credit card stolen in Google gift cards, or Amazon gift cards is going to skyrocket. They just I'm sorry, just people are dumb. And they're very easily tricked. And a few, you know, relatively, you know, clever folks with sinister motives. It's going to do some damage. I mean, the same thing today, I've seen at least six hilarious, but very real looking photos of Donald Trump getting arrested. That didn't happen, or at least not yet, or not at all. I know that that didn't happen, because I follow the news. And I know I would see more about this. But they've got the hands right. And everything. These images are very convincing. They're hilarious. But I know for a fact, I'm just waiting to get that text message from my cousin who doesn't pay a lot of attention to news and may see these floating around and is just can you believe and then I you know, it's gonna be it's gonna be a lot more of a headache for your fact checkers for your deep bunkers and everything. And God bless them, I do not envy them for what they're going to have to deal with in terms of the onslaught of fake and misleading and generated content. But it's also this type of hand wringing also happened when the printing press came out? Oh, anybody can write anything. Now? What are we just kind of let anybody publish anything? And yeah, we are. And guess what it's going to be chaos. We haven't even really exited or left the, you know, introductory bubble of the internet, if we're being honest. I mean, the it's been what, maybe 20 years since in ubiquity of the internet, I would say maybe around the early 2000s. And like I said, as before, Zoom has been around for three years, we still haven't really figured out how to do that kind of stuff yet. So there's going to be a big learning curve. For some people, there's going to be a bigger learning curve for those for on the interpretation and the and the consumption end. But we're also going to see the proliferation of a lot of empowered individuals and low resource organizations able to generate output and work with things and build things at a scale and at a level and with sophistication and complexity that they were previously unable to do. So without lopping a major budget off for you know, tech and digital and development and stuff. So you're gonna like any new technology, you can't uninvent it, it's here now you can either figure out how it works and understand how it operates. Or you can you know, whine about it and wait until it takes over. So I choose to be on the on the tinkering side, I'd like to know how it works. I don't ever I don't want this to become like my thing, you know, because I get a lot of crypto vibes from the conversation around AI and the hype bubble that sort of is exploding there and Lord knows the Grifters and the hustle culture people have already globbed onto it, and have already started. I already got fooled by a $2 prompt book. And that's actually why I wrote the prompt book that I wrote because I paid $2 And we got paid $2 for this. And in two seconds. I was like aI wrote this, like the chat bot wrote this thing. I was like damn it. So I was like, well, actually, you know what, what if I wrote a good one, and then asked You know, if people would throw a few bucks, and turns out they would. And so again, when bullshit is so easy to make the value is in authenticity, and reality and human input and creativity. So it will simultaneously make it harder to tell the difference. And also easier to distinguish yourself and rise above, if you just put a little bit of elbow grease into something instead of just having the bot do it. I will say though, I cannot wait for the day to end when every single person I talked to asks the same question anytime I write an email or submit some text, which is just did the bot write that for you? Or did you write like, I'm waiting to the point where it gets that that question becomes similar to asking, Well, did you did you know that or did you Google it? So that's, that's what I see is the future. And, you know, I'm excited. It's exciting. It's scary. Either way, it's going to be funny, which I tend to appreciate whether or not that's going to be good for humanity and society. Overall, I can't tell you, but I'm here for the ride. So

Nikita Roy  30:55  
yeah. And just to wrap up for newsrooms, who want to be at the forefront of adopting this technology, and what's the biggest piece of advice you would give them? And right now,

Joe Amditis  31:05  
it's free. It's unlimited knowledge, play around with it, like, we have to have come up with a new, like, let me Google that for you thing, because there's no reason you shouldn't at least just make a free account, make a burner email, mess around with it, see what it's capable of, if you dig it, you dig it. If you don't, you can bail. But there's no cost to learning this thing. And it accelerates your ability to learn. So if you don't find that interesting or intriguing, I don't know what to tell, you know, have fun.

Nikita Roy  31:33  
Yeah, well, it's been an absolutely fascinating conversation to have with you, Joe today. And I can't thank you enough for taking the time to be on the AI and journalism podcast and sharing all of your insights and experiences with Chad GPT so far. But before we wrap up, I'd love to let our listeners know how they can stay connected with you and learn more about the resources and projects that you're working on.

Joe Amditis  31:57  
Sure, yeah, you could just go to center for cooperative media.org. That's our organization's website. We're also on medium and on Twitter at center Co Op media. Yeah, that's it center for cooperative media.org.

Nikita Roy  32:07  
Fantastic. Once again, thank you for joining us today. And it's been a pleasure having you on the show.

Joe Amditis  32:13  
Appreciate it. Thanks for having me.

Nikita Roy  32:16  
That was Joe and Titus, Assistant Director of products and events at the Center for cooperative media and author of the bigness from Tandberg chat. TPT. For local news publishers. You can look at our show notes for resources related to today's podcast. Subscribe to newsroom robots wherever you get your podcasts and send us any questions you have at news from robots.com. This podcast was made possible thanks to the Harvard Innovation Lab Spock grant. I'm Nikita Roy, and thank you for listening to newsroom robots.

"
newsroom_robots,1,"Wed, 12 Apr 2023 05:20:00 GMT",Matt Karolian: AI Efforts at The Boston Globe and Views on the AI Revolution,https://www.newsroomrobots.com/episodes/matt-karolian-ai-efforts-at-the-boston-globe-and-views-on-the-ai-revolution-WcLN8I7K,"<p>As AI technology rapidly evolves, how will it transform journalism and newsrooms? In our first episode, we delve into the intersection of AI and journalism with our guest, Matt Karolian, General Manager of Boston.com and Platforms at the Boston Globe. </p><p>In 2017, Matt spent a year at Harvard and MIT as a Nieman Fellow studying how AI and automation might impact the future of news, media, and publishing. </p><p>He teaches Audience Engagement: Journalism in the Age of Google, Facebook, Twitter, and Apple at the Harvard Extension School.</p><p>Join us for this insightful conversation as Matt shares his experience leading the AI efforts at The Boston Globe. He provides a unique perspective on how the news industry can adapt, innovate, and flourish in the age of AI. </p><p>We explore the implications of generative AI on journalism, tackle concerns related to AI disclosure, trust, accuracy, and bias, and examine the impact of AI-powered search engines on search traffic for publishers.</p><p>Be a part of the conversation on AI in journalism! Send us your questions <a href=""https://forms.gle/YfRDEsfcFphFpids9"">here</a>. </p><br /><hr /><p style=""color: grey; font-size: 0.75em;""> Hosted on Acast. See <a href=""https://acast.com/privacy"" rel=""noopener noreferrer"" style=""color: grey;"" target=""_blank"">acast.com/privacy</a> for more information.</p>","Nikita Roy  0:02  
This is Newsroom Robots, the podcast where we explore the intersection of artificial intelligence and the news industry. I'm Nikita Roy, data scientist, media entrepreneur, and one of the many founders currently building their ventures at the Harvard Innovation Labs. On the Newsroom Robots, I'm excited to bring you insightful conversations with industry experts about how AI is impacting the way we do journalism.

Matt Karolian  0:29  
Joining me today is an expert who is at the forefront of this exciting field. We have Matt Karolian, General Manager of Boston.com, and platforms at the Boston Globe. He spent a year at Harvard and MIT as a Nieman Fellow studying how AI and automation might impact the future of news, media and publishing. He teaches Audience Engagement: Journalism in the age of Google, Facebook, Twitter, and Apple at the Harvard Extension School. Matt, welcome. I'm so excited to have you here on my podcast today. Oh, thank you so much for having me. I'm so incredibly excited to be able to catch up today about well, I guess exactly what this podcast is called AI and journalism. Matt, I'd like to start with your time at the Nieman foundation where you studied how AI will impact the media industry's future. Earlier this year, you also wrote a substack post where you said that your main takeaway, which was about five years ago, was that the industry was far too focused on short term ideas, rather than preparing for the day when computers could read and write at a reasonably intelligible level, which now in 2023, is a reality the technology is here, and it's working. So I'd like to start off this conversation with the question that's top of mind for newsrooms right now. How should the media industry future proof itself for the AI revolution? Yeah, that's a great question. It's so funny to look back. I mean, you know, I feel like in five years is, you know, a lifetime, but also no time when it comes to some of this like really disruptive technology. I mean, back even five years ago, it was a big hit. Right? It it was, if machines can learn to read and write, that's going to be where the magic starts to happen. And as you just said, right, like, we've kind of hit that point. And so I think, you know, the way to, at least I'm thinking about AI, in the context of news media, and publishing is looking at it as a disruptive force. Right. So if we look at how traditionally, the news industry has been disrupted over time, you know, originally, we had, you know, the internet and the internet browser, disrupted printed papers, right? Like, instead of collecting your news from a stack of paper, they hit your doorstep every morning, you could go on your computer, and, you know, go to NY You know, nyt.com and get your news kind of instantly, Craigslist disrupted one of the largest revenue streams for publishers, which was classifieds. Google obviously disrupted the need for for loyalty, right. So it used to be you would go to your publisher, you had a question that you wanted answered. And now you would go to Google, Google also disrupted the the ad model, right? So instead of buying ads directly to publishers, you would buy targeting and pay a network, or pay an ad technology platform that has this network. And, you know, Facebook, disrupted curation, in the sense that, you know, it's not about going to the globe.com. And seeing what's organized there in terms of importance, every individual person on Facebook has their own individualized news feed. And for the most part, you know, I think news media and publishing industry, it's no secret has been on the more difficult end of those disruptive events, the one area that has not largely been disrupted, for the most part, right? Like there's, there's still like the content, greater ecosystem and those types of things. But he has content, right? Like, we still largely produce content the same way for today's we did you know, in 1950, or 1850, for that matter, right, like a reporter is going out in the fields, collecting information, doing an investigation, talking to people, and then writing that in taking that content and turning it into a linear story. And then that story gets published, and it's relatively static, right, we printed in the paper, and we posted online. Again, there's some some exceptions there. But largely, that's how it kind of works. And generative AI is going to disrupt, at least in my opinion, that last vestige of news media and publishing that has not been horribly disrupted. And so it's a big moment right now. It's kind of the last, the last area that's not disrupted. And this technology is happening. It's coming online really, really quickly. And publishers really need to think about how they approach this because if they don't, they're just going to find themselves on the on the losing end of that disruption. We have this rare moment of opportunity to kind of chart our own course and impact our own destiny, and we need to seize on that. And I want to delve more into that topic, generative AI with the release of chat GBT and dally it's been quite the sensation globally. And in regards to the news industry, it's there's been quite the hype, but there's also understandably

Nikita Roy  5:00  
been some hesitation and skepticism regarding using these tools, and a lot of concerned regarding robots taking over the job of a journalist. I want to get your thoughts on what the implications you see, of using this technology for journalism is? And is the job of a journalist really under threat?

Matt Karolian  5:20  
Yeah, it's a great question. You know, I think a lot of the anxiety is coming from not being able to parse out the two different kinds of components of generative AI. So, you know, I think there, there are two main main chunks, right there is, you know, I'm just gonna use GPT, as the example, right, like, what GPT knows, is different than what GPT knows how to do, right. And I think we see these examples where, you know, you'll ask it to write an article about, you know, a news event. And it just makes stuff up, right. And because it's pulling on a corpus of highly unreliable, in poorly structured data from a fact and storytelling perspective. And that's difficult and scary, and not very likely what users want. And it's not particularly helpful. What is the the big opportunity, in my mind is that it knows how to write an article, it knows how to write a radio script, it knows how to write a YouTube script. And the ability to know how to do those things, met with verified data from a reporter is a really, really powerful combination. And that's where I think we can, as the news, media and publishing industry can win. And so that's how we're kind of looking at it at the globe, at least, I think that's how a lot of others are starting to look at it. But there is that lot of hand wringing and anxiety because these examples of, you know, going to church EBT and saying, Hey, write the story. They're filled with errors. Nobody wants errors. And so you know, what we need to do is train train these these models on our own data, verified data, timely data, as opposed to just relying on this huge corpus of data that these natural language models have been previously trained on, right? It's great if you wanted to read a fictitious story, or write a song or you know, do those types of things. But when when facts matter, you need a journalist in the loop, you need a journalist driving that loop. And so I think, partially the way that that all kind of plays out, right, it's like, this is a force multiplier for journalists. This increases the importance of journalism and reporting, because it's so it's so fundamental to the success of this technology. You know, I see this much more as kind of a an Iron Man suit that a reporter puts on and allows them to be more capable. And that allows them to get more done, and allows them to do fundamentally more reporting and less writing. I mean, this, this reminds me of a of a conversation that I used to have with a journalist that I worked with, who would oftentimes remind the newsroom that they were a reporter, not a writer. And you know, the things that they were really good at are going out, getting sources figuring out and breaking news. And then the part of the job that they did not particularly like was then taking all of that, those learnings in that that news that the public needed to know, and turning it into a story, right, like actually sitting down to write. And so I think that, you know, this is going to be a technology that allows for, you know, journalists to become untethered from what is sometimes seen as the chore of them writing a story, for the large for the most part.

Nikita Roy  8:22  
Yeah, it's interesting to explore how AI can really help journalists with their writing process, and free up time for what we're really good at doing, which is going out and getting the stories and reporting. But I'm really excited to learn more about how AI is being introduced and implemented in the newsroom. From a leadership point of view, you are leading the AI efforts at the Boston Globe. And so I'm really curious to hear more about what your experience has been using this technology as the newsroom leader and want to get a more hands on perspective. So can you tell me more about how AI is being used right now at the globe? And how has the response been?

Matt Karolian  9:04  
That's a really great question. It's something that we're working on as teams, right? So our newsroom teams have been leaning into investigating things like story automation in categories where there's a lot of structured data, so things like real estate transactions and weather in sports. And so that that kind of team is running really kind of quickly at those types of things. We have, you know, another group that's looking at like generative AI as it relates to imagery, so using tools like dolly and journey to quickly and super efficiently create imagery for stories, right? So, you know, not not every single story necessarily has a great photo to go with it. Or if we want to do an illustration that's very, you know, time intensive and you being able to use tools like this can potentially pose a huge kind of efficiency, opportunity. And then we're looking at ways of producing content that we otherwise would not have been able to produce. So for example, is there an opportunity for every story we write to also have aI go in and create a radio script version of that is that is then turned into an audio file. Using text to speech, AI, which has gotten quite convincing, you know, an area that is really kind of accelerated is the ability to take text and have a machine, read it back to you, and have it sound almost indistinguishable from, from a person reading it, you know, and that lets us deploy content in ways that we otherwise we wouldn't be able to do. So when you're reading a story, you know, reading a text story, you kind of have to pay 100% of your attention to that story, which is great, but it means that you can't do other things. And there are times of your day where you're doing dishes, doing laundry, driving, doing a whole bunch of other other activities, where you know, you're not able to also read while while doing those activities. But if we're able to go and create radio scripts, and have those radio scripts turned into audio that you can listen to you big opportunity to extend, extend the work and introduce a whole new audience to to that journalism, which you know, folks otherwise would not have been able to get access to, because it would have required them to be spending all of their time and attention reading it. So, you know, we're looking at things like that we're looking at being able to summarize, stories make stories dynamic to the context of a reader, there's a huge amount of opportunity, you know, one of the things that I've always really dreamt of right is that a story would be unique and customized to you and your context and your interest. So for example, like health care, where if you're reading a story about health care reform, it would be really handy if that story was augmented with information in context about your congressional representatives, right? How are they talked about this? How they voted on it? What are their stances to you personally? Do you have something in your life? Or, you know, is there a data point that we can we can use to help further contextualize the story for you write like, you know, I have, I have asthma, I need an inhaler. It's a story about healthcare reform, how's that gonna, like impact, you know, my, the cost of my, you know, Albuterol inhaler, you know, there's, there's a big opportunity to make this from a one, a one size fits all approach to being quite customized, and legitimately, and potentially much more useful. And so these are all things we're thinking about, I think one of the things that I'm really grateful for is that, you know, we have a team at the globe, who's really kind of leaning in as opposed to being, you know, worried about or overly worried about the threats of AI. From a disruption standpoint, you know, there's a willingness to lean in and experiment and be at the forefront, as opposed to kind of leaning back and just seeing what happens.

Nikita Roy  12:34  
Well, that's very exciting to be at a really experimental phase with AI at the Globe, and exciting to hear to hear about all of the different opportunities exploring, but it kind of leads me into my next question, which is really about all the concerns the industry is having about AI disclosure, trust accuracy, the bias of generative AI, we as a news industry are held to a really high standard, and how are you ensuring that as a newsroom, you're also able to maintain the core values and journalistic standards, while also adapting to all of these new technologies, and finding new ways to deliver content?

Matt Karolian  13:15  
That's a great question. You know, I think we're always leaning towards disclosure, right? Like, it's always better to over communicate and over explain than it is to try to do the opposite, right, where you try to either either intentionally or unintentionally create a situation where, you know, a user doesn't quite understand if what they're reading was generated by a person or generated by a machine. You know, I will say that, you know, I think that there's a lot of anxiety in our industry about about this, but AI is like, microplastics, it is in everything, like every digital system that you touch for you, or have touched or used for the past 670 years, AI is driving some element of that, whether it's what you see, when you do a Google search, you know, your personalized feed with an Apple news down to things like, you know, Netflix using, you know, data from, you know, their shows to then create new scripts and new shows that are more optimized based on when people, you know, stopped watching, which was, I think, what they did on House of Cards, they looked at, you know, how, when viewers would exit an episode, and they could start to understand what was, you know, what was driving those patterns, and, you know, it actually impacted their, their creative process in terms of, you know, writing scripts that avoided those, you know, exit triggers. So, we're looking at all of that, you know, we're obviously leaning towards being you know, more at the forefront of disclosure and making sure that, you know, users always always know when and where they're experiencing AI generated content. But I think you know, one of the big blind spots we have right now is user preference. Do your users like aI content? Do they not like AI? At content, we have a lot of ideas around how users will, will respond and interact with this content. But we don't actually have a whole lot of data around. What happens in practice, which is going to be a big area of learning, I think over the next year, is understanding that when you introduce this content or these systems to, to readers and users, how do they respond from an engagement perspective? And how do they respond from a UX perspective, and in terms of whether or not they they find these things valuable or off putting, or if they love it, or if they just don't care about it? Right? Like, it might, it may be that at the end of the day, their article that they're reading, or their experience that they're having is, you know, impacted or driven by AI, and it creates a better experience for them that they might not care at all. And we're just gonna have to see where where this all goes. Because it's a, it's a big unknown. I think if we look at, you know, the areas where AI is most prevalent in people's lives, there is really not a whole lot of pushback, right? Like customer, you know, customized Spotify playlists, news feed on Facebook, more relevant results within search, you know, all of those things are, are huge parts of people's lives. Now, I think the general consensus is that it's been an added value. We'll see. But yeah, we're we're just being very cautious and over over communicating. And starting starting from that posture as opposed to those the opposite.

Nikita Roy  16:23  
And I just want to sort of go back to search results you were talking about is a huge part of people's lives. It's also a huge part of traffic for publishers today. But with generative AI, we are now moving into a future with AI powered search engines like Bing testing our charge GPT powered search results and the startup naeba Ai, that just shows you a summarized answer for your questions, and then references that out to other websites. Yeah. How do you see the future of search now evolving? And its impact on search traffic for publishers?

Matt Karolian  16:58  
Yeah, I mean, you know, I think realistically, the publishing industry, and the news industry should prepare for that traffic that they're getting from search right now, to diminish significantly, right? If users are going to search for an answer, right? They go to Google for an answer, and then they are able to get that answer, right within the results page. That's going to satisfy percent or more, in my opinion, people's questions, right, you know, we Google things all the time that we're just looking for a quick answer, right? Like, how long do I need to cook this chicken? How, what was the score to the Red Sox game last night, you know, just all of these kinds of like, short, direct queries. And Google has been doing a fairly good job of servicing those for a long time with snippets and smart standards. Now, things are getting, you know, slightly more complex. And, you know, the summaries are generally pretty good. But also partially, you know, in some cases, like, absolutely completely wrong and disastrous, right. And like, we're going to need to see how users respond to that, right, like, one out of every five queries, they put into a search tool returns a result that is inaccurate. Is that acceptable to users? Or is that not right? Like, if, if you're, you know, Googling the safe cooking temperature for fish, and that number is wrong, and you poison your your dinner guests? Is that going to make it so that you, you know, never, never want to use this? Again? That's a great question. You know, I think that there's going to be an industry that gets created, where, you know, this industry would would essentially feed structured and verified news and information data to these platforms, so that it increases the overall accuracy of those results. Right? You know, right now, these tools are trying to go and crawl the web for information and understand the context. And then, you know, string it all together into a little paragraph summary. And they can get it really wrong. You know, I have a friend who unfortunately shares a name with someone who was a kk k Klansmen who murdered people in the 60s or 70s. And there was a, you know, I asked, you know, one of these platforms, who is, you know, my friend, and I use his name, he completely conflated my friend who is someone who's fairly known in, you know, the tech industry, with this keh, keh, keh Klansmen? And I mean, no distinguishing it did not distinguish between the two individuals, which obviously was pretty horrific and was not not acceptable to this person. And, you know, those kinds of errors are gonna continue to exist. If, if the data is not, you know, well structured and verified, it's gonna go into it. So, you know, I think one of the things that I kind of went on a bit of a tweet storm about last late last year was, I think a lot of there's going to be an industry where, you know, reporters are going to be then effectively writing for machines as opposed to readers. It's probably not going to be the majority of the news media publishing industry, but they will you know, I'm fairly confident that they will be an industry that exists to feed that structured data, verified and structured data into these models in relative real time so that the quality of those results is better.

Nikita Roy  20:12  
So right now, we're still dealing with the misinformation and lack of accuracy from responses generated by Tad CBT. But even with all of this, as newsrooms increasingly look to opportunities with AI to help them produce content and streamline workflows, there's still a lot of lingering questions about how to effectively adopt this technology. And what do you think? What should be the steps in newsroom should take today to prepare for and embrace these changes?

Matt Karolian  20:43  
Yeah, it's a great question. I mean, I would really, the opportunity for publishers is not in what she did these GPT systems. No, it's in what they know how to do, right, like, start really focusing on using your own data as input to help drive really high quality outputs of these systems. In You know, I think that that is going to be the most fruitful path for publishers, both in terms of increasing efficiency, as well as generating really high quality output. That is really where I'm looking really for the next year, year and a half as to where we're going to be able to do the most experimentation and have the most most number of successful experiments as in, how do we use these tools to help interpret and reformat and augment the reporting that our reporters are already already doing? Right, like if we're able to write Quick, quick stories based on you know, bullet points from a reporters notebook that's really compelling. And lets us do more of those types of stories and lets these reporters be even more effective.

Nikita Roy  21:48  
All of these ideas that you're talking about really gets me thinking. And I want to end with this futuristic question. What do you think in 10 years down the line? How will the newsroom of the future look like?

Matt Karolian  21:59  
Oh, my gosh, great question. I if I knew the answer to this, I'd be a very, very wealthy man. I mean, I, you know, I think it's tools. I'm doing a poor job of describing it. So I think it's, I think it's further augmenting reporters with tools that allow them to further accelerate their job, whether that's being able to give them access to tools that allow them to uncover patterns that previously weren't apparent, right. And like, this is already kind of happening in some newsrooms, including, you know, a team at the globe, use an AI tool in the past few years, to fuel some reporting that was incredibly impactful. So it's gonna be giving, giving more and more reporters access to those tools that let them tell, like, uncover new truths and tell new stories, which is really excellent. I think we're gonna see AI help further fuel customization and relevancy for users. Right. So going back to that example of, you know, reading a story about healthcare and having it be customized to the user. And like, overall, Rick, really, there's this great book that my father in law gave me from that was written in the 70s, called Dream machines. And it's all about like, you know, the moment like the idea of desktop computing was coming online, and like, oh, my gosh, we have these these incredibly powerful, you know, devices that are connected and run code. But largely, we've treated them a lot like paper, right? And like, they use the six, you know, this word, or this phrase called the paper dime, where, you know, we use we've largely use these machines, like we've used paper, right? Like we go out, be collect information, you write a story and you publish it, and you're kind of like, you know, that's that's the real process, as opposed to be like, oh, gosh, like, we can build stories and experiences in the same way that we kind of build code where, you know, you're getting a multimedia, interactive, smart experience, that becomes more relevant to you that becomes more usable, that has better, more relevant context. It's, it's interesting, you know, I think we'll certainly see efficiency gains. But I think we also see this real, real, real significant threat from these large tech platforms, who want to get into journalism. And you're seeing that with Google bar, and you're seeing it with Neve AI, where you go, you go to those platforms, and you enter a query and you get a result right within right within search. And that's based on the work and labor of reporters. So one of the things we really got to do is figure out as an industry, how we're going to deal with that, right? Like these platforms, can't keep stealing our work and, and passing it off as their own in search. And so that's going to be a whole other battle that is likely to play out.

Nikita Roy  24:29  
Exactly what I'm really getting from this entire conversation is that more than AI taking away the job of journalists, we are going to have platforms steal our work, and that's the more alarming fact than us journalists having to be replaced by AI. Matt, this has just been such a fascinating conversation today. Thank you so much for talking about all things AI in journalism with me and I'm excited to see how the Boston Globe evolves and progresses by In facing AI,

Matt Karolian  25:01  
yeah, I'm so happy I had the opportunity to join you. And, you know, I'll keep listening. And I'm really curious to hear how others are approaching the same problems. It's her opportunities. I mean, they're really opportunity. So thank you so much for having me. It was great to reconnect. And I'm going to kind of continue to listen and excited to hear your conversations with others.

Nikita Roy  25:22  
That was mad Carolien, General Manager of boston.com and platforms at the Boston Globe. Subscribe to the newsroom robots wherever you get your podcasts and follow us on your favorite social media platform at newsroom robots. For more updates and insights about the world of AI and journalism. This podcast was made possible thanks to the Harvard Innovation Lab Spock grant. I'm Nikita Roy and thank you for tuning in.

"